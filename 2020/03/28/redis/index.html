<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="redis,数据库,">










<meta name="description" content="Redis单线程优势Redis 是完全开源免费的，遵守BSD协议，是一个高性能的key-value数据库。 NoSQL数据库的产生就是为了解决大规模数据集合，多重数据种类带来的挑战。 Redis 与其他 key - value 缓存产品有以下三个特点：  Redis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。 Redis不仅仅支持简单的key-value类型的">
<meta name="keywords" content="redis,数据库">
<meta property="og:type" content="article">
<meta property="og:title" content="redis知识汇总">
<meta property="og:url" content="http://yoursite.com/2020/03/28/redis/index.html">
<meta property="og:site_name" content="Wxning">
<meta property="og:description" content="Redis单线程优势Redis 是完全开源免费的，遵守BSD协议，是一个高性能的key-value数据库。 NoSQL数据库的产生就是为了解决大规模数据集合，多重数据种类带来的挑战。 Redis 与其他 key - value 缓存产品有以下三个特点：  Redis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。 Redis不仅仅支持简单的key-value类型的">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://yoursite.com/images/redis-16.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-17.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-18.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-19.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-24.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-25.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-13.png">
<meta property="og:image" content="http://yoursite.com/images/redis-20.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-21.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-22.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-6.png">
<meta property="og:image" content="http://yoursite.com/images/redis-23.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-14.png">
<meta property="og:image" content="http://yoursite.com/images/redis-26.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-8.png">
<meta property="og:image" content="http://yoursite.com/images/redis-9.png">
<meta property="og:image" content="http://yoursite.com/images/redis-10.png">
<meta property="og:image" content="http://yoursite.com/images/redis-11.png">
<meta property="og:image" content="http://yoursite.com/images/redis-12.png">
<meta property="og:image" content="http://yoursite.com/images/redis-27.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-31.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-30.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-28.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-29.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-32.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-33.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-34.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-4.png">
<meta property="og:image" content="http://yoursite.com/images/redis-5.png">
<meta property="og:image" content="http://yoursite.com/images/redis-7.png">
<meta property="og:image" content="http://yoursite.com/images/redis-35.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-36.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-37.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-38.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-39.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-40.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-41.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-42.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-43.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-44.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-45.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-48.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-49.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-50.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-51.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-52.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-53.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-54.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-55.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-56.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-57.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-58.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-59.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-60.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-61.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-62.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-63.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-64.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-65.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-66.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-67.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-68.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-69.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-70.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-71.jpg">
<meta property="og:image" content="http://yoursite.com/images/redis-72.jpg">
<meta property="og:image" content="http://yoursite.com/2020/03/28/redis/assets/16328983917246.jpg">
<meta property="og:updated_time" content="2021-09-29T06:53:12.684Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="redis知识汇总">
<meta name="twitter:description" content="Redis单线程优势Redis 是完全开源免费的，遵守BSD协议，是一个高性能的key-value数据库。 NoSQL数据库的产生就是为了解决大规模数据集合，多重数据种类带来的挑战。 Redis 与其他 key - value 缓存产品有以下三个特点：  Redis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。 Redis不仅仅支持简单的key-value类型的">
<meta name="twitter:image" content="http://yoursite.com/images/redis-16.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2020/03/28/redis/">





  <title>redis知识汇总 | Wxning</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>
    <a href="https://github.com/wxning1107" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewbox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"/><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"/><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"/></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Wxning</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-个人简历">
          <a href="/个人简历/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            个人简历
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/03/28/redis/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Wxning">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Wxning">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">redis知识汇总</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-03-28T23:07:31+08:00">
                2020-03-28
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/数据库/" itemprop="url" rel="index">
                    <span itemprop="name">数据库</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/数据库/redis/" itemprop="url" rel="index">
                    <span itemprop="name">redis</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i> 阅读数
            <span class="busuanzi-value" id="busuanzi_value_page_pv"></span>次
            </span>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="Redis单线程优势"><a href="#Redis单线程优势" class="headerlink" title="Redis单线程优势"></a>Redis单线程优势</h2><p><a href="https://redis.io/" target="_blank" rel="noopener">Redis</a> 是完全开源免费的，遵守BSD协议，是一个高性能的key-value数据库。</p>
<p>NoSQL数据库的产生就是为了解决大规模数据集合，多重数据种类带来的挑战。</p>
<p>Redis 与其他 key - value 缓存产品有以下三个特点：</p>
<ul>
<li>Redis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。</li>
<li>Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。</li>
<li>Redis支持数据的备份，即master-slave模式的数据备份。</li>
</ul>
<p>Redis优势：</p>
<ul>
<li>性能极高 – Redis能读的速度是110000次/s,写的速度是81000次/s 。</li>
<li>丰富的数据类型 – Redis支持二进制案例的 Strings, Lists, Hashes, Sets 及 Ordered Sets 数据类型操作。</li>
<li>原子 – Redis的所有操作都是原子性的，意思就是要么成功执行要么失败完全不执行。单个操作是原子性的。多个操作也支持事务，即原子性，通过MULTI和EXEC指令包起来。</li>
<li>丰富的特性 – Redis还支持 publish/subscribe, 通知, key 过期等等特性。</li>
</ul>
<p>首先，我要和你厘清一个事实，我们通常说，Redis 是单线程，主要是指 Redis 的网络 IO<br>和键值对读写是由一个线程来完成的，这也是 Redis 对外提供键值存储服务的主要流程。<br>但 Redis 的其他功能，比如持久化、异步删除、集群数据同步等，其实是由额外的线程执<br>行的。</p>
<h3 id="为什么不用多线程？"><a href="#为什么不用多线程？" class="headerlink" title="为什么不用多线程？"></a>为什么不用多线程？</h3><p>使用多线程，可以增加系统吞吐率，或是可以增加系统扩展性。但是，多线程编程模式面临的共享资源的并发访问控制问题。系统中通常会存在被多线程同时访问的共享资源，比如一个共享的数据结构。当有多个线程要修改这个共享资源时，为了保证共享资源的正确性，就需要有额外的机制进行保证，而这个额外的机制，就会带来额外的开销。</p>
<h3 id="单线程-Redis-为什么那么快？"><a href="#单线程-Redis-为什么那么快？" class="headerlink" title="单线程 Redis 为什么那么快？"></a>单线程 Redis 为什么那么快？</h3><p>通常来说，单线程的处理能力要比多线程差很多，但是 Redis 却能使用单线程模型达到每<br>秒数十万级别的处理能力，这是为什么呢？其实，这是 Redis 多方面设计选择的一个综合<br>结果。<br>一方面，Redis 的大部分操作在内存上完成，再加上它采用了高效的数据结构，例如哈希<br>表和跳表，这是它实现高性能的一个重要原因。<br>另一方面，就是 Redis 采用了多路复用机制，使其在网络 IO 操作中能并发处理大量的客户端请求，实现高吞吐率。</p>
<h2 id="redis数据类型"><a href="#redis数据类型" class="headerlink" title="redis数据类型"></a>redis数据类型</h2><p>redis数据类型与底层数据结构对应关系：<br><img src="/images/redis-16.jpg" alt="redis-1"></p>
<p>为了实现从键到值的快速访问，Redis 使用了一个哈希表来保存所有键值对。一个哈希表，其实就是一个数组，数组的每个元素称为一个哈希桶。所以，我们常说，一个哈希表是由多个哈希桶组成的，每个哈希桶中保存了键值对数据。哈希桶中的元素保存的并不是值本身，而是指向具体值的指针。这也就是说，不管值是 String，还是集合类型，哈希桶中的元素都是指向它们的指针。<br><img src="/images/redis-17.jpg" alt="redis-1"></p>
<p>hash表的操作时间复杂度是O(1)，但是当往 Redis 中<br>写入大量数据后，就可能发现操作有时候会突然变慢了。这是因为忽略了一个潜在的风险点，那就是哈希表的冲突问题和 rehash 可能带来的操作阻塞。<br>Redis 解决哈希冲突的方式，就是链式哈希。链式哈希就是指同一个哈希桶中的多个元素用一个链表来保存，它们之间依次用指针连接。<br>如果哈希表里写入的数据越来越多，哈希冲突可能也会越来越多，这就会导致某些哈希冲突链<br>过长，进而导致这个链上的元素查找耗时长，效率降低。所以，Redis 会对哈希表做 rehash 操作。rehash 也就是增加现有的哈希桶数量，让逐渐增多的 entry 元素能在更多的桶之间分散保存，减少单个桶中的元素数量，从而减少单个桶中的冲突。<br>其实，为了使 rehash 操作更高效，Redis 默认使用了两个全局哈希表：<code>哈希表 1</code> 和<code>哈希表 2</code>。一开始，当你刚插入数据时，默认使用哈希表 1，此时的哈希表 2 并没有被分配空间。随着数据逐步增多，Redis 开始执行 rehash，这个过程分为三步：</p>
<ol>
<li>给哈希表 2 分配更大的空间，例如是当前哈希表 1 大小的两倍；</li>
<li>把哈希表 1 中的数据重新映射并拷贝到哈希表 2 中；</li>
<li>释放哈希表 1 的空间。</li>
</ol>
<p>到此，我们就可以从哈希表 1 切换到哈希表 2，用增大的哈希表 2 保存更多数据，而原来<br>的哈希表 1 留作下一次 rehash 扩容备用。这个过程第二步涉及大量的数据拷贝，如果一次性把哈希表 1 中的数据都迁移完，会造成 Redis 线程阻塞，无法服务其他请求。此时Redis 就无法快速访问数据了。为了避免这个问题，Redis 采用了渐进式 rehash。<br>简单来说就是在第二步拷贝数据时，Redis 仍然正常处理客户端请求，每处理一个请求<br>时，从哈希表 1 中的第一个索引位置开始，顺带着将这个索引位置上的所有 entries 拷贝<br>到哈希表 2 中。等处理下一个请求时，再顺带拷贝哈希表 1 中的下一个索引位置的 entries。如下图所示：<br><img src="/images/redis-18.jpg" alt="redis-1"></p>
<p>这样就巧妙地把一次性大量拷贝的开销，分摊到了多次处理请求的过程中，避免了耗时操<br>作，保证了数据的快速访问。<br><img src="/images/redis-19.jpg" alt="redis-1"></p>
<blockquote>
<p>第一，单元素操作，是指每一种集合类型对单个数据实现的增删改查操作。例如，Hash 类<br>型的 HGET、HSET 和 HDEL，Set 类型的 SADD、SREM、SRANDMEMBER 等。这些操<br>作的复杂度由集合采用的数据结构决定，例如，HGET、HSET 和 HDEL 是对哈希表做操<br>作，所以它们的复杂度都是 O(1)；Set 类型用哈希表作为底层数据结构时，它的 SADD、<br>SREM、SRANDMEMBER 复杂度也是 O(1)。Hash 类型的 HMGET 和 HMSET，Set 类型的 SADD 也支持同时增加多个元素。此时，这些操作的复杂度，就是由单个元素操作复杂度和元素个数决定的。例如，HMSET 增加 M 个元素时，复杂度就从 O(1) 变成 O(M) 了。</p>
</blockquote>
<blockquote>
<p>第二，范围操作，是指集合类型中的遍历操作，可以返回集合中的所有数据，比如 Hash<br>类型的 HGETALL 和 Set 类型的 SMEMBERS，或者返回一个范围内的部分数据，比如 List<br>类型的 LRANGE 和 ZSet 类型的 ZRANGE。这类操作的复杂度一般是 O(N)，比较耗时，<br>我们应该尽量避免。不过，Redis 从 2.8 版本开始提供了 SCAN 系列操作（包括 HSCAN，SSCAN 和 ZSCAN），这类操作实现了渐进式遍历，每次只返回有限数量的数据。这样一来，相比于 HGETALL、SMEMBERS 这类操作来说，就避免了一次性返回所有元素而导致的 Redis 阻塞。</p>
</blockquote>
<blockquote>
<p>第三，统计操作，是指集合类型对集合中所有元素个数的记录，例如 LLEN 和 SCARD。这<br>类操作复杂度只有 O(1)，这是因为当集合类型采用压缩列表、双向链表、整数数组这些数<br>据结构时，这些结构中专门记录了元素的个数统计，因此可以高效地完成相关操作。</p>
</blockquote>
<blockquote>
<p>第四，例外情况，是指某些数据结构的特殊记录，例如压缩列表和双向链表都会记录表头<br>和表尾的偏移量。这样一来，对于 List 类型的 LPOP、RPOP、LPUSH、RPUSH 这四个操<br>作来说，它们是在列表的头尾增删元素，这就可以通过偏移量直接定位，所以它们的复杂<br>度也只有 O(1)，可以实现快速操作。</p>
</blockquote>
<table>
<thead>
<tr>
<th>类型</th>
<th>简介</th>
<th>特性</th>
<th>场景</th>
</tr>
</thead>
<tbody><tr>
<td>String(字符串)</td>
<td>二进制安全</td>
<td>可以包含任何数据,比如jpg图片或者序列化的对象,一个键最大能存储512M</td>
<td>做简单的键值对缓存。适合最简单的k-v存储，类似于memcached的存储结构，短信验证码，配置信息等，就用这种类型来存储。</td>
</tr>
<tr>
<td>Hash(字典)</td>
<td>键值对集合</td>
<td>适合存储对象，并且可以像数据库中update一个属性一样只修改某一项属性值(Memcached中需要取出整个字符串反序列化成对象修改完再序列化存回去)</td>
<td>1，存储，读取修改用户属性。2，结构化的数据，比如一个对象。3，一般key为ID或者唯一标示，value对应的就是详情了。如商品详情，个人信息详情，新闻详情等。</td>
</tr>
<tr>
<td>List(列表)</td>
<td>链表(双向链表)</td>
<td>增删快，提供了操作某一段元素的API</td>
<td>1,最新消息排行等功能(比如朋友圈的时间线) 2,消息队列 3，存储一些列表型的数据结构，类似粉丝列表，文章评论列表之类。4，因为list是有序的，比较适合存储一些有序且数据相对固定的数据。如省市区表、字典表等。因为list是有序的，适合根据写入的时间来排序，如：最新的***，消息队列等。</td>
</tr>
<tr>
<td>Set(集合)</td>
<td>哈希表实现,元素不重复</td>
<td>1、添加、删除,查找的复杂度都是O(1) 2、为集合提供了求交集、并集、差集等操作</td>
<td>1、共同好友（交集并集差级操作，两个人的粉丝列表整一个交集） 2、利用唯一性,统计访问网站的所有独立ip 3、好友推荐时,根据tag求交集,大于某个阈值就可以推荐。4，可以简单的理解为ID-List的模式，如微博中一个人有哪些好友，set最牛的地方在于，可以对两个set提供交集、并集、差集操作。例如：查找两个人共同的好友等。</td>
</tr>
<tr>
<td>Sorted Set(有序集合)</td>
<td>将Set中的元素增加一个权重参数score,元素按score有序排列</td>
<td>数据插入集合时,已经进行天然排序</td>
<td>1、排行榜 2、带权重的消息队列 3、去重还可以排序，比如获取排名前几名用户。4，是set的增强版本，增加了一个score参数，自动会根据score的值进行排序。比较适合类似于top 10等不根据插入的时间来排序的数据。</td>
</tr>
</tbody></table>
<h2 id="String-应用场景"><a href="#String-应用场景" class="headerlink" title="String 应用场景"></a>String 应用场景</h2><ul>
<li><strong>缓存功能：String</strong>字符串是最常用的数据类型，不仅仅是<strong>Redis</strong>，各个语言都是最基本类型，因此，利用<strong>Redis</strong>作为缓存，配合其它数据库作为存储层，利用<strong>Redis</strong>支持高并发的特点，可以大大加快系统的读写速度、以及降低后端数据库的压力。</li>
<li><strong>计数器：\</strong>许多系统都会使用*<em>Redis*</em>作为系统的实时计数器，可以快速实现计数和查询的功能。而且最终的数据结果可以按照特定的时间落地到数据库或者其它存储介质当中进行永久保存。</li>
<li><strong>共享用户Session：\</strong>用户重新刷新一次界面，可能需要访问一下数据进行重新登录，或者访问页面缓存*<em>Cookie*</em>，但是可以利用<strong>Redis</strong>将用户的<strong>Session</strong>集中管理，在这种模式只需要保证<strong>Redis</strong>的高可用，每次用户<strong>Session</strong>的更新和获取都可以快速完成。大大提高效率。</li>
</ul>
<h2 id="Hash-应用场景"><a href="#Hash-应用场景" class="headerlink" title="Hash 应用场景"></a>Hash 应用场景</h2><p>这个是类似 <strong>Map</strong> 的一种结构，这个一般就是可以将结构化的数据，比如一个对象（前提是<strong>这个对象没嵌套其他的对象</strong>）给缓存在 <strong>Redis</strong> 里，然后每次读写缓存的时候，可以就操作 <strong>Hash</strong> 里的<strong>某个字段</strong>。</p>
<p>但是这个的场景其实还是多少单一了一些，因为现在很多对象都是比较复杂的，比如你的商品对象可能里面就包含了很多属性，其中也有对象。我自己使用的场景用得不是那么多。</p>
<h2 id="List-应用场景"><a href="#List-应用场景" class="headerlink" title="List 应用场景"></a>List 应用场景</h2><p><strong>List</strong> 是有序列表，这个还是可以玩儿出很多花样的。</p>
<p>比如可以通过 <strong>List</strong> 存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类的东西。</p>
<p>比如可以通过 <strong>lrange</strong> 命令，读取某个闭区间内的元素，可以基于 <strong>List</strong> 实现分页查询，这个是很棒的一个功能，基于 <strong>Redis</strong> 实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西，性能高，就一页一页走。</p>
<p>比如可以搞个简单的消息队列，从 <strong>List</strong> 头怼进去，从 <strong>List</strong> 屁股那里弄出来。</p>
<p><strong>List</strong>本身就是我们在开发过程中比较常用的数据结构了，热点数据更不用说了。</p>
<ul>
<li><p><strong>消息队列：Redis</strong>的链表结构，可以轻松实现阻塞队列，可以使用左进右出的命令组成来完成队列的设计。比如：数据的生产者可以通过<strong>Lpush</strong>命令从左边插入数据，多个数据消费者，可以使用<strong>BRpop</strong>命令阻塞的“抢”列表尾部的数据。</p>
</li>
<li><p>文章列表或者数据分页展示的应用。</p>
<p>比如，我们常用的博客网站的文章列表，当用户量越来越多时，而且每一个用户都有自己的文章列表，而且当文章多时，都需要分页展示，这时可以考虑使用<strong>Redis</strong>的列表，列表不但有序同时还支持按照范围内获取元素，可以完美解决分页查询功能。大大提高查询效率。</p>
</li>
</ul>
<h2 id="Set应用场景"><a href="#Set应用场景" class="headerlink" title="Set应用场景"></a>Set应用场景</h2><p><strong>Set</strong> 是无序集合，会自动去重的那种。</p>
<p>直接基于 <strong>Set</strong> 将系统里需要去重的数据扔进去，自动就给去重了，如果你需要对一些数据进行快速的全局去重，你当然也可以基于 <strong>JVM</strong> 内存里的 <strong>HashSet</strong> 进行去重，但是如果你的某个系统部署在多台机器上呢？得基于<strong>Redis</strong>进行全局的 <strong>Set</strong> 去重。</p>
<p>可以基于 <strong>Set</strong> 玩儿交集、并集、差集的操作，比如交集吧，我们可以把两个人的好友列表整一个交集，看看俩人的共同好友是谁？对吧。</p>
<p>反正这些场景比较多，因为对比很快，操作也简单，两个查询一个<strong>Set</strong>搞定。</p>
<h2 id="Sorted-Set-应用场景"><a href="#Sorted-Set-应用场景" class="headerlink" title="Sorted Set 应用场景"></a>Sorted Set 应用场景</h2><p><strong>Sorted set</strong> 是排序的 <strong>Set</strong>，去重但可以排序，写进去的时候给一个分数，自动根据分数排序。</p>
<p>有序集合的使用场景与集合类似，但是set集合不是自动有序的，而<strong>Sorted set</strong>可以利用分数进行成员间的排序，而且是插入时就排序好。所以当你需要一个有序且不重复的集合列表时，就可以选择<strong>Sorted set</strong>数据结构作为选择方案。</p>
<ul>
<li><p>排行榜：有序集合经典使用场景。例如视频网站需要对用户上传的视频做排行榜，榜单维护可能是多方面：按照时间、按照播放量、按照获得的赞数等。</p>
</li>
<li><p>用<strong>Sorted Sets</strong>来做带权重的队列，比如普通消息的score为1，重要消息的score为2，然后工作线程可以选择按score的倒序来获取工作任务。让重要的任务优先执行。</p>
<p>微博热搜榜，就是有个后面的热度值，前面就是名称</p>
</li>
</ul>
<h2 id="Redis使用场景"><a href="#Redis使用场景" class="headerlink" title="Redis使用场景"></a>Redis使用场景</h2><ol>
<li><p><code>计数器</code></p>
<p>可以对 String 进行自增自减运算，从而实现计数器功能。Redis 这种内存型数据库的读写性能非常高，很适合存储频繁读写的计数量。</p>
</li>
<li><p><code>缓存</code></p>
<p>将热点数据放到内存中，设置内存的最大使用量以及淘汰策略来保证缓存的命中率。</p>
</li>
<li><p><code>会话缓存</code></p>
<p>可以使用 Redis 来统一存储多台应用服务器的会话信息。当应用服务器不再存储用户的会话信息，也就不再具有状态，一个用户可以请求任意一个应用服务器，从而更容易实现高可用性以及可伸缩性。</p>
</li>
<li><p><code>全页缓存</code></p>
<p>除基本的会话token之外，Redis还提供很简便的FPC平台。以Magento为例，Magento提供一个插件来使用Redis作为全页缓存后端。此外，对WordPress的用户来说，Pantheon有一个非常好的插件 wp-redis，这个插件能帮助你以最快速度加载你曾浏览过的页面。</p>
</li>
<li><p><code>查找表</code></p>
<p>例如 DNS 记录就很适合使用 Redis 进行存储。查找表和缓存类似，也是利用了 Redis 快速的查找特性。但是查找表的内容不能失效，而缓存的内容可以失效，因为缓存不作为可靠的数据来源。</p>
</li>
<li><p><code>消息队列(发布/订阅功能)</code></p>
<p>List 是一个双向链表，可以通过 lpush 和 rpop 写入和读取消息。不过最好使用 Kafka、RabbitMQ 等消息中间件。</p>
</li>
<li><p><code>分布式锁实现</code></p>
<p>在分布式场景下，无法使用单机环境下的锁来对多个节点上的进程进行同步。可以使用 Redis 自带的 SETNX 命令实现分布式锁，除此之外，还可以使用官方提供的 RedLock 分布式锁实现。</p>
</li>
<li><p>其他</p>
<p>Set 可以实现交集、并集等操作，从而实现共同好友等功能。ZSet 可以实现有序性操作，从而实现排行榜等功能。</p>
</li>
</ol>
<h2 id="高级用法"><a href="#高级用法" class="headerlink" title="高级用法"></a>高级用法</h2><p> <strong>Bitmap</strong> :</p>
<p>位图是支持按 bit 位来存储信息，可以用来实现 <strong>布隆过滤器（BloomFilter）</strong>；</p>
<p> <strong>HyperLogLog:</strong></p>
<p>供不精确的去重计数功能，比较适合用来做大规模数据的去重统计，例如统计 UV；</p>
<p> <strong>Geospatial:</strong></p>
<p>可以用来保存地理位置，并作位置距离计算或者根据半径计算位置等。有没有想过用Redis来实现附近的人？或者计算最优地图路径？</p>
<p>这三个其实也可以算作一种数据结构，不知道还有多少朋友记得，我在梦开始的地方，Redis基础中提到过，你如果只知道五种基础类型那只能拿60分，如果你能讲出高级用法，那就觉得你<strong>有点东西</strong>。</p>
<p> <strong>pub/sub：</strong></p>
<p>功能是订阅发布功能，可以用作简单的消息队列。</p>
<p> <strong>Pipeline：</strong></p>
<p>可以批量执行一组指令，一次性返回全部结果，可以减少频繁的请求应答。</p>
<p> <strong>Lua：</strong></p>
<p><strong>Redis</strong> 支持提交 <strong>Lua</strong> 脚本来执行一系列的功能。</p>
<p>秒杀场景经常使用这个东西，讲道理有点香，利用他的原子性。</p>
<p> <strong>事务：</strong></p>
<p>最后一个功能是事务，但 <strong>Redis</strong> 提供的不是严格的事务，<strong>Redis</strong> 只保证串行执行命令，并且能保证全部执行，但是执行命令失败时并不会回滚，而是会继续执行下去。</p>
<h2 id="Redis持久化"><a href="#Redis持久化" class="headerlink" title="Redis持久化"></a>Redis持久化</h2><p>Redis是一个支持持久化的内存数据库，通过持久化机制把内存中的数据同步到硬盘文件来保证数据持久化。当Redis重启后通过把硬盘文件重新加载到内存，就能达到恢复数据的目的。</p>
<p>持久化方式：</p>
<ul>
<li>快照：1. MySQL dump 2. redis RDB</li>
<li>写日志：1. MySQL binlog  2. Hbase Hlog  3. Redis AOF </li>
</ul>
<h2 id="RDB-–-内存快照（宕机快速恢复）"><a href="#RDB-–-内存快照（宕机快速恢复）" class="headerlink" title="RDB – 内存快照（宕机快速恢复）"></a>RDB – 内存快照（宕机快速恢复）</h2><p>RDB 是 Redis DataBase 的缩写，是Redis默认的持久化方式。按照一定的时间周期策略把内存的数据以快照的形式保存到硬盘的二进制文件。即Snapshot快照存储，对应产生的数据文件为<code>dump.rdb</code>，通过配置文件中的save参数来定义快照的周期。（ 快照可以是其所表示的数据的一个副本，也可以是数据的一个复制品）</p>
<p>和 AOF 相比，RDB 记录的是某一时刻的数据，并不是操作，所以，在做数据恢复时，我们可以直接把 RDB 文件读入内存，很快地完成恢复。</p>
<p>Redis 的数据都在内存中，为了提供所有数据的可靠性保证，它执行的是全量快照，也就是说，把内存中的所有数据都记录到磁盘中。</p>
<h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p>Redis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave。</p>
<blockquote>
<p>save：在主线程中执行，会导致阻塞.</p>
<p>bgsave：创建一个子进程，专门用于写入 RDB 文件，避免了主线程的阻塞，这也是 Redis RDB 文件生成的默认配置。</p>
</blockquote>
<p>redis会单独创建（fork）一个与当前进程一模一样的子进程进行持久化，这个子进程的所有数据（变量，环境变量，程序设计器）都和原进程一模一样。会先将数据写入到一个临时文件中，待持久化结束后，再用这个临时文件替换上次持久化好的文件，整个过程中主进程不进行任何io操作，这保证极高的性能。</p>
<p>为什么要fork一个子进程：因为redis是单进程的，同一时刻只能做一件事，所以fork子进程去持久化</p>
<h3 id="快照时数据能修改吗"><a href="#快照时数据能修改吗" class="headerlink" title="快照时数据能修改吗?"></a>快照时数据能修改吗?</h3><p>Redis 就会借助操作系统提供的写时复制技术（Copy-On-Write, COW），在执行快照的同时，正常处理写操作。</p>
<p>简单来说，bgsave 子进程是由主线程 fork 生成的，可以共享主线程的所有内存数据。bgsave 子进程运行后，开始读取主线程的内存数据，并把它们写入 RDB 文件。</p>
<p>此时，如果主线程对这些数据也都是读操作（例如图中的键值对 A），那么，主线程和 bgsave 子进程相互不影响。但是，如果主线程要修改一块数据（例如图中的键值对 C），那么，这块数据就会被复制一份，生成该数据的副本。然后，bgsave 子进程会把这个副本数据写入 RDB 文件，而在这个过程中，主线程仍然可以直接修改原来的数据。</p>
<p><img src="/images/redis-24.jpg" alt="redis-1"></p>
<p>这既保证了快照的完整性，也允许主线程同时对数据进行修改，避免了对正常业务的影响。</p>
<h3 id="增加快照"><a href="#增加快照" class="headerlink" title="增加快照"></a>增加快照</h3><p>虽然 bgsave 执行时不阻塞主线程，但是，如果频繁地执行全量快照，也会带来两方面的开销。</p>
<blockquote>
<p>一方面，频繁将全量数据写入磁盘，会给磁盘带来很大压力，多个快照竞争有限的磁盘带宽，前一个快照还没有做完，后一个又开始做了，容易造成恶性循环。</p>
<p>另一方面，bgsave 子进程需要通过 fork 操作从主线程创建出来。虽然，子进程在创建后不会再阻塞主线程，但是，fork 这个创建过程本身会阻塞主线程，而且主线程的内存越大，阻塞时间越长。如果频繁 fork 出 bgsave 子进程，这就会频繁阻塞主线程了。</p>
</blockquote>
<p>RDB采用增量快照，就是指，做了一次全量快照后，后续的快照只对修改的数据进行快照记录，这样可以避免每次全量快照的开销。</p>
<p>在第一次做完全量快照后，T1 和 T2 时刻如果再做快照，我们只需要将被修改的数据写入快照文件就行。但是，这么做的前提是，我们需要记住哪些数据被修改了。它需要我们使用额外的元数据信息去记录哪些数据被修改了，这会带来额外的空间开销问题。如下图所示：</p>
<p><img src="/images/redis-25.jpg" alt="redis-1"></p>
<p>虽然跟 AOF 相比，快照的恢复速度快，但是，快照的频率不好把握，如果频率太低，两次快照间一旦宕机，就可能有比较多的数据丢失。如果频率太高，又会产生额外开销。</p>
<h3 id="什么时候fork子进程（触发RDB持久化机制）"><a href="#什么时候fork子进程（触发RDB持久化机制）" class="headerlink" title="什么时候fork子进程（触发RDB持久化机制）"></a>什么时候fork子进程（触发RDB持久化机制）</h3><ol>
<li><p>shutdown时，如果没有开启aof会触发</p>
</li>
<li><p>配置文件中</p>
</li>
</ol>
<p>指定多长时间内，多少次更新操作，就将数据同步到数据文件，可以多个条件配合。</p>
<p>下面表示900秒（15分钟内）有一个更改，300秒内有10个更改以及60秒内有10000个更改就会触发</p>
<p><img src="/images/redis-13.png" alt="redis-1"></p>
<ol start="3">
<li>执行命令save或者bgsave</li>
</ol>
<p><code>save</code>命令只管保存，其他不管，全部阻塞，save是使用主进程去持久化，此时是不能够操作redis的，它是一个同步操作。</p>
<p><code>bgsave</code>命令redis会在后台异步进行持久化，过程是会fork一个子进程，这个进程再创建RDB文件</p>
<table>
<thead>
<tr>
<th>命令</th>
<th>save</th>
<th>bgsave</th>
</tr>
</thead>
<tbody><tr>
<td>IO类型</td>
<td>同步</td>
<td>异步</td>
</tr>
<tr>
<td>阻塞？</td>
<td>是</td>
<td>是（阻塞发生在fork，redis内存越大耗时越长）</td>
</tr>
<tr>
<td>复杂度</td>
<td>O(n)</td>
<td>O(n)</td>
</tr>
<tr>
<td>优点</td>
<td>不会消耗额外内存</td>
<td>不阻塞客户端命令</td>
</tr>
<tr>
<td>缺点</td>
<td>阻塞客户端命令</td>
<td>需要fork消耗内存</td>
</tr>
</tbody></table>
<h3 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h3><p>他会生成多个数据文件，每个数据文件分别都代表了某一时刻<strong>Redis</strong>里面的数据，这种方式，有没有觉得很适合做<strong>冷备</strong>，完整的数据运维设置定时任务，定时同步到远端的服务器，比如阿里的云服务，这样一旦线上挂了，你想恢复多少分钟之前的数据，就去远端拷贝一份之前的数据就好了。</p>
<p><strong>RDB</strong>对<strong>Redis</strong>的性能影响非常小，是因为在同步数据的时候他只是<strong>fork</strong>了一个子进程去做持久化的，而且他在数据恢复的时候速度比<strong>AOF</strong>来的快。</p>
<p><strong>RDB</strong>都是快照文件，都是默认五分钟甚至更久的时间才会生成一次，这意味着你这次同步到下次同步这中间五分钟的数据都很可能全部丢失掉。<strong>AOF</strong>则最多丢一秒的数据，<strong>数据完整性</strong>上高下立判。</p>
<p>还有就是<strong>RDB</strong>在生成数据快照的时候，如果文件很大，客户端可能会暂停几毫秒甚至几秒，你公司在做秒杀的时候他刚好在这个时候<strong>fork</strong>了一个子进程去生成一个大快照，那就出大问题了。</p>
<h2 id="AOF-—-避免数据丢失"><a href="#AOF-—-避免数据丢失" class="headerlink" title="AOF — 避免数据丢失"></a>AOF — 避免数据丢失</h2><p>说到日志，我们比较熟悉的是数据库的写前日志（Write Ahead Log, WAL），也就是说，在实际写数据前，先把修改的数据记到日志文件中，以便故障时进行恢复。不过，AOF 日志正好相反，它是写后日志，“写后”的意思是 Redis 是先执行命令，把数据写入内存，然后才记录日志。</p>
<p>那 AOF 为什么要先执行命令再记日志呢？要回答这个问题，我们要先知道 AOF 里记录了什么内容。传统数据库的日志，例如 redo log（重做日志），记录的是修改后的数据，而 AOF 里记录的是 Redis 收到的每一条命令，这些命令是以文本形式保存的。</p>
<p>我们以 Redis 收到“set testkey testvalue”命令后记录的日志为例，看看 AOF 日志的内容。其中，“*3”表示当前命令有三个部分，每部分都是由“$+数字”开头，后面紧跟着具体的命令、键或值。这里，“数字”表示这部分中的命令、键或值一共有多少字节。例如，“$3 set”表示这部分有 3 个字节，也就是“set”命令。</p>
<p><img src="/images/redis-20.jpg" alt="redis-6"></p>
<p>但是，为了避免额外的检查开销，Redis 在向 AOF 里面记录日志的时候，并不会先去对这些命令进行语法检查。所以，如果先记日志再执行命令的话，日志中就有可能记录了错误的命令，Redis 在使用日志恢复数据时，就可能会出错。而写后日志这种方式，就是先让系统执行命令，只有命令能执行成功，才会被记录到日志中，否则，系统就会直接向客户端报错。所以，Redis 使用写后日志这一方式的一大好处是，可以避免出现记录错误命令的情况。</p>
<p>除此之外，AOF 还有一个好处：它是在命令执行后才记录日志，所以不会阻塞当前的写操作</p>
<p><strong>AOF</strong> 机制对每条写入命令作为日志，以 <strong>append-only</strong> 的模式写入一个日志文件中，因为这个模式是只追加的方式，所以没有任何磁盘寻址的开销，所以很快，有点像Mysql中的<strong>binlog</strong>。</p>
<p>Redis会将每一个收到的写<code>命令</code>都通过Write函数追加到文件最后，类似于MySQL的binlog。当Redis重启是会通过重新执行文件中保存的写命令来在内存中重建整个数据库的内容。对应产生的数据库文件为<code>appendonly.aof</code></p>
<p>上面redis配置文件里触发持久化最少也要60秒，但是如果小于60秒退出数据就会丢失。AOF就是为了解决这个问题。AOF是不会超过两秒，每秒钟保存一次数据。</p>
<p>AOF保存的是<code>命令</code>字符串，还有协议。</p>
<h3 id="AOF三种写回策略"><a href="#AOF三种写回策略" class="headerlink" title="AOF三种写回策略"></a>AOF三种写回策略</h3><p>首先，如果刚执行完一个命令，还没有来得及记日志就宕机了，那么这个命令和相应的数据就有丢失的风险。如果此时 Redis 是用作缓存，还可以从后端数据库重新读入数据进行恢复，但是，如果 Redis 是直接用作数据库的话，此时，因为命令没有记入日志，所以就无法用日志进行恢复了。</p>
<p>其次，AOF 虽然避免了对当前命令的阻塞，但可能会给下一个操作带来阻塞风险。这是因为，AOF 日志也是在主线程中执行的，如果在把日志文件写入磁盘时，磁盘写压力大，就会导致写盘很慢，进而导致后续的操作也无法执行了。</p>
<p>仔细分析的话，就会发现，这两个风险都是和 AOF 写回磁盘的时机相关的。这也就意味着，如果我们能够控制一个写命令执行完后 AOF 日志写回磁盘的时机，这两个风险就解除了。</p>
<p>其实，对于这个问题，AOF 机制给我们提供了三个选择，也就是 AOF 配置项 appendfsync 的三个可选值。</p>
<blockquote>
<p>Always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘；</p>
<p>Everysec，每秒写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘；</p>
<p>No，操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。</p>
</blockquote>
<p>同步写回”可以做到基本不丢数据，但是它在每一个写命令后都有一个慢速的落盘操作，不可避免地会影响主线程性能。</p>
<p>虽然“操作系统控制的写回”在写完缓冲区后，就可以继续执行后续的命令，但是落盘的时机已经不在 Redis 手中了，只要 AOF 记录没有写回磁盘，一旦宕机对应的数据就丢失了。</p>
<p>“每秒写回”采用一秒写回一次的频率，避免了“同步写回”的性能开销，虽然减少了对系统性能的影响，但是如果发生宕机，上一秒内未落盘的命令操作仍然会丢失。所以，这只能算是，在避免影响主线程性能和避免数据丢失两者间取了个折中。</p>
<p><img src="/images/redis-21.jpg" alt="redis-6"></p>
<h3 id="AOF重写机制"><a href="#AOF重写机制" class="headerlink" title="AOF重写机制"></a>AOF重写机制</h3><p>当aof增长到一定大小的时候Redis能够调用bgrewriteaof对日志文件进行重写。</p>
<p>例如：如果新建了数据，然后又删除了，这时这两条命令就不需要保存了，或者set同一个key多次，那我们只需要保存最后一次的命令即可</p>
<p><img src="/images/redis-22.jpg" alt="redis-6"></p>
<p>AOF重写机制的目的是：减少磁盘占用量，加速恢复速度</p>
<p>AOF重写的两种方式：</p>
<ul>
<li>bgrewriteaof命令。同样redis会fork一个子进程进行重写，<code>注意：fork是同步操作会阻塞redis</code></li>
<li>AOF重写配置，见下图</li>
</ul>
<p><img src="/images/redis-6.png" alt="redis-6"></p>
<p>auto-aof-rewrite-min-size：AOF文件重写需要的尺寸</p>
<p>auto-aof-rewrite-percentage：AOF文件增长率</p>
<p>次执行重写时，主线程 fork 出后台的 bgrewriteaof 子进程。此<br>时，fork 会把主线程的内存拷贝一份给 bgrewriteaof 子进程，这里面就包含了数据库的最新数据。然后，bgrewriteaof 子进程就可以在不影响主线程的情况下，逐一把拷贝的数据写成操作，记入重写日志。</p>
<p>因为主线程未阻塞，仍然可以处理新来的操作。此时，如果有写操作，对于正在使用的 AOF 日志，Redis 会把这个操作写到它的缓冲区。这样一来，即使宕机了，这个 AOF 日志的操作仍然是齐全的，可以用于恢复。</p>
<p>对于新的 AOF 重写日志。这个操作也会被写到重写日志的缓冲区。这<br>样，重写日志也不会丢失最新的操作。等到拷贝数据的所有操作记录重写完成后，重写日志记录的这些最新操作也会写入新的 AOF 文件，以保证数据库最新状态的记录。此时，我们就可以用新的 AOF 文件替代旧文件了。</p>
<p><img src="/images/redis-23.jpg" alt="redis-6"></p>
<p>总结来说，每次 AOF 重写时，Redis 会先执行一个内存拷贝，用于重写；然后，使用两个日志保证在重写过程中，新写入的数据不会丢失。而且，因为 Redis 采用额外的线程进行数据重写，所以，这个过程并不会阻塞主线程。</p>
<h3 id="AOF-重写过程中有没有其他潜在的阻塞风险？"><a href="#AOF-重写过程中有没有其他潜在的阻塞风险？" class="headerlink" title="AOF 重写过程中有没有其他潜在的阻塞风险？"></a>AOF 重写过程中有没有其他潜在的阻塞风险？</h3><p>风险一：Redis 主线程 fork 创建 bgrewriteaof 子进程时，内核需要创建用于管理子进程的相关数据结构，这些数据结构在操作系统中通常叫作进程控制块（Process Control<br>Block，简称为 PCB）。内核要把主线程的 PCB 内容拷贝给子进程。这个创建和拷贝过程由内核执行，是会阻塞主线程的。而且，在拷贝过程中，子进程要拷贝父进程的页表，这个过程的耗时和 Redis 实例的内存大小有关。如果 Redis 实例内存大，页表就会大，fork 执行时间就会长，这就会给主线程带来阻塞风险。</p>
<p>风险二：bgrewriteaof 子进程会和主线程共享内存。当主线程收到新写或修改的操作时，主线程会申请新的内存空间，用来保存新写或修改的数据，如果操作的是 bigkey，也就是数据量大的集合类型数据，那么，主线程会因为申请大空间而面临阻塞风险。因为操作系统在分配内存空间时，有查找和锁的开销，这就会导致阻塞。</p>
<h3 id="AOF追加阻塞"><a href="#AOF追加阻塞" class="headerlink" title="AOF追加阻塞"></a>AOF追加阻塞</h3><p><img src="/images/redis-14.png" alt="redis-14"></p>
<h3 id="优缺点-1"><a href="#优缺点-1" class="headerlink" title="优缺点"></a>优缺点</h3><p>上面提到了，<strong>RDB</strong>五分钟一次生成快照，但是<strong>AOF</strong>是一秒一次去通过一个后台的线程<code>fsync</code>操作，那最多丢这一秒的数据。</p>
<p><strong>AOF</strong>在对日志文件进行操作的时候是以<code>append-only</code>的方式去写的，他只是追加的方式写数据，自然就少了很多磁盘寻址的开销了，写入性能惊人，文件也不容易破损。</p>
<p><strong>AOF</strong>的日志是通过一个叫<strong>非常可读</strong>的方式记录的，这样的特性就适合做<strong>灾难性数据误删除</strong>的紧急恢复了，比如公司的实习生通过<strong>flushall</strong>清空了所有的数据，只要这个时候后台重写还没发生，你马上拷贝一份<strong>AOF</strong>日志文件，把最后一条<strong>flushall</strong>命令删了就完事了。</p>
<p>RDB性能消耗低，丢失数据多，速度也快。AOF性能消耗高，丢失数据少</p>
<p>一样的数据，<strong>AOF</strong>文件比<strong>RDB</strong>还要大。</p>
<p><strong>AOF</strong>开启后，<strong>Redis</strong>支持写的<strong>QPS</strong>会比<strong>RDB</strong>支持写的要低，他不是每秒都要去异步刷新一次日志嘛<strong>fsync</strong>，当然即使这样性能还是很高，我记得<strong>ElasticSearch</strong>也是这样的，异步刷新缓存区的数据去持久化，为啥这么做呢，不直接来一条怼一条呢，因为这样性能可能低到没办法用的。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><strong>redis提供了RDB持久化方案，为什么还要aof</strong></p>
<p>优化数据丢失问题，rdb会丢失最后一次快照后的数据，aof丢失不会超过两秒的数据</p>
<p><strong>如果AOF和RDB同时存在，听谁的</strong></p>
<p>AOF，两种机制全部开启的时候，Redis在重启的时候会默认使用AOF去重新构建数据，因为AOF的数据是比RDB更完整的。</p>
<p><strong>RDB 和 AOF优劣势</strong></p>
<p>AOF性能消耗高，丢失数据少，RDB性能消耗低，丢失数据多，速度也快，RDB会对数据进行压缩</p>
<p><strong>RDB</strong>对<strong>Redis</strong>的性能影响非常小，是因为在同步数据的时候他只是<strong>fork</strong>了一个子进程去做持久化的，而且他在数据恢复的时候速度比<strong>AOF</strong>来的快。</p>
<p>两种方式都可以把<strong>Redis</strong>内存中的数据持久化到磁盘上，然后再将这些数据备份到别的地方去，<strong>RDB</strong>更适合做<strong>冷备</strong>，<strong>AOF</strong>更适合做<strong>热备</strong>，比如我杭州的某电商公司有这两个数据，我备份一份到我杭州的节点，再备份一个到上海的，就算发生无法避免的自然灾害，也不会两个地方都一起挂吧，这<strong>灾备</strong>也就是<strong>异地容灾</strong>。</p>
<h3 id="两者如何选择"><a href="#两者如何选择" class="headerlink" title="两者如何选择"></a>两者如何选择</h3><p>Redis 4.0 中提出了一个混合使用 AOF 日志和内存快照的方法。简单来说，内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。</p>
<p>这样一来，快照不用很频繁地执行，这就避免了频繁 fork 对主线程的影响。而且，AOF 日志也只用记录两次快照间的操作，也就是说，不需要记录所有操作了，因此，就不会出现文件过大的情况了，也可以避免重写开销。</p>
<p>如下图所示，T1 和 T2 时刻的修改，用 AOF 日志记录，等到第二次做全量快照时，就可以清空 AOF 日志，因为此时的修改都已经记录到快照中了，恢复时就不再用日志了。</p>
<p><img src="/images/redis-26.jpg" alt="redis-14"></p>
<p>这个方法既能享受到 RDB 文件快速恢复的好处，又能享受到 AOF 只记录操作命令的简单优势，颇有点“鱼和熊掌可以兼得”的感觉，建议在实践中用起来!</p>
<p>单独用<strong>RDB</strong>你会丢失很多数据，单独用<strong>AOF</strong>，你数据恢复没<strong>RDB</strong>来的快，真出什么时候第一时间用<strong>RDB</strong>恢复，然后<strong>AOF</strong>做数据补全，冷备热备一起上，才是互联网时代一个高健壮性系统的王道。</p>
<p>注意：bgsave和bgrewriteaof会fork子进程，这是阻塞的操作，redis内存越大耗时越长</p>
<h2 id="使用缓存一般思路"><a href="#使用缓存一般思路" class="headerlink" title="使用缓存一般思路"></a>使用缓存一般思路</h2><p>缓存的作用就是让直接请求数据库的数量少一些，数据库压力小一些</p>
<p>首先去查缓存中有没有，缓存中有就直接返回，如果没有就去数据库中查，如果数据库中有，就加入到缓存中</p>
<h2 id="内存淘汰机制"><a href="#内存淘汰机制" class="headerlink" title="内存淘汰机制"></a>内存淘汰机制</h2><p><strong>Redis</strong>的过期策略，是有<strong>定期删除+惰性删除</strong>两种。</p>
<p>定期好理解，默认100ms就随机抽一些设置了过期时间的key，去检查是否过期，过期了就删了。</p>
<p>惰性删除，我不主动删，我等你来<strong>查询</strong>了我看看你过期没，过期就删了还不给你返回，没过期该怎么样就怎么样。</p>
<h2 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h2><p>使用不存在的key（在数据库没有，自然在缓存中也不会有）进行大量的高并发查询，导致缓存无法命中，每次请求都要穿透到后端数据库进行查询，数据库压力过大</p>
<p>解决方案：</p>
<ul>
<li>将空值缓存起来</li>
<li>布隆过滤器</li>
</ul>
<p>如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟(设置过期时间就是防止我们真的在数据库中存储了这个值就会导致一致性问题)。通过这个直接设置的默认值存放到缓存，这样第二次到缓冲中获取就有值了，而不会继续访问数据库，这种办法最简单粗暴。但是这个用个问题，如果是黑客攻击，可能会采用uuid去获取，这样会导致无法解决穿透到数据库获取数据的问题，所以我们一般使用布隆过滤器解决。</p>
<p><strong>布隆过滤器</strong>：将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。通过一定的错误率换取空间（因为布隆过滤器里面数据避免太多，节约内存占用），降低错误率的方法有两种，增大数组，增加hash函数的个数</p>
<h2 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h2><p>缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没有读到数据，又同时去数据库中取数据，引发数据库压力过大</p>
<p>一般来说不用处理，公司业务中也很少有那种并发量，即使有，只要数据库没有崩，我们就不用处理。</p>
<p>解决方案：</p>
<ul>
<li>互斥锁，如果项目不会多部署使用jvm锁，如果项目多部署则使用分布式锁（加锁之后第一个请求就会被锁住，然后就会把这个数据加入缓存，这样后面的请求就会在缓存中拿到了，不必请求数据库了）</li>
<li>二级缓存，再加一个redis缓存和当前缓存一模一样，相当于主从复制。</li>
</ul>
<h2 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h2><p>缓存服务器重启或大量缓存集中在某一时间内失效</p>
<p>所有原本应该访问缓存的请求都去查询数据库了，而对数据库CPU和内存造成巨大压力</p>
<p>解决方案：</p>
<ul>
<li>搭建高可用集群，保证机器高可用</li>
<li>对不同的数据使用不同的实效时间，甚至对相同的数据不同的请求也使用不同的失效时间</li>
<li>大多数系统设计者考虑用加锁（ 最多的解决方案）或者队列的方式保证来保证不会有大量的线程对数据库一次性进行读写，从而避免失效时大量的并发请求落到底层存储系统上</li>
</ul>
<h2 id="布隆过滤器"><a href="#布隆过滤器" class="headerlink" title="布隆过滤器"></a>布隆过滤器</h2><p>就是引入了k(k&gt;1)k(k&gt;1)个相互独立的哈希函数，保证在给定的空间、误判率下，完成元素判重的过程。</p>
<p>它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。</p>
<p>Bloom-Filter算法的核心思想就是利用多个不同的Hash函数来解决“冲突”。</p>
<p>Hash存在一个冲突（碰撞）的问题，用同一个Hash得到的两个URL的值有可能相同。为了减少冲突，我们可以多引入几个Hash，如果通过其中的一个Hash值我们得出某元素不在集合中，那么该元素肯定不在集合中。只有在所有的Hash函数告诉我们该元素在集合中时，才能确定该元素存在于集合中。这便是Bloom-Filter的基本思想。</p>
<p>Bloom-Filter一般用于在大数据量的集合中判定某元素是否存在。</p>
<h2 id="缓存与数据库数据一致性"><a href="#缓存与数据库数据一致性" class="headerlink" title="缓存与数据库数据一致性"></a>缓存与数据库数据一致性</h2><p>如果要更新某条数据，该怎么更新？</p>
<p>先更新数据库，再更新缓存：如果更新缓存失败了怎么就导致一致性问题</p>
<p><img src="/images/redis-8.png" alt="redis-8"></p>
<p>如果是两个线程同时去更新数据库，就会有下面这个问题：线程A更新字段数据为A，线程B更新字段数据为B，本应最终结果是B，但是由于B比A更早更新了缓存，这就导致缓存中的数据是A而数据库中是B</p>
<p><img src="/images/redis-9.png" alt="redis-9"></p>
<p>解决方案：先删除缓存，再修改数据库，如果数据库修改失败了，那么数据库中是旧数据，缓存中是空的，那么数据不会不一致。因为读的时候缓存没有，则读数据库中旧数据，然后更新到缓存中</p>
<p>但是如果这个过程中有查询数据，那正好在缓存中查不到，就去数据库中查，然后把缓存更新了，这样缓存就没有被删除</p>
<p><img src="/images/redis-10.png" alt="redis-10"></p>
<p>解决方案一：延时双删，但是只能大概率解决，第5步需要做延时，要等查询完之后再把缓存删除</p>
<p><img src="/images/redis-11.png" alt="redis-11"></p>
<p>解决方案二：加队列，因为上图中3和5的顺序不能保证，只是加个延时并不一定能解决，所以加队列</p>
<p><img src="/images/redis-12.png" alt="redis-12"></p>
<h2 id="单线程的redis为什么这么快"><a href="#单线程的redis为什么这么快" class="headerlink" title="单线程的redis为什么这么快"></a>单线程的redis为什么这么快</h2><p><strong>Redis</strong>采用的是基于内存的采用的是单进程单线程模型的 KV 数据库，由C语言编写，官方提供的数据是可以达到100000+的<strong>QPS（每秒内查询次数）</strong></p>
<ol>
<li>存内存操作：完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。它的数据存在内存中，类似于<strong>HashMap</strong>，<strong>HashMap</strong>的优势就是查找和操作的时间复杂度都是O(1)；</li>
<li>数据结构简单，对数据操作也简单，<strong>Redis</strong>中的数据结构是专门进行设计的</li>
<li>单线程操作：采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 <strong>CPU</strong>，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；</li>
<li>使用多路I/O复用模型，非阻塞IO；</li>
<li>使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，<strong>Redis</strong>直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求；</li>
</ol>
<p>上下文切换：比如你看一本英文书，你看到第十页发现有个单词不会读，你加了个书签，然后去查字典，过了一会你又回来继续从书签那里读，ok到目前为止没啥问题。</p>
<p>如果是你一个人读肯定没啥问题，但是你去查的时候，别的小伙伴好奇你在看啥他就翻了一下你的书，然后溜了，哦豁，你再看的时候就发现书不是你看的那一页了。为啥会线程不安全，就是因为你一个人怎么看都没事，但是人多了换来换去的操作一本书数据就乱了。道理是一样的。</p>
<h2 id="Redis变慢的场景"><a href="#Redis变慢的场景" class="headerlink" title="Redis变慢的场景"></a>Redis变慢的场景</h2><ol>
<li>使用复杂度过高的命令或一次查询全量数据；</li>
<li>操作 bigkey；</li>
<li>大量 key 集中过期；3.</li>
<li>内存达到 maxmemory；</li>
<li>客户端使用短连接和 Redis 相连；</li>
<li>当 Redis 实例的数据量大时，无论是生成 RDB，还是 AOF 重写，都会导致 fork 耗时严重；</li>
<li>AOF 的写回策略为 always，导致每个操作都要同步刷回磁盘；</li>
<li>Redis 实例运行机器的内存不足，导致 swap 发生，Redis 需要到 swap 分区读取数据；</li>
<li>进程绑定 CPU 不合理；</li>
<li>Redis 实例运行机器上开启了透明内存大页机制；</li>
<li>网卡压力过大。</li>
</ol>
<h2 id="Redis架构模式"><a href="#Redis架构模式" class="headerlink" title="Redis架构模式"></a>Redis架构模式</h2><h3 id="主从复制"><a href="#主从复制" class="headerlink" title="主从复制"></a>主从复制</h3><p><img src="/images/redis-27.jpg" alt="redis-3"></p>
<p><strong>主从库间网络断了怎么办？</strong></p>
<p><img src="/images/redis-31.jpg" alt="redis-31"></p>
<p>在 Redis 2.8 之前，如果主从库在命令传播时出现了网络闪断，那么，从库就会和主库重新进行一次全量复制，开销非常大。从 Redis 2.8 开始，网络断了之后，主从库会采用增量复制的方式继续同步。听名字大概<br>就可以猜到它和全量复制的不同：全量复制是同步所有数据，而增量复制只会把主从库网络断连期间主库收到的命令，同步给从库。</p>
<p>当主从库断连后，主库会把断连期间收到的写操作命令，写入 replication buffer，同时也会把这些操作命令也写入 repl_backlog_buffer 这个缓冲区。</p>
<p>repl_backlog_buffer 是一个环形缓冲区，主库会记录自己写到的位置，从库则会记录自己已经读到的位置。</p>
<p>刚开始的时候，主库和从库的写读位置在一起，这算是它们的起始位置。随着主库不断接收新的写操作，它在缓冲区中的写位置会逐步偏离起始位置，我们通常用偏移量来衡量这个偏移距离的大小，对主库来说，对应的偏移量就是 master_repl_offset。主库接收的新写操作越多，这个值就会越大。</p>
<p>同样，从库在复制完写操作命令后，它在缓冲区中的读位置也开始逐步偏移刚才的起始位置，此时，从库已复制的偏移量 slave_repl_offset 也在不断增加。正常情况下，这两个偏移量基本相等。</p>
<p><img src="/images/redis-30.jpg" alt="redis-3"></p>
<p>主从库的连接恢复之后，从库首先会给主库发送 psync 命令，并把自己当前的 slave_repl_offset 发给主库，主库会判断自己的master_repl_offset 和 slave_repl_offset 之间的差距。</p>
<p>在网络断连阶段，主库可能会收到新的写操作命令，所以，一般来说，master_repl_offset 会大于 slave_repl_offset。此时，主库只用把 master_repl_offset 和 slave_repl_offset 之间的命令操作同步给从库就行。</p>
<p>不过，有一个地方我要强调一下，因为 repl_backlog_buffer 是一个环形缓冲区，所以在缓冲区写满后，主库会继续写入，此时，就会覆盖掉之前写入的操作。如果从库的读取速度比较慢，就有可能导致从库还未读取的操作被主库新写的操作覆盖了，这会导致主从库间的数据不一致。</p>
<p>因此，我们要想办法避免这一情况，一般而言，我们可以调整repl_backlog_size 这个参数。这个参数和所需的缓冲空间大小有关。缓冲空间的计算公式是：缓冲空间大小 = 主库写入命令速度 * 操作大小 - 主从库间网络传输命令速度 * 操作大小。在实际应用中，考虑到可能存在一些突发的请求压力，我们通常需要把这个缓冲空间扩大一倍，即 repl_backlog_size = 缓冲空间大小 * 2，这也就是repl_backlog_size 的最终值。</p>
<p><strong>主从复制优缺点</strong></p>
<p>特点：</p>
<ul>
<li>master/slave 角色</li>
<li>master/slave 数据相同</li>
<li>降低 master 读压力，再转交从库</li>
<li>读写分离，容灾备份</li>
<li>主专门写数据，从专门读数据</li>
</ul>
<hr>
<p>缺点：</p>
<ul>
<li>无法保证高可用</li>
<li>没有解决 master 写的压力</li>
<li>主机挂了不能自动切换从机，需要手动切换（哨兵解决）</li>
</ul>
<p><strong>主从之间数据的同步</strong></p>
<p>当我们启动多个 Redis 实例的时候，它们相互之间就可以通过 replicaof（Redis 5.0 之前使用 slaveof）命令形成主库和从库的关系，之后会按照三个阶段完成数据的第一次同步。</p>
<p><img src="/images/redis-28.jpg" alt="image-20210124195123383"></p>
<p>第一阶段是主从库间建立连接、协商同步的过程，主要是为全量复制做准备。在这一步，从库和主库建立起连接，并告诉主库即将进行同步，主库确认回复后，主从库间就可以开始同步了。</p>
<p>具体来说，从库给主库发送 psync 命令，表示要进行数据同步，主库根据这个命令的参数来启动复制。psync 命令包含了主库的 runID 和复制进度 offset 两个参数。</p>
<blockquote>
<p>runID，是每个 Redis 实例启动时都会自动生成的一个随机 ID，用来唯一标记这个实例。当从库和主库第一次复制时，因为不知道主库的runID，所以将 runID 设为“？”。</p>
<p>offset，此时设为 -1，表示第一次复制。</p>
</blockquote>
<p>主库收到 psync 命令后，会用 FULLRESYNC 响应命令带上两个参数：主库 runID 和主库</p>
<p>目前的复制进度 offset，返回给从库。从库收到响应后，会记录下这两个参数。</p>
<p>这里有个地方需要注意，FULLRESYNC 响应表示第一次复制采用的全量复制，也就是说，主库会把当前所有的数据都复制给从库。</p>
<p>在第二阶段，主库将所有数据同步给从库。从库收到数据后，在本地完成数据加载。这个过程依赖于内存快照生成的 RDB 文件。</p>
<p>具体来说，主库执行 bgsave 命令，生成 RDB 文件，接着将文件发给从库。从库接收到 RDB 文件后，会先清空当前数据库，然后加载 RDB 文件。这是因为从库在通过 replicaof 命令开始和主库同步前，可能保存了其他数据。为了避免之前数据的影响，从库需要先把当前数据库清空。</p>
<p>在主库将数据同步给从库的过程中，主库不会被阻塞，仍然可以正常接收请求。否则，Redis 的服务就被中断了。但是，这些请求中的写操作并没有记录到刚刚生成的 RDB 文件中。为了保证主从库的数据一致性，主库会在内存中用专门的 replication buffer，记录 RDB 文件生成后收到的所有写操作。</p>
<p>最后，也就是第三个阶段，主库会把第二阶段执行过程中新收到的写命令，再发送给从库。具体的操作是，当主库完成 RDB 文件发送后，就会把此时 replication buffer 中的修改操作发给从库，从库再重新执行这些操作。这样一来，主从库就实现同步了。</p>
<hr>
<p><strong>主从级联模式分担全量复制时的主库压力</strong></p>
<p>一次全量复制中，对于主库来说，需要完成两个耗时的操作：生成 RDB 文件和传输 RDB 文件。以通过“主 - 从 - 从”模式将主库生成 RDB 和传输 RDB 的压力，以级联的方式分散到从库上。<br><img src="/images/redis-29.jpg" alt="redis-29"></p>
<h3 id="哨兵模式"><a href="#哨兵模式" class="headerlink" title="哨兵模式"></a>哨兵模式</h3><p>在主从模式下，如果从库发生故障了，客户端可以继续向主库或其他从库发送请求，进行相关的操作，但是如果主库发生故障了，那就直接会影响到从库的同步，因为从库没有相应的主库可以进行数据复制操作了。</p>
<p>而且，如果客户端发送的都是读操作请求，那还可以由从库继续提供服务，这在纯读的业务场景下还能被接受。但是，一旦有写操作请求了，按照主从库模式下的读写分离要求，需要由主库来完成写操作。此时，也没有实例可以来服务客户端的写操作请求了。</p>
<p>哨兵其实就是一个运行在特殊模式下的 Redis 进程，主从库实例运行的同时，它也在运行。哨兵主要负责的就是三个任务：监控、选主（选择主库）和通知。</p>
<p>监控是指哨兵进程在运行时，周期性地给所有的主从库发送PING 命令，检测它们是否仍然在线运行。如果从库没有在规定时间内响应哨兵的 PING 命令，哨兵就会把它标记为“下线状态”；同样，如果主库也没有在规定时间内响应哨兵的 PING 命令，哨兵就会判定主库下线，然后开始自动切换主库的流程。</p>
<p>这个流程首先是执行哨兵的第二个任务，选主。主库挂了以后，哨兵就需要从很多个从库里，按照一定的规则选择一个从库实例，把它作为新的主库。这一步完成后，现在的集群里就有了新主库。</p>
<p>然后，哨兵会执行最后一个任务：通知。在执行通知任务时，哨兵会把新主库的连接信息发给其他从库，让它们执行 replicaof 命令，和新主库建立连接，并进行数据复制。同时，哨兵会把新主库的连接信息通知给客户端，让它们把请求操作发到新主库上。</p>
<p><img src="/images/redis-32.jpg" alt="redis-4"></p>
<p>首先，我们要知道啥叫误判。很简单，就是主库实际并没有下线，但是哨兵误以为它下线了。误判一般会发生在集群网络压力较大、网络拥塞，或者是主库本身压力较大的情况下。</p>
<p>一旦哨兵判断主库下线了，就会开始选择新主库，并让从库和新主库进行数据同步，这个过程本身就会有开销，例如，哨兵要花时间选出新主库，从库也需要花时间和新主库同步。而在误判的情况下，主库本身根本就不需要进行切换的，所以这个过程的开销是没有价值的。正因为这样，我们需要判断是否有误判，以及减少误判。</p>
<p>哨兵机制通常会采用多实例组成的集群模式进行部署，这也被称为哨兵集群。引入多个哨兵实例一起来判断，就可以避免单个哨兵因为自身网络状况不好，而误判主库下线的情况。同时，多个哨兵的网络同时不稳定的概率较小，由它们一起做决策，误判率也能降低。</p>
<p>简单来说，“客观下线”的标准就是，当有 N 个哨兵实例时，最好要有 N/2 + 1 个实例判断主库为“主观下线”，才能最终判定主库为“客观下线”。这样一来，就可以减少误判的概率，也能避免误判带来的无谓的主从库切换。</p>
<p><strong>如何选定新主库？</strong><br>一般来说，我把哨兵选择新主库的过程称为“筛选 + 打分”。简单来说，我们在多个从库中，先按照一定的筛选条件，把不符合条件的从库去掉。然后，我们再按照一定的规则，给剩下的从库逐个打分，将得分最高的从库选为新主库，如下图所示：</p>
<p><img src="/images/redis-33.jpg" alt="redis-33"></p>
<p>首先来看筛选的条件。<br>一般情况下，我们肯定要先保证所选的从库仍然在线运行。不过，在选主时从库正常在线，这只能表示从库的现状良好，并不代表它就是最适合做主库的。</p>
<p>设想一下，如果在选主时，一个从库正常运行，我们把它选为新主库开始使用了。可是，很快它的网络出了故障，此时，我们就得重新选主了。这显然不是我们期望的结果。</p>
<p>所以，在选主时，除了要检查从库的当前在线状态，还要判断它之前的网络连接状态。如果从库总是和主库断连，而且断连次数超出了一定的阈值，我们就有理由相信，这个从库的网络状况并不是太好，就可以把这个从库筛掉了。</p>
<p>具体怎么判断呢？你使用配置项 down-after-milliseconds * 10。其中，down-after-milliseconds 是我们认定主从库断连的最大连接超时时间。如果在 down-after-milliseconds 毫秒内，主从节点都没有通过网络联系上，我们就可以认为主从节点断连了。如果发生断连的次数超过了 10 次，就说明这个从库的网络状况不好，不适合作为新主库。</p>
<p>好了，这样我们就过滤掉了不适合做主库的从库，完成了筛选工作。</p>
<p>接下来就要给剩余的从库打分了。我们可以分别按照三个规则依次进行三轮打分，这三个规则分别是从库优先级、从库复制进度以及从库 ID 号。只要在某一轮中，有从库得分最高，那么它就是主库了，选主过程到此结束。如果没有出现得分最高的从库，那么就继续进行下一轮。</p>
<p>第一轮：优先级最高的从库得分高。</p>
<p>用户可以通过 slave-priority 配置项，给不同的从库设置不同优先级。比如，你有两个从库，它们的内存大小不一样，你可以手动给内存大的实例设置一个高优先级。在选主时，哨兵会给优先级高的从库打高分，如果有一个从库优先级最高，那么它就是新主库了。如果从库的优先级都一样，那么哨兵开始第二轮打分。</p>
<p>第二轮：和旧主库同步程度最接近的从库得分高。</p>
<p>这个规则的依据是，如果选择和旧主库同步最接近的那个从库作为主库，那么，这个新主库上就有最新的数据。</p>
<p>如何判断从库和旧主库间的同步进度呢？</p>
<p>主从库同步时有个命令传播的过程。在这个过程中，主库会用<br>master_repl_offset 记录当前的最新写操作在repl_backlog_buffer 中的位置，而从库会用 slave_repl_offset 这个值记录当前的复制进度。</p>
<p>此时，我们想要找的从库，它的 slave_repl_offset 需要最接近 master_repl_offset。如果在所有从库中，有从库的 slave_repl_offset 最接近 master_repl_offset，那么它的得分就最高，可以作为新主库。</p>
<p>就像下图所示，旧主库的 master_repl_offset 是 1000，从库 1、2 和 3 的 slave_repl_offset 分别是 950、990 和 900，那么，从库 2 就应该被选为新主库。</p>
<p><img src="/images/redis-34.jpg" alt="redis-4"></p>
<p>当然，如果有两个从库的 slave_repl_offset 值大小是一样的（例如，从库 1 和从库 2 的 slave_repl_offset 值都是 990），我们就需要给它们进行第三轮打分了。</p>
<p>第三轮：ID 号小的从库得分高。</p>
<p>每个实例都会有一个 ID，这个 ID 就类似于这里的从库的编号。目前，Redis 在选主库时，有一个默认的规定：在优先级和复制进度都相同的情况下，ID 号最小的从库得分最高，会被选为新主库。</p>
<p>到这里，新主库就被选出来了，“选主”这个过程就完成了。</p>
<p>我们再回顾下这个流程。首先，哨兵会按照在线状态、网络状态，筛选过滤掉一部分不符合要求的从库，然后，依次按照优先级、复制进度、ID 号大小再对剩余的从库进行打分，只要有得分最高的从库出现，就把它选为新主库。</p>
<p><img src="/images/redis-4.png" alt="redis-4"></p>
<p>Redis sentinel 是一个分布式系统中监控 redis 主从服务器，并在主服务器下线时自动进行故障转移。其中三个特性：</p>
<ul>
<li>监控（Monitoring）：  Sentinel 会不断地检查你的主服务器和从服务器是否运作正常。</li>
<li>提醒（Notification）： 当被监控的某个 Redis 服务器出现问题时， Sentinel 可以通过 API 向管理员或者其他应用程序发送通知。</li>
<li>自动故障迁移（Automatic failover）： 当一个主服务器不能正常工作时， Sentinel 会开始一次自动故障迁移操作。</li>
</ul>
<p><strong>特点：</strong></p>
<p>优点</p>
<ul>
<li>保证高可用</li>
<li>监控各个节点</li>
<li>自动故障迁移</li>
</ul>
<p>缺点：</p>
<ul>
<li>主从模式，切换需要时间，丢数据</li>
<li>没有解决 master 写的压力</li>
</ul>
<h3 id="Redis-Cluster高可用集群"><a href="#Redis-Cluster高可用集群" class="headerlink" title="Redis Cluster高可用集群"></a>Redis Cluster高可用集群</h3><p><strong>解决单机的瓶颈</strong></p>
<p>用集群的部署方式也就是<strong>Redis cluster</strong>，并且是主从同步读写分离，类似<strong>Mysql</strong>的主从同步，<strong>Redis cluster</strong> 支撑 N 个 <strong>Redis master node</strong>，每个<strong>master node</strong>都可以挂载多个 <strong>slave node</strong>。</p>
<p>这样整个 <strong>Redis</strong> 就可以横向扩容了。如果你要支撑更大数据量的缓存，那就横向扩容更多的 <strong>master</strong> 节点，每个 <strong>master</strong> 节点就能存放更多的数据了。</p>
<p>哨兵模式下故障转移过程中整个redis服务是不可用的</p>
<p>redis cluster是由多个主从节点群组成的分布式集群</p>
<p><img src="/images/redis-5.png" alt="redis-5"></p>
<p>Redis-Cluster采用无中心结构，每个节点保存数据和整个集群状态,每个节点都和其他所有节点连接。</p>
<p><img src="/images/redis-7.png" alt="redis-7"></p>
<p>对命令的key进行crc16（hash一致性算法）算法得到一串数字，再对16384取余，结果在哪个区间（槽位）就分配给哪个集群</p>
<p>即使其中一个小集群挂了，仍然有三分之二的几率是可用的，等故障转移之后可用性全部恢复了，当然实际生产中还是要看集群的数量</p>
<p><strong>数据分片原理</strong></p>
<p>一个需求：要用 Redis 保存 5000 万个键值对，每个键值对大约是 512B，为了能快速部署并对外提供服务，我们采用云主机来运行 Redis 实例，那么，该如何选择云主机的内存容量呢？</p>
<p>我粗略地计算了一下，这些键值对所占的内存空间大约是 25GB（5000 万 *512B）。所以，当时，我想到的第一方案就是：选择一台 32GB 内存的云主机来部署 Redis。因为 32GB 的内存能保存所有数据，而且还留有 7GB，可以保证系统的正常运行。同时，我还采用 RDB 对数据做持久化，以确保 Redis 实例故障后，还能从 RDB 恢复数据。</p>
<p>但是，在使用的过程中，我发现，Redis 的响应有时会非常慢。后来，我们使用 INFO 命令查看 Redis 的latest_fork_usec 指标值（表示最近一次 fork 的耗时），结果显示这个指标值特别高，快到秒级别了。</p>
<p>这跟 Redis 的持久化机制有关系。在使用 RDB 进行持久化时，Redis 会 fork 子进程来完成，fork 操作的用时和 Redis 的数据量是正相关的，而 fork 在执行时会阻塞主线程。数据量越大，fork 操作造成的主线程阻塞的时间越长。所以，在使用 RDB 对 25GB 的数据进行持久化时，数据量较大，后台运行的子进程在 fork 创建时阻塞了主线程，于是就导致<br>Redis 响应变慢了。</p>
<p>看来，第一个方案显然是不可行的，我们必须要寻找其他的方案。这个时候，我们注意到了 Redis 的切片集群。虽然组建切片集群比较麻烦，但是它可以保存大量数据，而且对 Redis 主线程的阻塞影响较小。</p>
<p>切片集群，也叫分片集群，就是指启动多个 Redis 实例组成一个集群，然后按照一定的规则，把收到的数据划分成多份，每一份用一个实例来保存。回到我们刚刚的场景中，如果把 25GB 的数据平均分成 5 份（当然，也可以不做均分），使用 5 个实例来保存，每个实例只需要保存 5GB 数据。如下图所示：</p>
<p><img src="/images/redis-35.jpg" alt="redis-3"></p>
<p>那么，在切片集群中，实例在为 5GB 数据生成 RDB 时，数据量就小了很多，fork 子进程一般不会给主线程带来较长时间的阻塞。采用多个实例保存数据切片后，我们既能保存25GB 数据，又避免了 fork 子进程阻塞主线程而导致的响应突然变慢。</p>
<p>在实际应用 Redis 时，随着用户或业务规模的扩展，保存大量数据的情况通常是无法避免的。而切片集群，就是一个非常好的解决方案。</p>
<p><strong>数据切片和实例的对应分布关系</strong></p>
<p>在切片集群中，数据需要分布在不同实例上，那么，数据和实例之间如何对应呢？这就和接下来我要讲的 Redis Cluster 方案有关了。不过，我们要先弄明白切片集群和 Redis Cluster 的联系与区别。</p>
<p>实际上，切片集群是一种保存大量数据的通用机制，这个机制可以有不同的实现方案。在 Redis 3.0 之前，官方并没有针对切片集群提供具体的方案。从 3.0 开始，官方提供了一个名为 Redis Cluster 的方案，用于实现切片集群。Redis Cluster 方案中就规定了数据和实例的对应规则。</p>
<p>具体来说，Redis Cluster 方案采用哈希槽（Hash Slot，接下来我会直接称之为 Slot），来处理数据和实例之间的映射关系。在 Redis Cluster 方案中，一个切片集群共有 16384<br>个哈希槽，这些哈希槽类似于数据分区，每个键值对都会根据它的 key，被映射到一个哈希槽中。</p>
<p>具体的映射过程分为两大步：首先根据键值对的 key，按照 CRC16 算法计算一个 16 bit 的值；然后，再用这个 16bit 值对 16384 取模，得到 0~16383 范围内的模数，每个模数代表一个相应编号的哈希槽。</p>
<p>那么，这些哈希槽又是如何被映射到具体的 Redis 实例上的呢？</p>
<p>我们在部署 Redis Cluster 方案时，可以使用 cluster create 命令创建集群，此时，Redis 会自动把这些槽平均分布在集群实例上。例如，如果集群中有 N 个实例，那么，每个实例上的槽个数为 16384/N 个。</p>
<p><img src="/images/redis-36.jpg" alt="redis-3"></p>
<p>示意图中的切片集群一共有 3 个实例，同时假设有 5 个哈希槽，我们首先可以通过下面的命令手动分配哈希槽：实例 1 保存哈希槽 0 和 1，实例 2 保存哈希槽 2 和 3，实例 3 保存<br>哈希槽 4。</p>
<p><strong>客户端如何定位数据？</strong></p>
<p>在定位键值对数据时，它所处的哈希槽是可以通过计算得到的，这个计算可以在客户端发送请求时来执行。但是，要进一步定位到实例，还需要知道哈希槽分布在哪个实例上。</p>
<p>一般来说，客户端和集群实例建立连接后，实例就会把哈希槽的分配信息发给客户端。但是，在集群刚刚创建的时候，每个实例只知道自己被分配了哪些哈希槽，是不知道其他实例拥有的哈希槽信息的。</p>
<p>那么，客户端为什么可以在访问任何一个实例时，都能获得所有的哈希槽信息呢？这是因为，Redis 实例会把自己的哈希槽信息发给和它相连接的其它实例，来完成哈希槽分配信息的扩散。当实例之间相互连接后，每个实例就有所有哈希槽的映射关系了。</p>
<p>客户端收到哈希槽信息后，会把哈希槽信息缓存在本地。当客户端请求键值对时，会先计算键所对应的哈希槽，然后就可以给相应的实例发送请求了。</p>
<p>但是，在集群中，实例和哈希槽的对应关系并不是一成不变的，最常见的变化有两个：</p>
<blockquote>
<p>在集群中，实例有新增或删除，Redis 需要重新分配哈希<br>槽；</p>
<p>为了负载均衡，Redis 需要把哈希槽在所有实例上重新分布&gt; 一遍。</p>
</blockquote>
<p>此时，实例之间还可以通过相互传递消息，获得最新的哈希槽分配信息，但是，客户端是无法主动感知这些变化的。这就会导致，它缓存的分配信息和最新的分配信息就不一致了，那该怎么办呢？</p>
<p>Redis Cluster 方案提供了一种重定向机制，所谓的“重定向”，就是指，客户端给一个实例发送数据读写操作时，这个实例上并没有相应的数据，客户端要再给一个新实例发送操作命令。</p>
<p>那客户端又是怎么知道重定向时的新实例的访问地址呢？当客户端把一个键值对的操作请求发给一个实例时，如果这个实例上并没有这个键值对映射的哈希槽，那么，这个实例就会给客户端返回下面的 MOVED 命令响应结果，这个结果中就包含了新实例的访问地址。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">GET hello:key</span><br><span class="line">(error) MOVED 13320 172.16.19.5:6379</span><br></pre></td></tr></table></figure>

<p>其中，MOVED 命令表示，客户端请求的键值对所在的哈希槽 13320，实际是在 172.16.19.5 这个实例上。通过返回的 MOVED 命令，就相当于把哈希槽所在的新实例的信息告诉给客户端了。这样一来，客户端就可以直接和 172.16.19.5 连接，并发送操作请求了。</p>
<p><strong>特点：</strong></p>
<ul>
<li>无中心架构（不存在哪个节点影响性能瓶颈），少了 proxy 层。</li>
<li>数据按照 slot 存储分布在多个节点，节点间数据共享，可动态调整数据分布。</li>
<li>可扩展性，可线性扩展到 1000 个节点，节点可动态添加或删除。</li>
<li>高可用性，部分节点不可用时，集群仍可用。通过增加 Slave 做备份数据副本</li>
<li>实现故障自动 failover，节点之间通过 gossip 协议交换状态信息，用投票机制完成 Slave到 Master 的角色提升。</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>资源隔离性较差，容易出现相互影响的情况。</li>
<li>数据通过异步复制,不保证数据的强一致性</li>
</ul>
<h2 id="数据结构实践-–-字符串"><a href="#数据结构实践-–-字符串" class="headerlink" title="数据结构实践 – 字符串"></a>数据结构实践 – 字符串</h2><p>一个我曾经遇到的需求，当时，我们要开发一个图片存储系统，要求这个系统能快速地记录图片 ID 和图片在存储系统中保存时的 ID（可以直接叫作图片存储对象 ID）。同时，还要能够根据图片 ID 快速查找到图片存储对象 ID。</p>
<p>因为图片数量巨大，所以我们就用 10 位数来表示图片 ID 和图片存储对象 ID，例如，图片 ID 为 1101000051，它在存储系统中对应的 ID 号是 3301000051。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">photo_id: 1101000051</span><br><span class="line">photo_obj_id: 3301000051</span><br></pre></td></tr></table></figure>

<p>可以看到，图片 ID 和图片存储对象 ID 正好一一对应，是典型的“键 - 单值”模式。所谓的“单值”，就是指键值对中的值就是一个值，而不是一个集合，这和 String 类型提供的“一个键对应一个值的数据”的保存形式刚好契合。</p>
<p>而且，String 类型可以保存二进制字节流，就像“万金油”一样，只要把数据转成二进制字节数组，就可以保存了。</p>
<p>所以，我们的第一个方案就是用 String 保存数据。我们把图片 ID 和图片存储对象 ID 分别作为键值对的 key 和 value 来保存，其中，图片存储对象 ID 用了 String 类型。</p>
<p>刚开始，我们保存了 1 亿张图片，大约用了 6.4GB 的内存。但是，随着图片数据量的不断增加，我们的 Redis 内存使用量也在增加，结果就遇到了大内存 Redis 实例因为生成 RDB<br>而响应变慢的问题。</p>
<p>tring 类型并不是适用于所有场合的，它有一个明显的短板，就是它保存数据时所消耗的内存空间较多。</p>
<p><strong>为什么 String 类型内存开销大？</strong></p>
<p>我们保存了 1 亿张图片的信息，用了约 6.4GB 的内存，一个图片 ID 和图片存储对象 ID 的记录平均用了 64 字节。</p>
<p>但问题是，一组图片 ID 及其存储对象 ID 的记录，实际只需要 16 字节就可以了。</p>
<p>我们来分析一下。图片 ID 和图片存储对象 ID 都是 10 位数，我们可以用两个 8 字节的 Long 类型表示这两个 ID。因为 8 字节的 Long 类型最大可以表示 2 的 64 次方的数值，<br>所以肯定可以表示 10 位数。但是，为什么 String 类型却用了 64 字节呢？</p>
<p>其实，除了记录实际数据，String 类型还需要额外的内存空间记录数据长度、空间使用等信息，这些信息也叫作元数据。当实际保存的数据较小时，元数据的空间开销就显得比较大了，有点“喧宾夺主”的意思。</p>
<p>那么，String 类型具体是怎么保存数据的呢？我来解释一下。<br>当你保存 64 位有符号整数时，String 类型会把它保存为一个 8 字节的 Long 类型整数，这种保存方式通常也叫作 int 编码方式。</p>
<p>但是，当你保存的数据中包含字符时，String 类型就会用简单动态字符串（Simple Dynamic String，SDS）结构体来保存，如下图所示：</p>
<p><img src="/images/redis-37.jpg" alt="redis-3"></p>
<blockquote>
<p>buf：字节数组，保存实际数据。为了表示字节数组的结束，<br>Redis 会自动在数组最后加一个“\0”，这就会额外占用 1<br>个字节的开销。</p>
<p>len：占 4 个字节，表示 buf 的已用长度。</p>
<p>alloc：也占个 4 字节，表示 buf 的实际分配长度，一般<br>大于 len。</p>
</blockquote>
<p>可以看到，在 SDS 中，buf 保存实际数据，而 len 和 alloc 本身其实是 SDS 结构体的额外开销。</p>
<p>另外，对于 String 类型来说，除了 SDS 的额外开销，还有一个来自于 <code>RedisObject</code> 结构体的开销。</p>
<p>因为 Redis 的数据类型有很多，而且，不同数据类型都有些相同的元数据要记录（比如最后一次访问的时间、被引用的次数等），所以，Redis 会用一个 RedisObject 结构体来统一记录这些元数据，同时指向实际数据。</p>
<p>一个 RedisObject 包含了 8 字节的元数据和一个 8 字节指针，这个指针再进一步指向具体数据类型的实际数据所在，例如指向 String 类型的 SDS 结构所在的内存地址，可以看一下下面的示意图。</p>
<p><img src="/images/redis-38.jpg" alt="redis-3"></p>
<p>为了节省内存空间，Redis 还对 Long 类型整数和 SDS 的内存布局做了专门的设计。</p>
<p>一方面，当保存的是 Long 类型整数时，RedisObject 中的指针就直接赋值为整数数据了，这样就不用额外的指针再指向整数了，节省了指针的空间开销。</p>
<p>另一方面，当保存的是字符串数据，并且字符串小于等于 44 字节时，RedisObject 中的元数据、指针和 SDS 是一块连续的内存区域，这样就可以避免内存碎片。这种布局方式也被称为 embstr 编码方式。</p>
<p>当然，当字符串大于 44 字节时，SDS 的数据量就开始变多了，Redis 就不再把 SDS 和 RedisObject 布局在一起了，而是会给 SDS 分配独立的空间，并用指针指向 SDS 结构。这种布局方式被称为 raw 编码模式。</p>
<p>为了帮助你理解 int、embstr 和 raw 这三种编码模式，我画了一张示意图，如下所示：</p>
<p><img src="/images/redis-39.jpg" alt="redis-3"></p>
<p>因为 10 位数的图片 ID 和图片存储对象 ID 是 Long 类型整数，所以可以直接用 int 编码的 RedisObject 保存。每个 int 编码的 RedisObject 元数据部分占 8 字节，指针部分被直接赋值为 8 字节的整数了。此时，每个 ID 会使用 16 字节，加起来一共是 32 字节。但是，另外的 32 字节去哪儿了呢？</p>
<p>Redis 会使用一个全局哈希表保存所有键值对，哈希表的每一项是一个 dictEntry 的结构体，用来指向一个键值对。dictEntry 结构中有三个 8 字节的指针，分别指向 key、value 以及下一个 dictEntry，三个指针共24 字节，如下图所示：</p>
<p><img src="/images/redis-40.jpg" alt="redis-3"></p>
<p>但是，这三个指针只有 24 字节，为什么会占用了 32 字节呢？这就要提到 Redis 使用的内存分配库 jemalloc 了。</p>
<p>jemalloc 在分配内存时，会根据我们申请的字节数 N，找一个比 N 大，但是最接近 N 的 2 的幂次数作为分配的空间，这样可以减少频繁分配的次数。</p>
<p>举个例子。如果你申请 6 字节空间，jemalloc 实际会分配 8 字节空间；如果你申请 24 字节空间，jemalloc 则会分配 32 字节。所以，在我们刚刚说的场景里，dictEntry 结构就占用了 32 字节。</p>
<p>好了，到这儿，你应该就能理解，为什么用 String 类型保存图片 ID 和图片存储对象 ID 时需要用 64 个字节了。</p>
<p>你看，明明有效信息只有 16 字节，使用 String 类型保存时，却需要 64 字节的内存空间，有 48 字节都没有用于保存实际的数据。我们来换算下，如果要保存的图片有 1 亿张，那么 1 亿条的图片 ID 记录就需要 6.4GB 内存空间，其中有 4.8GB 的内存空间都用来保存元数据了，额外的内存空间开销很大。那么，有没有更加节省内存的方法呢？</p>
<p><strong>用什么数据结构可以节省内存？</strong></p>
<p>Redis 有一种底层数据结构，叫压缩列表（ziplist），这是一种非常节省内存的结构。</p>
<p>我们先回顾下压缩列表的构成。表头有三个字段 zlbytes、zltail 和 zllen，分别表示列表长度、列表尾的偏移量，以及列表中的 entry 个数。压缩列表尾还有一个 zlend，表示列表结束。</p>
<p><img src="/images/redis-41.jpg" alt="redis-3"></p>
<p>压缩列表之所以能节省内存，就在于它是用一系列连续的 entry 保存数据。每个 entry 的元数据包括下面几部分。</p>
<blockquote>
<p>prev_len，表示前一个 entry 的长度。prev_len 有两种取值情况：1 字节或 5 字节。取值 1 字节时，表示上一个 entry 的长度小于 254 字节。虽然 1 字节的值能表示的数值范围是 0 到 255，但是压缩列表中 zlend 的取值默认是255，因此，就默认用 255 表示整个压缩列表的结束，其他表示长度的地方就不能再用 255 这个值了。所以，当上一个 entry 长度小于 254 字节时，prev_len 取值为 1 字节，否则，就取值为 5 字节。</p>
<p>len：表示自身长度，4 字节；</p>
<p>encoding：表示编码方式，1 字节；</p>
<p>content：保存实际数据。</p>
</blockquote>
<p>这些 entry 会挨个儿放置在内存中，不需要再用额外的指针进行连接，这样就可以节省指针所占用的空间。</p>
<p>每个 entry 保存一个图片存储对象 ID（8 字节），此时，每个 entry 的 prev_len 只需要 1 个字节就行，因为每个 entry 的前一个 entry 长度都只有 8 字节，小于 254 字节。这样一来，一个图片的存储对象 ID 所占用的内存大小是 14 字节（1+4+1+8=14），实际分配 16 字节。</p>
<p>Redis 基于压缩列表实现了 List、Hash 和 Sorted Set 这样的集合类型，这样做的最大好处就是节省了 dictEntry 的开销。当你用 String 类型时，一个键值对就有一个 dictEntry，要用 32 字节空间。但采用集合类型时，一个 key 就对应一个集合的数据，能保存的数据多了很多，但也只用了一个 dictEntry，这样就节省了内存。</p>
<p>这个方案听起来很好，但还存在一个问题：在用集合类型保存键值对时，一个键对应了一个集合的数据，但是在我们的场景中，一个图片 ID 只对应一个图片的存储对象 ID，我们该怎么用集合类型呢？换句话说，在一个键对应一个值（也就是单值键值对）的情况下，我们该怎么用集合类型来保存这种单值键值对呢？</p>
<p><strong>如何用集合类型保存单值的键值对？</strong></p>
<p>在保存单值的键值对时，可以采用基于 Hash 类型的二级编码方法。这里说的二级编码，就是把一个单值的数据拆分成两部分，前一部分作为 Hash 集合的 key，后一部分作为 Hash 集合的 value，这样一来，我们就可以把单值数据保存到 Hash 集合中了。</p>
<p>以图片 ID 1101000060 和图片存储对象 ID 3302000080 为例，我们可以把图片 ID 的前 7 位（1101000）作为 Hash 类型的键，把图片 ID 的最后 3 位（060）和图片存储对象<br>ID 分别作为 Hash 类型值中的 key 和 value。</p>
<p>按照这种设计方法，我在 Redis 中插入了一组图片 ID 及其存储对象 ID 的记录，并且用 info 命令查看了内存开销，我发现，增加一条记录后，内存占用只增加了 16 字节，如下所示：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; info memory</span><br><span class="line"><span class="meta">#</span> Memory</span><br><span class="line">used_memory:1039120</span><br><span class="line">127.0.0.1:6379&gt; hset 1101000 060 3302000080</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; info memory</span><br><span class="line"><span class="meta">#</span> Memory</span><br><span class="line">used_memory:1039136</span><br></pre></td></tr></table></figure>

<p>在使用 String 类型时，每个记录需要消耗 64 字节，这种方式却只用了 16 字节，所使用的内存空间是原来的 1/4，满足了我们节省内存空间的需求。</p>
<p>不过，你可能也会有疑惑：“二级编码一定要把图片 ID 的前 7 位作为 Hash 类型的键，把最后 3 位作为 Hash 类型值中的 key 吗？”其实，二级编码方法中采用的 ID 长度是有讲究的。</p>
<p>Redis Hash 类型的两种底层实现结构，分别是压缩列表和哈希<br>表。那么，Hash 类型底层结构什么时候使用压缩列表，什么时候使用哈希表呢？其实，Hash 类型设置了用压缩列表保存数据时的两个阈值，一旦超过了阈值，Hash 类型就会用哈希表来保存数据了。</p>
<p>这两个阈值分别对应以下两个配置项：</p>
<blockquote>
<p>hash-max-ziplist-entries：表示用压缩列表保存时哈希集合中的最大元素个数。</p>
<p>hash-max-ziplist-value：表示用压缩列表保存时哈希集合中单个元素的最大长度。</p>
</blockquote>
<p>如果我们往 Hash 集合中写入的元素个数超过了 hash-max-ziplist-entries，或者写入的单个元素大小超过了 hash-max-ziplist-value，Redis 就会自动把 Hash 类型的实现结构由压缩列表转为哈希表</p>
<p>一旦从压缩列表转为了哈希表，Hash 类型就会一直用哈希表进行保存，而不会再转回压缩列表了。在节省内存空间方面，哈希表就没有压缩列表那么高效了。</p>
<p>为了能充分使用压缩列表的精简内存布局，我们一般要控制保存在 Hash 集合中的元素个数。所以，在刚才的二级编码中，我们只用图片 ID 最后 3 位作为 Hash 集合的 key，也就保证了 Hash 集合的元素个数不超过 1000，同时，我们把 hash-max-ziplist-entries 设置为 1000，这样一来，Hash 集合就可以一直使用压缩列表来节省内存空间了。</p>
<h2 id="集合类型统计模式"><a href="#集合类型统计模式" class="headerlink" title="集合类型统计模式"></a>集合类型统计模式</h2><p>在 Web 和移动应用的业务场景中，我们经常需要保存这样一种信息：一个 key 对应了一个数据集合。我举几个例子。</p>
<blockquote>
<p>手机 App 中的每天的用户登录信息：一天对应一系列用户 ID 或移动设备 ID；</p>
<p>电商网站上商品的用户评论列表：一个商品对应了一系列的评论；</p>
<p>用户在手机 App 上的签到打卡信息：一天对应一系列用户的签到记录；</p>
<p>应用网站上的网页访问信息：一个网页对应一系列的访问点击。</p>
</blockquote>
<p>我们知道，Redis 集合类型的特点就是一个键对应一系列的数据，所以非常适合用来存取这些数据。但是，在这些场景中，除了记录信息，我们往往还需要对集合中的数据进行统计，例如：</p>
<blockquote>
<p>在移动应用中，需要统计每天的新增用户数和第二天的留存用户数；</p>
<p>在电商网站的商品评论中，需要统计评论列表中的最新评论；</p>
<p>在签到打卡中，需要统计一个月内连续打卡的用户数；</p>
<p>在网页访问记录中，需要统计独立访客（Unique Visitor，UV）量。</p>
</blockquote>
<p>通常情况下，我们面临的用户数量以及访问量都是巨大的，比如百万、千万级别的用户数量，或者千万级别、甚至亿级别的访问信息。所以，我们必须要选择能够非常高效地统计大量数据（例如亿级）的集合类型。</p>
<p>要想选择合适的集合，我们就得了解常用的集合统计模式</p>
<p><strong>聚合统计</strong></p>
<p>所谓的聚合统计，就是指统计多个集合元素的聚合结果，包括：统计多个集合的共有元素（交集统计）；把两个集合相比，统计其中一个集合独有的元素（差集统计）；统计多个集合的所有元素（并集统计）。</p>
<p>在刚才提到的场景中，统计手机 App 每天的新增用户数和第二天的留存用户数，正好对应了聚合统计。</p>
<p>要完成这个统计任务，我们可以用一个集合记录所有登录过 App 的用户 ID，同时，用另一个集合记录每一天登录过 App 的用户 ID。然后，再对这两个集合做聚合统计。我们来看下具体的操作。</p>
<p>记录所有登录过 App 的用户 ID 还是比较简单的，我们可以直接使用 Set 类型，把 key 设置为 user:id，表示记录的是用户 ID，value 就是一个 Set 集合，里面是所有登录过 App 的用户 ID，我们可以把这个 Set 叫作累计用户 Set，如下图所示：</p>
<p><img src="/images/redis-42.jpg" alt="redis-3"></p>
<p>需要注意的是，累计用户 Set 中没有日期信息，我们是不能直接统计每天的新增用户的。所以，我们还需要把每一天登录的用户 ID，记录到一个新集合中，我们把这个集合叫作每日用户 Set，它有两个特点：</p>
<blockquote>
<p>key 是 user:id 以及当天日期，例如user:id:20200803；</p>
<p>value 是 Set 集合，记录当天登录的用户 ID。</p>
</blockquote>
<p><img src="/images/redis-43.jpg" alt="redis-3"></p>
<p>在统计每天的新增用户时，我们只用计算每日用户 Set 和累计用户 Set 的差集就行。</p>
<p>假设我们的手机 App 在 2020 年 8 月 3 日上线，那么，8 月 3 日前是没有用户的。此时，累计用户 Set 是空集，当天登录的用户 ID 会被记录到 key 为 user:id:20200803 的<br>Set 中。所以，user:id:20200803 这个 Set 中的用户就是当天的新增用户。</p>
<p>然后，我们计算累计用户 Set 和 user:id:20200803  Set 的并集结果，结果保存在 user:id 这个累计用户 Set 中，如下所示：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SUNIONSTORE  user:id  user:id  user:id:20200803</span><br></pre></td></tr></table></figure>

<p>此时，user:id 这个累计用户 Set 中就有了 8 月 3 日的用户 ID。等到 8 月 4 日再统计时，我们把 8 月 4 日登录的用户 ID 记录到 user:id:20200804 的 Set 中。接下来，我们执行 SDIFFSTORE 命令计算累计用户 Set 和 user:id:20200804 Set 的差集，结果保存在 key 为 user:new 的 Set 中，如下所示：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SDIFFSTORE  user:new  user:id:20200804 user:id</span><br></pre></td></tr></table></figure>

<p>可以看到，这个差集中的用户 ID 在 user:id:20200804 的 Set 中存在，但是不在累计用户 Set 中。所以，user:new 这个 Set 中记录的就是 8 月 4 日的新增用户。</p>
<p>当要计算 8 月 4 日的留存用户时，我们只需要再计算 user:id:20200803 和 user:id:20200804 两个 Set 的交集，就可以得到同时在这两个集合中的用户 ID 了，这些就是在 8 月 3 日登录，并且在 8 月 4 日留存的用户。执行的命令如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SINTERSTORE user:id:rem user:id:20200803 user:id:20200804</span><br></pre></td></tr></table></figure>

<p>当你需要对多个集合进行聚合计算时，Set 类型会是一个非常不错的选择。不过，我要提醒你一下，这里有一个潜在的风险。</p>
<p>Set 的差集、并集和交集的计算复杂度较高，在数据量较大的情况下，如果直接执行这些计算，会导致 Redis 实例阻塞。所以，我给你分享一个小建议：你可以从主从集群中选择一个从库，让它专门负责聚合计算，或者是把数据读取到客户端，在客户端来完成聚合统计，这样就可以规避阻塞主库实例和其他从库实例的风险了。</p>
<p><strong>排序统计</strong></p>
<p>接下来，我们再来聊一聊应对集合元素排序需求的方法。我以在电商网站上提供最新评论列表的场景为例，进行讲解。</p>
<p>最新评论列表包含了所有评论中的最新留言，这就要求集合类型能对元素保序，也就是说，集合中的元素可以按序排列，这种对元素保序的集合类型叫作有序集合。</p>
<p>在 Redis 常用的 4 个集合类型中（List、Hash、Set、Sorted Set），List 和 Sorted Set 就属于有序集合。</p>
<p>List 是按照元素进入 List 的顺序进行排序的，而 Sorted Set 可以根据元素的权重来排序，我们可以自己来决定每个元素的权重值。比如说，我们可以根据元素插入 Sorted Set 的时间确定权重值，先插入的元素权重小，后插入的元素权重大。</p>
<p>我先说说用 List 的情况。每个商品对应一个 List，这个 List 包含了对这个商品的所有评论，而且会按照评论时间保存这些评论，每来一个新评论，就用 LPUSH 命令把它插入 List<br>的队头。</p>
<p>在只有一页评论的时候，我们可以很清晰地看到最新的评论，但是，在实际应用中，网站一般会分页显示最新的评论列表，一旦涉及到分页操作，List 就可能会出现问题了。</p>
<p>假设当前的评论 List 是{A, B, C, D, E, F}（其中，A 是最新的评论，以此类推，F 是最早的评论），在展示第一页的 3 个评论时，我们可以用下面的命令，得到最新的三条评论 A、B、C：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">LRANGE product1 0 2</span><br><span class="line">1) "A"</span><br><span class="line">2) "B"</span><br><span class="line">3) "C"</span><br></pre></td></tr></table></figure>

<p>然后，再用下面的命令获取第二页的 3 个评论，也就是 D、E、F。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">LRANGE product1 3 5</span><br><span class="line">1) "D"</span><br><span class="line">2) "E"</span><br><span class="line">3) "F"</span><br></pre></td></tr></table></figure>

<p>但是，如果在展示第二页前，又产生了一个新评论 G，评论 G 就会被 LPUSH 命令插入到评论 List 的队头，评论 List 就变成了{G, A, B, C, D, E, F}。此时，再用刚才的命令获取第二页评论时，就会发现，评论 C 又被展示出来了，也就是 C、D、E。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">LRANGE product1 3 5</span><br><span class="line">1) "C"</span><br><span class="line">2) "D"</span><br><span class="line">3) "E"</span><br></pre></td></tr></table></figure>

<p>之所以会这样，关键原因就在于，List 是通过元素在 List 中的位置来排序的，当有一个新元素插入时，原先的元素在 List 中的位置都后移了一位，比如说原来在第 1 位的元素现在排在了第 2 位。所以，对比新元素插入前后，List 相同位置上的元素就会发生变化，用 LRANGE 读取时，就会读到旧元素。</p>
<p>和 List 相比，Sorted Set 就不存在这个问题，因为它是根据元素的实际权重来排序和获取数据的。</p>
<p>我们可以按评论时间的先后给每条评论设置一个权重值，然后再把评论保存到 Sorted Set 中。Sorted Set 的 ZRANGEBYSCORE 命令就可以按权重排序后返回元素。这样的话，即使集合中的元素频繁更新，Sorted Set 也能通过 ZRANGEBYSCORE 命令准确地获取到按序排列的数据。</p>
<p>假设越新的评论权重越大，目前最新评论的权重是 N，我们执行下面的命令时，就可以获得最新的 10 条评论：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ZRANGEBYSCORE comments N-9 N</span><br></pre></td></tr></table></figure>

<p>所以，在面对需要展示最新列表、排行榜等场景时，如果数据更新频繁或者需要分页显示，建议你优先考虑使用 Sorted Set。</p>
<p><strong>二值状态统计</strong></p>
<p>现在，我们再来分析下第三个场景：二值状态统计。这里的二值状态就是指集合元素的取值就只有 0 和 1 两种。在签到打卡的场景中，我们只用记录签到（1）或未签到（0），所以它就是非常典型的二值状态，在签到统计时，每个用户一天的签到用 1 个 bit 位就能表示，一个月（假设是 31 天）的签到情况用 31 个 bit 位就可以，而一年的签到也只需要用 365 个 bit 位，根本不用太复杂的集合类型。这个时候，我们就可以选择 Bitmap。这是 Redis 提供的扩展数据类型。</p>
<p>Bitmap 本身是用 String 类型作为底层数据结构实现的一种统计二值状态的数据类型。String 类型是会保存为二进制的字节数组，所以，Redis 就把字节数组的每个 bit 位利用起来，用来表示一个元素的二值状态。你可以把 Bitmap 看作是一个 bit 数组。</p>
<p>Bitmap 提供了 GETBIT/SETBIT 操作，使用一个偏移值 offset 对 bit 数组的某一个 bit 位进行读和写。不过，需要注意的是，Bitmap 的偏移量是从 0 开始算的，也就是说 offset 的最小值是 0。当使用 SETBIT 对一个 bit 位进行写操作时，这个 bit 位会被设置为 1。Bitmap 还提供了 BITCOUNT 操作，用来统计这个 bit 数组中所有“1”的个数。</p>
<p>那么，具体该怎么用 Bitmap 进行签到统计呢？我还是借助一个具体的例子来说明。</p>
<p>假设我们要统计 ID 3000 的用户在 2020 年 8 月份的签到情况，就可以按照下面的步骤进行操作。</p>
<p>第一步，执行下面的命令，记录该用户 8 月 3 号已签到。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SETBIT uid:sign:3000:202008 2 1</span><br></pre></td></tr></table></figure>

<p>第二步，检查该用户 8 月 3 日是否签到。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GETBIT uid:sign:3000:202008 2</span><br></pre></td></tr></table></figure>

<p>第三步，统计该用户在 8 月份的签到次数。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">BITCOUNT uid:sign:3000:202008</span><br></pre></td></tr></table></figure>

<p>这样，我们就知道该用户在 8 月份的签到情况了，是不是很简单呢？接下来，你可以再思考一个问题：如果记录了 1 亿个用户 10 天的签到情况，你有办法统计出这 10 天连续签到的用户总数吗？</p>
<p>在介绍具体的方法之前，我们要先知道，Bitmap 支持用 BITOP 命令对多个 Bitmap 按位做“与”“或”“异或”的操作，操作的结果会保存到一个新的 Bitmap 中。</p>
<p>我以按位“与”操作为例来具体解释一下。从下图中，可以看到，三个 Bitmap bm1、bm2 和 bm3，对应 bit 位做“与”操作，结果保存到了一个新的 Bitmap 中（示例中，这个结果 Bitmap 的 key 被设为“resmap”）。</p>
<p><img src="/images/redis-44.jpg" alt="redis-3"></p>
<p>回到刚刚的问题，在统计 1 亿个用户连续 10 天的签到情况时，你可以把每天的日期作为 key，每个 key 对应一个 1 亿位的 Bitmap，每一个 bit 对应一个用户当天的签到情况。</p>
<p>接下来，我们对 10 个 Bitmap 做“与”操作，得到的结果也是一个 Bitmap。在这个 Bitmap 中，只有 10 天都签到的用户对应的 bit 位上的值才会是 1。最后，我们可以用<br>BITCOUNT 统计下 Bitmap 中的 1 的个数，这就是连续签到 10 天的用户总数了。</p>
<p>现在，我们可以计算一下记录了 10 天签到情况后的内存开销。每天使用 1 个 1 亿位的 Bitmap，大约占 12MB 的内存（10^8/8/1024/1024），10 天的 Bitmap 的内存开销约<br>为 120MB，内存压力不算太大。不过，在实际应用时，最好对 Bitmap 设置过期时间，让 Redis 自动删除不再需要的签到记录，以节省内存开销。</p>
<p>所以，如果只需要统计数据的二值状态，例如商品有没有、用户在不在等，就可以使用 Bitmap，因为它只用一个 bit 位就能表示 0 或 1。在记录海量数据时，Bitmap 能够有效地节省内存空间。</p>
<p><strong>基数统计</strong></p>
<p>最后，我们再来看一个统计场景：基数统计。基数统计就是指统计一个集合中不重复的元素个数。对应到我们刚才介绍的场景中，就是统计网页的 UV。</p>
<p>网页 UV 的统计有个独特的地方，就是需要去重，一个用户一天内的多次访问只能算作一次。在 Redis 的集合类型中，Set 类型默认支持去重，所以看到有去重需求时，我们可能第一时间就会想到用 Set 类型。</p>
<p>我们来结合一个例子看一看用 Set 的情况。</p>
<p>有一个用户 user1 访问 page1 时，你把这个信息加到 Set 中：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SADD page1:uv user1</span><br></pre></td></tr></table></figure>

<p>用户 1 再来访问时，Set 的去重功能就保证了不会重复记录用户 1 的访问次数，这样，用户 1 就算是一个独立访客。当你需要统计 UV 时，可以直接用 SCARD 命令，这个命令会返回一个集合中的元素个数。</p>
<p>但是，如果 page1 非常火爆，UV 达到了千万，这个时候，一个 Set 就要记录千万个用户 ID。对于一个搞大促的电商网站而言，这样的页面可能有成千上万个，如果每个页面都用这样的一个 Set，就会消耗很大的内存空间。</p>
<p>当然，你也可以用 Hash 类型记录 UV。</p>
<p>例如，你可以把用户 ID 作为 Hash 集合的 key，当用户访问页面时，就用 HSET 命令（用于设置 Hash 集合元素的值），对这个用户 ID 记录一个值“1”，表示一个独立访客，用户 1 访问 page1 后，我们就记录为 1 个独立访客，如下所示：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HSET page1:uv user1 1</span><br></pre></td></tr></table></figure>

<p>即使用户 1 多次访问页面，重复执行这个 HSET 命令，也只会把 user1 的值设置为 1，仍然只记为 1 个独立访客。当要统计 UV 时，我们可以用 HLEN 命令统计 Hash 集合中的所有元素个数。</p>
<p>但是，和 Set 类型相似，当页面很多时，Hash 类型也会消耗很大的内存空间。那么，有什么办法既能完成统计，还能节省内存吗？</p>
<p>这时候，就要用到 Redis 提供的 HyperLogLog 了。<br>HyperLogLog 是一种用于统计基数的数据集合类型，它的最大优势就在于，当集合元素数量非常多时，它计算基数所需的空间总是固定的，而且还很小。</p>
<p>在 Redis 中，每个 HyperLogLog 只需要花费 12 KB 内存，就可以计算接近 2^64 个元素的基数。你看，和元素越多就越耗费内存的 Set 和 Hash 类型相比，HyperLogLog 就非<br>常节省空间。</p>
<p>在统计 UV 时，你可以用 PFADD 命令（用于向HyperLogLog 中添加新元素）把访问页的每个用户都添加到 HyperLogLog 中。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PFADD page1:uv user1 user2 user3 user4 user5</span><br></pre></td></tr></table></figure>

<p>接下来，就可以用 PFCOUNT 命令直接获得 page1 的 UV 值了，这个命令的作用就是返回 HyperLogLog 的统计结果。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PFCOUNT page1:uv</span><br></pre></td></tr></table></figure>

<p>不过，有一点需要你注意一下，HyperLogLog 的统计规则是基于概率完成的，所以它给出的统计结果是有一定误差的，标准误算率是 0.81%。这也就意味着，你使用HyperLogLog 统计的 UV 是 100 万，但实际的 UV 可能是 101 万。虽然误差率不算大，但是，如果你需要精确统计结果的话，最好还是继续用 Set 或 Hash 类型。</p>
<p><img src="/images/redis-45.jpg" alt="redis-3"></p>
<p>可以看到，Set 和 Sorted Set 都支持多种聚合统计，不过，对于差集计算来说，只有 Set 支持。Bitmap 也能做多个 Bitmap 间的聚合计算，包括与、或和异或操作。</p>
<p>当需要进行排序统计时，List 中的元素虽然有序，但是一旦有新元素插入，原来的元素在 List 中的位置就会移动，那么，按位置读取的排序结果可能就不准确了。而 Sorted Set 本身是按照集合元素的权重排序，可以准确地按序获取结果，所以建议你优先使用它。</p>
<p>如果我们记录的数据只有 0 和 1 两个值的状态，Bitmap 会是一个很好的选择，这主要归功于 Bitmap 对于一个数据只用 1 个 bit 记录，可以节省内存。</p>
<p>对于基数统计来说，如果集合元素量达到亿级别而且不需要精确统计时，我建议你使用 HyperLogLog。</p>
<h2 id="如何在Redis中保存时间序列数据？"><a href="#如何在Redis中保存时间序列数据？" class="headerlink" title="如何在Redis中保存时间序列数据？"></a>如何在Redis中保存时间序列数据？</h2><p>我们现在做互联网产品的时候，都有这么一个需求：记录用户在网站或者 App 上的点击行为数据，来分析用户行为。这里的数据一般包括用户 ID、行为类型（例如浏览、登录、下单等）、行为发生的时间戳：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">UserID, Type, TimeStamp</span><br></pre></td></tr></table></figure>

<p>我之前做过的一个物联网项目的数据存取需求，和这个很相似。我们需要周期性地统计近万台设备的实时状态，包括设备 ID、压力、温度、湿度，以及对应的时间戳：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DeviceID, Pressure, Temperature, Humidity, TimeStamp</span><br></pre></td></tr></table></figure>

<p>这些与发生时间相关的一组数据，就是时间序列数据。这些数据的特点是没有严格的关系模型，记录的信息可以表示成键和值的关系（例如，一个设备 ID 对应一条记录），所以，并不需要专门用关系型数据库（例如 MySQL）来保存。而 Redis 的键值数据模型，正好可以满足这里的数据存取需求。Redis 基于自身数据结构以及扩展模块，提供了两种解决方案。</p>
<p><strong>时间序列数据的读写特点</strong></p>
<p>在实际应用中，时间序列数据通常是持续高并发写入的，例如，需要连续记录数万个设备的实时状态值。同时，时间序列数据的写入主要就是插入新数据，而不是更新一个已存在的数据，也就是说，一个时间序列数据被记录后通常就不会变了，因为它就代表了一个设备在某个时刻的状态值（例如，一个设备在某个时刻的温度测量值，一旦记录下来，这个值本身就不会再变了）。</p>
<p>所以，这种数据的写入特点很简单，就是插入数据快，这就要求我们选择的数据类型，在进行数据插入时，复杂度要低，尽量不要阻塞。看到这儿，你可能第一时间会想到用 Redis 的 String、Hash 类型来保存，因为它们的插入复杂度都是 O(1)，是个不错的选择。但是，我在之前说过，String 类型在记录小数据时（例如刚才例子中的设备温度值），元数据的内存开销比较大，不太适合保存大量数据。</p>
<p>那我们再看看，时间序列数据的“读”操作有什么特点。</p>
<p>我们在查询时间序列数据时，既有对单条记录的查询（例如查询某个设备在某一个时刻的运行状态信息，对应的就是这个设备的一条记录），也有对某个时间范围内的数据的查询（例如每天早上 8 点到 10 点的所有设备的状态信息）。</p>
<p>除此之外，还有一些更复杂的查询，比如对某个时间范围内的数据做聚合计算。这里的聚合计算，就是对符合查询条件的所有数据做计算，包括计算均值、最大 / 最小值、求和等。例如，我们要计算某个时间段内的设备压力的最大值，来判断是否有故障发生。</p>
<p>那用一个词概括时间序列数据的“读”，就是查询模式多。</p>
<p>弄清楚了时间序列数据的读写特点，接下来我们就看看如何在 Redis 中保存这些数据。我们来分析下：针对时间序列数据的“写要快”，Redis 的高性能写特性直接就可以满足了；而针对“查询模式多”，也就是要支持单点查询、范围查询和聚合计算，Redis 提供了保存时间序列数据的两种方案，分别可以基于 Hash 和 Sorted Set 实现，以及基于 RedisTimeSeries 模块实现。</p>
<p><strong>基于 Hash 和 Sorted Set 保存时间序列数据</strong></p>
<p>为什么保存时间序列数据，要同时使用这两种类型？</p>
<p>关于 Hash 类型，我们都知道，它有一个特点是，可以实现对单键的快速查询。这就满足了时间序列数据的单键查询需求。我们可以把时间戳作为 Hash 集合的 key，把记录的设备状态值作为 Hash 集合的 value。</p>
<p>可以看下用 Hash 集合记录设备的温度值的示意图：</p>
<p><img src="/images/redis-48.jpg" alt="redis-3"></p>
<p>当我们想要查询某个时间点或者是多个时间点上的温度数据时，直接使用 HGET 命令或者 HMGET 命令，就可以分别获得 Hash 集合中的一个 key 和多个 key 的 value 值了。</p>
<p>举个例子。我们用 HGET 命令查询 202008030905 这个时刻的温度值，使用 HMGET 查询 202008030905、202008030907、202008030908 这三个时刻的温度值，如下所示：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">HGET device:temperature 202008030905</span><br><span class="line">"25.1"</span><br><span class="line"></span><br><span class="line">HMGET device:temperature 202008030905 202008030907 202008030908</span><br><span class="line">1) "25.1"</span><br><span class="line">2) "25.9"</span><br><span class="line">3) "24.9"</span><br></pre></td></tr></table></figure>

<p>用 Hash 类型来实现单键的查询很简单。但是，Hash 类型有个短板：它并不支持对数据进行范围查询。</p>
<p>虽然时间序列数据是按时间递增顺序插入 Hash 集合中的，但 Hash 类型的底层结构是哈希表，并没有对数据进行有序索引。所以，如果要对 Hash 类型进行范围查询的话，就需要扫描 Hash 集合中的所有数据，再把这些数据取回到客户端进行排序，然后，才能在客户端得到所查询范围内的数据。显然，查询效率很低。</p>
<p>为了能同时支持按时间戳范围的查询，可以用 Sorted Set 来保存时间序列数据，因为它能够根据元素的权重分数来排序。我们可以把时间戳作为 Sorted Set 集合的元素分数，把时间点上记录的数据作为元素本身。</p>
<p>我还是以保存设备温度的时间序列数据为例，进行解释。下图显示了用 Sorted Set 集合保存的结果。</p>
<p><img src="/images/redis-49.jpg" alt="redis-3"></p>
<p>使用 Sorted Set 保存数据后，我们就可以使用 ZRANGEBYSCORE 命令，按照输入的最大时间戳和最小时间戳来查询这个时间范围内的温度值了。如下所示，我们来查询一下在<br>2020 年 8 月 3 日 9 点 7 分到 9 点 10 分间的所有温度值：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ZRANGEBYSCORE device:temperature 202008030907 202008030910</span><br><span class="line">1) "25.9"</span><br><span class="line">2) "24.9"</span><br><span class="line">3) "25.3"</span><br><span class="line">4) "25.2"</span><br></pre></td></tr></table></figure>

<p>现在我们知道了，同时使用 Hash 和 Sorted Set，可以满足单个时间点和一个时间范围内的数据查询需求了，但是我们又会面临一个新的问题，也就是我们要解答的第二个问题：</p>
<p>如何保证写入 Hash 和 Sorted Set 是一个原子性的操作呢？</p>
<p>所谓“原子性的操作”，就是指我们执行多个写命令操作时（例如用 HSET 命令和 ZADD 命令分别把数据写入 Hash 和 Sorted Set），这些命令操作要么全部完成，要么都不完成。</p>
<p>只有保证了写操作的原子性，才能保证同一个时间序列数据，在 Hash 和 Sorted Set 中，要么都保存了，要么都没保存。否则，就可能出现 Hash 集合中有时间序列数据，而 Sorted Set 中没有，那么，在进行范围查询时，就没有办法满足查询需求了。</p>
<p>那 Redis 是怎么保证原子性操作的呢？这里就涉及到了 Redis 用来实现简单的事务的 MULTI 和 EXEC 命令。当多个命令及其参数本身无误时，MULTI 和 EXEC 命令可以保证执<br>行这些命令时的原子性。关于 Redis 的事务支持和原子性保证的异常情况。</p>
<blockquote>
<p>MULTI 命令：表示一系列原子性操作的开始。收到这个命令后，Redis 就知道，接下来再收到的命令需要放到一个内部队列中，后续一起执行，保证原子性。</p>
<p>EXEC 命令：表示一系列原子性操作的结束。一旦 Redis 收到了这个命令，就表示所有要保证原子性的命令操作都已经发送完成了。此时，Redis 开始执行刚才放到内部队列中的所有命令操作。</p>
</blockquote>
<p>你可以看下下面这张示意图，命令 1 到命令 N 是在 MULTI 命令后、EXEC 命令前发送的，它们会被一起执行，保证原子性。</p>
<p><img src="/images/redis-50.jpg" alt="redis-3"></p>
<p>以保存设备状态信息的需求为例，我们执行下面的代码，把设备在 2020 年 8 月 3 日 9 时 5 分的温度，分别用 HSET 命令和 ZADD 命令写入 Hash 集合和 Sorted Set 集合。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; MULTI</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; HSET device:temperature 202008030911 26.8</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379&gt; ZADD device:temperature 202008030911 26.8</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379&gt; EXEC</span><br><span class="line">1) (integer) 1</span><br><span class="line">2) (integer) 1</span><br></pre></td></tr></table></figure>

<p>可以看到，首先，Redis 收到了客户端执行的 MULTI 命令。然后，客户端再执行 HSET 和 ZADD 命令后，Redis 返回的结果为“QUEUED”，表示这两个命令暂时入队，先不执行；执行了 EXEC 命令后，HSET 命令和 ZADD 命令才真正执行，并返回成功结果（结果值为 1）。</p>
<p>到这里，我们就解决了时间序列数据的单点查询、范围查询问题，并使用 MUTLI 和 EXEC 命令保证了 Redis 能原子性地把数据保存到 Hash 和 Sorted Set 中。接下来，我们需要继续解决第三个问题：如何对时间序列数据进行聚合计算？</p>
<p>聚合计算一般被用来周期性地统计时间窗口内的数据汇总状态，在实时监控与预警等场景下会频繁执行。</p>
<p>因为 Sorted Set 只支持范围查询，无法直接进行聚合计算，所以，我们只能先把时间范围内的数据取回到客户端，然后在客户端自行完成聚合计算。这个方法虽然能完成聚合计算，但是会带来一定的潜在风险，也就是大量数据在 Redis 实例和客户端间频繁传输，这会和其他操作命令竞争网络资源，导致其他操作变慢。</p>
<p>在我们这个物联网项目中，就需要每 3 分钟统计一下各个设备的温度状态，一旦设备温度超出了设定的阈值，就要进行报警。这是一个典型的聚合计算场景，我们可以来看看这个过程中的数据体量。</p>
<p>假设我们需要每 3 分钟计算一次的所有设备各指标的最大值，每个设备每 15 秒记录一个指标值，1 分钟就会记录 4 个值，3 分钟就会有 12 个值。我们要统计的设备指标数量有 33 个，所以，单个设备每 3 分钟记录的指标数据有将近 400 个（33 * 12 = 396），而设备总数量有 1 万台，这样一来，每 3 分钟就有将近 400 万条（396 * 1 万 = 396 万）数据需要在客户端和 Redis 实例间进行传输。</p>
<p>为了避免客户端和 Redis 实例间频繁的大量数据传输，我们可以使用 RedisTimeSeries 来保存时间序列数据。</p>
<p>RedisTimeSeries 支持直接在 Redis 实例上进行聚合计算。还是以刚才每 3 分钟算一次最大值为例。在 Redis 实例上直接聚合计算，那么，对于单个设备的一个指标值来说，每 3<br>分钟记录的 12 条数据可以聚合计算成一个值，单个设备每 3 分钟也就只有 33 个聚合值需要传输，1 万台设备也只有 33 万条数据。数据量大约是在客户端做聚合计算的十分之一，<br>很显然，可以减少大量数据传输对 Redis 实例网络的性能影响。</p>
<p>所以，如果我们只需要进行单个时间点查询或是对某个时间范围查询的话，适合使用 Hash 和 Sorted Set 的组合，它们都是 Redis 的内在数据结构，性能好，稳定性高。但是，如果<br>我们需要进行大量的聚合计算，同时网络带宽条件不是太好时，Hash 和 Sorted Set 的组合就不太适合了。此时，使用 RedisTimeSeries 就更加合适一些。</p>
<p><strong>基于 RedisTimeSeries 模块保存时间序列数据</strong></p>
<p>RedisTimeSeries 是 Redis 的一个扩展模块。它专门面向时间序列数据提供了数据类型和访问接口，并且支持在 Redis 实例上直接对数据进行按时间范围的聚合计算。</p>
<p>因为 RedisTimeSeries 不属于 Redis 的内建功能模块，在使用时，我们需要先把它的源码单独编译成动态链接库 redistimeseries.so，再使用 loadmodule 命令进行加载，如下所示：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loadmodule redistimeseries.so</span><br></pre></td></tr></table></figure>

<p>当用于时间序列数据存取时，RedisTimeSeries 的操作主要有 5 个：</p>
<blockquote>
<p>用 TS.CREATE 命令创建时间序列数据集合；</p>
<p>用 TS.ADD 命令插入数据；</p>
<p>用 TS.GET 命令读取最新数据；</p>
<p>用 TS.MGET 命令按标签过滤查询数据集合；</p>
<p>用 TS.RANGE 支持聚合计算的范围查询。</p>
</blockquote>
<p><strong>1.用 TS.CREATE 命令创建一个时间序列数据集合</strong></p>
<p>在 TS.CREATE 命令中，我们需要设置时间序列数据集合的 key 和数据的过期时间（以毫秒为单位）。此外，我们还可以为数据集合设置标签，来表示数据集合的属性。</p>
<p>例如，我们执行下面的命令，创建一个 key 为 device:temperature、数据有效期为 600s 的时间序列数据集合。也就是说，这个集合中的数据创建了 600s 后，就会被自动删除。最后，我们给这个集合设置了一个标签属性{device_id:1}，表明这个数据集合中记录的是属于设备 ID 号为 1 的数据。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">TS.CREATE device:temperature RETENTION 600000 LABELS device_id 1 </span><br><span class="line">OK</span><br></pre></td></tr></table></figure>

<p><strong>2.用 TS.ADD 命令插入数据，用 TS.GET 命令读取最新数据</strong></p>
<p>我们可以用 TS.ADD 命令往时间序列集合中插入数据，包括时间戳和具体的数值，并使用 TS.GET 命令读取数据集合中的最新一条数据。</p>
<p>例如，我们执行下列 TS.ADD 命令时，就往 device:temperature 集合中插入了一条数据，记录的是设备在 2020 年 8 月 3 日 9 时 5 分的设备温度；再执行TS.GET 命令时，就会把刚刚插入的最新数据读取出来。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">TS.ADD device:temperature 1596416700 25.1</span><br><span class="line">1596416700</span><br><span class="line"></span><br><span class="line">TS.GET device:temperature </span><br><span class="line">25.1</span><br></pre></td></tr></table></figure>

<p><strong>3.用 TS.MGET 命令按标签过滤查询数据集合</strong></p>
<p>在保存多个设备的时间序列数据时，我们通常会把不同设备的数据保存到不同集合中。此时，我们就可以使用 TS.MGET 命令，按照标签查询部分集合中的最新数据。在使用<br>TS.CREATE 创建数据集合时，我们可以给集合设置标签属性。当我们进行查询时，就可以在查询条件中对集合标签属性进行匹配，最后的查询结果里只返回匹配上的集合中的最新数据。</p>
<p>举个例子。假设我们一共用 4 个集合为 4 个设备保存时间序列数据，设备的 ID 号是 1、2、3、4，我们在创建数据集合时，把 device_id 设置为每个集合的标签。此时，我们就可以使用下列 TS.MGET 命令，以及 FILTER 设置（这个配置项用来设置集合标签的过滤条件），查询 device_id 不等于 2 的所有其他设备的数据集合，并返回各自集合中的最新的一条数据。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">TS.MGET FILTER device_id!=2 </span><br><span class="line">1) 1) "device:temperature:1"</span><br><span class="line">   2) (empty list or set)</span><br><span class="line">   3) 1) (integer) 1596417000</span><br><span class="line">      2) "25.3"</span><br><span class="line">2) 1) "device:temperature:3"</span><br><span class="line">   2) (empty list or set)</span><br><span class="line">   3) 1) (integer) 1596417000</span><br><span class="line">      2) "29.5"</span><br><span class="line">3) 1) "device:temperature:4"</span><br><span class="line">   2) (empty list or set)</span><br><span class="line">   3) 1) (integer) 1596417000</span><br><span class="line">      2) "30.1"</span><br></pre></td></tr></table></figure>

<p><strong>4.用 TS.RANGE 支持需要聚合计算的范围查询</strong></p>
<p>最后，在对时间序列数据进行聚合计算时，我们可以使用 TS.RANGE 命令指定要查询的数据的时间范围，同时用 AGGREGATION 参数指定要执行的聚合计算类型。</p>
<p>RedisTimeSeries 支持的聚合计算类型很丰富，包括求均值（avg）、求最大 / 最小值（max/min），求和（sum）等。<br>例如，在执行下列命令时，我们就可以按照每 180s 的时间窗口，对 2020 年 8 月 3 日 9 时 5 分和 2020 年 8 月 3 日 9 时 12 分这段时间内的数据进行均值计算了。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">TS.RANGE device:temperature 1596416700 1596417120 AGGREGATION avg 180000</span><br><span class="line">1) 1) (integer) 1596416700</span><br><span class="line">   2) "25.6"</span><br><span class="line">2) 1) (integer) 1596416880</span><br><span class="line">   2) "25.8"</span><br><span class="line">3) 1) (integer) 1596417060</span><br><span class="line">   2) "26.1"</span><br></pre></td></tr></table></figure>

<p>与使用 Hash 和 Sorted Set 来保存时间序列数据相比，RedisTimeSeries 是专门为时间序列数据访问设计的扩展模块，能支持在 Redis 实例上直接进行聚合计算，以及按标签属性过滤查询数据集合，当我们需要频繁进行聚合计算，以及从大量集合中筛选出特定设备或用户的数据集合时，RedisTimeSeries 就可以发挥优势了。</p>
<h2 id="影响-Redis-性能的-5-大方面的潜在因素"><a href="#影响-Redis-性能的-5-大方面的潜在因素" class="headerlink" title="影响 Redis 性能的 5 大方面的潜在因素"></a>影响 Redis 性能的 5 大方面的潜在因素</h2><ol>
<li>Redis 内部的阻塞式操作；</li>
<li>CPU 核和 NUMA 架构的影响；</li>
<li>Redis 关键系统配置；</li>
<li>Redis 内存碎片；</li>
<li>Redis 缓冲区。</li>
</ol>
<h3 id="内部的阻塞式操作"><a href="#内部的阻塞式操作" class="headerlink" title="内部的阻塞式操作"></a>内部的阻塞式操作</h3><p><strong>Redis 实例有哪些阻塞点？</strong></p>
<p>Redis 实例在运行时，要和许多对象进行交互，这些不同的交互就会涉及不同的操作，下面我们来看看和 Redis 实例交互的对象，以及交互时会发生的操作。</p>
<blockquote>
<p><strong>客户端</strong>：网络 IO，键值对增删改查操作，数据库操作；</p>
<p><strong>磁盘</strong>：生成 RDB 快照，记录 AOF 日志，AOF 日志重写；</p>
<p><strong>主从节点</strong>：主库生成、传输 RDB 文件，从库接收 RDB 文件、清空数据库、加载 RDB 文件；</p>
<p><strong>切片集群实例</strong>：向其他实例传输哈希槽信息，数据迁移。</p>
</blockquote>
<p><img src="/images/redis-51.jpg" alt="redis-3"></p>
<hr>
<p><strong>1.和客户端交互时的阻塞点</strong></p>
<p>网络 IO 有时候会比较慢，但是 Redis 使用了 IO 多路复用机制，避免了主线程一直处在等待网络连接或请求到来的状态，所以，网络 IO 不是导致 Redis 阻塞的因素。</p>
<p>键值对的增删改查操作是 Redis 和客户端交互的主要部分，也是 Redis 主线程执行的主要任务。所以，复杂度高的增删改查操作肯定会阻塞 Redis。</p>
<p>那么，怎么判断操作复杂度是不是高呢？这里有一个最基本的标准，就是看操作的复杂度是否为 O(N)。</p>
<p>Redis 中涉及集合的操作复杂度通常为 O(N)，我们要在使用时重视起来。例如集合元素全量查询操作 HGETALL、SMEMBERS，以及集合的聚合统计操作，例如求交、并和差集。这些操作可以作为 <code>Redis 的第一个阻塞点：集合全量查询和聚合操作</code>。</p>
<p>除此之外，集合自身的删除操作同样也有潜在的阻塞风险。你可能会认为，删除操作很简单，直接把数据删除就好了，为什么还会阻塞主线程呢？</p>
<p>其实，删除操作的本质是要释放键值对占用的内存空间。你可不要小瞧内存的释放过程。释放内存只是第一步，为了更加高效地管理内存空间，在应用程序释放内存时，操作系统需要把释放掉的内存块插入一个空闲内存块的链表，以便后续进行管理和再分配。这个过程本身需要一定时间，而且会阻塞当前释放内存的应用程序，所以，如果一下子释放了大量内存，空闲内存块链表操作时间就会增加，相应地就会造成 Redis 主线程的阻塞。</p>
<p>那么，什么时候会释放大量内存呢？其实就是在删除大量键值对数据的时候，最典型的就是删除包含了大量元素的集合，也称为 bigkey 删除。为了让你对 bigkey 的删除性能有一个直观的印象，我测试了不同元素数量的集合在进行删除操作时所消耗的时间，如下表所示：</p>
<p><img src="/images/redis-52.jpg" alt="redis-3"></p>
<p>从这张表里，我们可以得出三个结论：</p>
<p><strong>1.当元素数量从 10 万增加到 100 万时，4 大集合类型的删除时间的增长幅度从 5 倍上升到了近 20 倍；</strong></p>
<p><strong>2.集合元素越大，删除所花费的时间就越长；</strong></p>
<p><strong>3.当删除有 100 万个元素的集合时，最大的删除时间绝对值已经达到了 1.98s（Hash 类型）。Redis 的响应时间一般在微秒级别，所以，一个操作达到了近 2s，不可避免地会阻塞主线程。</strong></p>
<p>经过刚刚的分析，很显然，<code>bigkey 删除操作就是 Redis 的第二个阻塞点</code>。删除操作对 Redis 实例性能的负面影响很大，而且在实际业务开发时容易被忽略，所以一定要重视它。</p>
<p>既然频繁删除键值对都是潜在的阻塞点了，那么，在 Redis 的数据库级别操作中，清空数据库（例如 FLUSHDB 和 FLUSHALL 操作）必然也是一个潜在的阻塞风险，因为它涉及到<br>删除和释放所有的键值对。所以，这就是 <code>Redis 的第三个阻塞点：清空数据库</code>。</p>
<hr>
<p><strong>2. 和磁盘交互时的阻塞点</strong></p>
<p>我之所以把 Redis 与磁盘的交互单独列为一类，主要是因为磁盘 IO 一般都是比较费时费力的，需要重点关注。</p>
<p>幸运的是，Redis 开发者早已认识到磁盘 IO 会带来阻塞，所以就把 Redis 进一步设计为采用子进程的方式生成 RDB 快照文件，以及执行 AOF 日志重写操作。这样一来，这两个操作由子进程负责执行，慢速的磁盘 IO 就不会阻塞主线程了。</p>
<p>但是，Redis 直接记录 AOF 日志时，会根据不同的写回策略对数据做落盘保存。一个同步写磁盘的操作的耗时大约是 1～2ms，如果有大量的写操作需要记录在 AOF 日志中，并同步写回的话，就会阻塞主线程了。这就得到了 <code>Redis 的第四个阻塞点了：AOF 日志同步写</code>。</p>
<hr>
<p><strong>3.主从节点交互时的阻塞点</strong></p>
<p>在主从集群中，主库需要生成 RDB 文件，并传输给从库。主库在复制的过程中，创建和传输 RDB 文件都是由子进程来完成的，不会阻塞主线程。但是，对于从库来说，它在接收了<br>RDB 文件后，需要使用 FLUSHDB 命令清空当前数据库，这就正好撞上了刚才我们分析的<code>第三个阻塞点</code>。</p>
<p>此外，从库在清空当前数据库后，还需要把 RDB 文件加载到内存，这个过程的快慢和 RDB 文件的大小密切相关，RDB 文件越大，加载过程越慢，所以，<code>加载 RDB 文件就成为了 Redis 的第五个阻塞点</code>。</p>
<hr>
<p><strong>4.切片集群实例交互时的阻塞点</strong></p>
<p>最后，当我们部署 Redis 切片集群时，每个 Redis 实例上分配的哈希槽信息需要在不同实例间进行传递，同时，当需要进行负载均衡或者有实例增删时，数据会在不同的实例间进行迁移。不过，哈希槽的信息量不大，而数据迁移是渐进式执行的，所以，一般来说，这两类操作对 Redis 主线程的阻塞风险不大。</p>
<p>不过，如果你使用了 Redis Cluster 方案，而且同时正好迁移的是 bigkey 的话，就会造成主线程的阻塞，因为 Redis Cluster 使用了同步迁移。这里你只需要知道，当没有 bigkey 时，切片集群的各实例在进行交互时不会阻塞主线程。</p>
<p>好了，你现在已经了解了 Redis 的各种关键操作，以及其中的阻塞式操作，我们来总结下刚刚找到的五个阻塞点：</p>
<blockquote>
<p><strong>集合全量查询和聚合操作</strong>；</p>
<p><strong>bigkey 删除</strong>；</p>
<p><strong>清空数据库</strong>；</p>
<p><strong>AOF 日志同步写</strong>；</p>
<p><strong>从库加载 RDB 文件</strong>。</p>
</blockquote>
<p>如果在主线程中执行这些操作，必然会导致主线程长时间无法服务其他请求。为了避免阻塞式操作，Redis 提供了异步线程机制。所谓的异步线程机制，就是指，Redis 会启动一些子线程，然后把一些任务交给这些子线程，让它们在后台完成，而不再由主线程来执行这些任务。使用异步线程机制执行操作，可以避免阻塞主线程。</p>
<p>不过，这个时候，问题来了：这五大阻塞式操作都可以被异步执行吗？</p>
<p><strong>哪些阻塞点可以异步执行？</strong></p>
<p>在分析阻塞式操作的异步执行的可行性之前，我们先来了解下异步执行对操作的要求。</p>
<p>如果一个操作能被异步执行，就意味着，它并不是 Redis 主线程的关键路径上的操作。我再解释下关键路径上的操作是啥。这就是说，客户端把请求发送给 Redis 后，等着 Redis 返回数据结果的操作。</p>
<p><img src="/images/redis-53.jpg" alt="redis-3"></p>
<p>主线程接收到操作 1 后，因为操作 1 并不用给客户端返回具体的数据，所以，主线程可以把它交给后台子线程来完成，同时只要给客户端返回一个“OK”结果就行。在子线程执行操作 1 的时候，客户端又向 Redis 实例发送了操作 2，而此时，客户端是需要使用操作 2 返回的数据结果的，如果操作 2 不返回结果，那么，客户端将一直处于等待状态。</p>
<p>在这个例子中，操作 1 就不算关键路径上的操作，因为它不用给客户端返回具体数据，所以可以由后台子线程异步执行。而操作 2 需要把结果返回给客户端，它就是关键路径上的操作，所以主线程必须立即把这个操作执行完。</p>
<p>对于 Redis 来说，读操作是典型的关键路径操作，因为客户端发送了读操作之后，就会等待读取的数据返回，以便进行后续的数据处理。而 Redis 的第一个阻塞点“集合全量查询和聚合操作”都涉及到了读操作，所以，它们是不能进行异步操作了。</p>
<p>我们再来看看删除操作。删除操作并不需要给客户端返回具体的数据结果，所以不算是关键路径操作。而我们刚才总结的第二个阻塞点“bigkey 删除”，和第三个阻塞点“清空数据库”，都是对数据做删除，并不在关键路径上。因此，我们可以使用后台子线程来异步执行删除操作。</p>
<p>对于第四个阻塞点“AOF 日志同步写”来说，为了保证数据可靠性，Redis 实例需要保证 AOF 日志中的操作记录已经落盘，这个操作虽然需要实例等待，但它并不会返回具体的数据结果给实例。所以，我们也可以启动一个子线程来执行 AOF 日志的同步写，而不用让主线程等待 AOF 日志的写完成。</p>
<p>最后，我们再来看下“从库加载 RDB 文件”这个阻塞点。从库要想对客户端提供数据存取服务，就必须把 RDB 文件加载完成。所以，这个操作也属于关键路径上的操作，我们必须让从库的主线程来执行。</p>
<p>对于 Redis 的五大阻塞点来说，除了“集合全量查询和聚合操作”和“从库加载 RDB 文件”，其他三个阻塞点涉及的操作都不在关键路径上，所以，我们可以使用 Redis 的异步子线程机制来实现 bigkey 删除，清空数据库，以及 AOF 日志同步写。</p>
<p>那么，Redis 实现的异步子线程机制具体是怎么执行呢？</p>
<p><strong>异步的子线程机制</strong></p>
<p>Redis 主线程启动后，会使用操作系统提供的pthread_create 函数创建 3 个子线程，分别由它们负责 AOF 日志写操作、键值对删除以及文件关闭的异步执行。</p>
<p>主线程通过一个链表形式的任务队列和子线程进行交互。当收到键值对删除和清空数据库的操作时，主线程会把这个操作封装成一个任务，放入到任务队列中，然后给客户端返回一个完成信息，表明删除已经完成。</p>
<p>但实际上，这个时候删除还没有执行，等到后台子线程从任务队列中读取任务后，才开始实际删除键值对，并释放相应的内存空间。因此，我们把这种异步删除也称为惰性删除（lazy free）。此时，删除或清空操作不会阻塞主线程，这就避免了对主线程的性能影响。</p>
<p>和惰性删除类似，当 AOF 日志配置成 everysec 选项后，主线程会把 AOF 写日志操作封装成一个任务，也放到任务队列中。后台子线程读取任务后，开始自行写入 AOF 日志，这<br>样主线程就不用一直等待 AOF 日志写完了。</p>
<p>下面这张图展示了 Redis 中的异步子线程执行机制，你可以再看下，加深印象。</p>
<p><img src="/images/redis-54.jpg" alt="redis-3"></p>
<p>这里有个地方需要你注意一下，异步的键值对删除和数据库清空操作是 Redis 4.0 后提供的功能，Redis 也提供了新的命令来执行这两个操作。</p>
<blockquote>
<p>键值对删除：当你的集合类型中有大量元素（例如有百万级别或千万级别元素）需要删除时，我建议你使用 UNLINK 命令。</p>
<p>清空数据库：可以在 FLUSHDB 和 FLUSHALL 命令后加上 ASYNC 选项，这样就可以让后台子线程异步地清空数据库，如下所示：<br> <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">FLUSHDB ASYNC</span><br><span class="line">FLUSHALL AYSNC</span><br></pre></td></tr></table></figure></p>
</blockquote>
<p>Redis 实例运行时的 4 大类交互对象：客户端、磁盘、主从库实例、切片集群实例。基于这 4 大类交互对象，我们梳理了会导致 Redis 性能受损的 5 大阻塞点，包括集合全量查询和聚合操作、bigkey 删除、清空数据库、AOF 日志同步写，以及从库加载 RDB 文件。</p>
<p>在这 5 大阻塞点中，bigkey 删除、清空数据库、AOF 日志同步写不属于关键路径操作，可以使用异步子线程机制来完成。Redis 在运行时会创建三个子线程，主线程会通过一个任务队列和三个子线程进行交互。子线程会根据任务的具体类型，来执行相应的异步操作。</p>
<p>不过，异步删除操作是 Redis 4.0 以后才有的功能，如果你使用的是 4.0 之前的版本，当你遇到 bigkey 删除时，我给你个小建议：先使用集合类型提供的 SCAN 命令读取数据，然后再进行删除。因为用 SCAN 命令可以每次只读取一部分数据并进行删除，这样可以避免一次性删除大量 key 给主线程带来的阻塞。</p>
<p>例如，对于 Hash 类型的 bigkey 删除，你可以使用 HSCAN 命令，每次从 Hash 集合中获取一部分键值对（例如 200 个），再使用 HDEL 删除这些键值对，这样就可以把删除压力分摊到多次操作中，那么，每次删除操作的耗时就不会太长，也就不会阻塞主线程了。</p>
<p>最后，我想再提一下，集合全量查询和聚合操作、从库加载 RDB 文件是在关键路径上，无法使用异步操作来完成。对于这两个阻塞点，我也给你两个小建议。</p>
<p>集合全量查询和聚合操作：可以使用 SCAN 命令，分批读取数据，再在客户端进行聚合计算；</p>
<p>从库加载 RDB 文件：把主库的数据量大小控制在 2~4GB 左右，以保证 RDB 文件能以较快的速度加载。</p>
<h3 id="为什么CPU结构也会影响Redis的性能？"><a href="#为什么CPU结构也会影响Redis的性能？" class="headerlink" title="为什么CPU结构也会影响Redis的性能？"></a>为什么CPU结构也会影响Redis的性能？</h3><p><strong>主流的 CPU 架构</strong></p>
<p>一个 CPU 处理器中一般有多个运行核心，我们把一个运行核心称为一个物理核，每个物理核都可以运行应用程序。每个物理核都拥有私有的一级缓存（Level 1 cache，简称 L1 cache），包括一级指令缓存和一级数据缓存，以及私有的二级缓存（Level 2 cache，简称 L2 cache）。</p>
<p>这里提到了一个概念，就是物理核的私有缓存。它其实是指缓存空间只能被当前的这个物理核使用，其他的物理核无法对这个核的缓存空间进行数据存取。我们来看一下 CPU 物理核的架构。</p>
<p><img src="/images/redis-55.jpg" alt="redis-3"></p>
<p>因为 L1 和 L2 缓存是每个物理核私有的，所以，当数据或指令保存在 L1、L2 缓存时，物理核访问它们的延迟不超过 10 纳秒，速度非常快。那么，如果 Redis 把要运行的指令或存取的数据保存在 L1 和 L2 缓存的话，就能高速地访问这些指令和数据。</p>
<p>但是，这些 L1 和 L2 缓存的大小受限于处理器的制造技术，一般只有 KB 级别，存不下太多的数据。如果 L1、L2 缓存中没有所需的数据，应用程序就需要访问内存来获取数据。而应用程序的访存延迟一般在百纳秒级别，是访问 L1、L2 缓存的延迟的近 10 倍，不可避免地会对性能造成影响。</p>
<p>所以，不同的物理核还会共享一个共同的三级缓存（Level 3 cache，简称为 L3 cache）。L3 缓存能够使用的存储资源比较多，所以一般比较大，能达到几 MB 到几十 MB，这就能<br>让应用程序缓存更多的数据。当 L1、L2 缓存中没有数据缓存时，可以访问 L3，尽可能避免访问内存。</p>
<p>另外，现在主流的 CPU 处理器中，每个物理核通常都会运行两个超线程，也叫作逻辑核。同一个物理核的逻辑核会共享使用 L1、L2 缓存。为了方便你理解，我用一张图展示一下物理核和逻辑核，以及一级、二级缓存的关系。</p>
<p><img src="/images/redis-56.jpg" alt="redis-3"></p>
<p>在主流的服务器上，一个 CPU 处理器会有 10 到 20 多个物理核。同时，为了提升服务器的处理能力，服务器上通常还会有多个 CPU 处理器（也称为多 CPU Socket），每个处理器有自己的物理核（包括 L1、L2 缓存），L3 缓存，以及连接的内存，同时，不同处理器间通过总线连接。</p>
<p>下图显示的就是多 CPU Socket 的架构，图中有两个Socket，每个 Socket 有两个物理核。</p>
<p><img src="/images/redis-57.jpg" alt="redis-3"></p>
<p>在多 CPU 架构上，应用程序可以在不同的处理器上运行。在刚才的图中，Redis 可以先在 Socket  1 上运行一段时间，然后再被调度到 Socket  2 上运行。</p>
<p>但是，有个地方需要你注意一下：如果应用程序先在一个 Socket 上运行，并且把数据保存到了内存，然后被调度到另一个 Socket 上运行，此时，应用程序再进行内存访问时，就需<br>要访问之前 Socket 上连接的内存，这种访问属于远端内存访问。和访问 Socket 直接连接的内存相比，远端内存访问会增加应用程序的延迟。</p>
<p>在多 CPU 架构下，一个应用程序访问所在 Socket 的本地内存和访问远端内存的延迟并不一致，所以，我们也把这个架构称为非统一内存访问架构（Non-Uniform Memory Access，NUMA 架构）。</p>
<p>到这里，我们就知道了主流的 CPU 多核架构和多 CPU 架构，我们来简单总结下 CPU 架构对应用程序运行的影响。</p>
<blockquote>
<p>L1、L2 缓存中的指令和数据的访问速度很快，所以，充分利用 L1、L2 缓存，可以有效缩短应用程序的执行时间；</p>
<p>在 NUMA 架构下，如果应用程序从一个 Socket 上调度到另一个 Socket 上，就可能会出现远端内存访问的情况，这会直接增加应用程序的执行时间。</p>
</blockquote>
<p><strong>CPU 多核对 Redis 性能的影响</strong></p>
<p>在一个 CPU 核上运行时，应用程序需要记录自身使用的软硬件资源信息（例如栈指针、CPU 核的寄存器值等），我们把这些信息称为运行时信息。同时，应用程序访问最频繁的指令和数据还会被缓存到 L1、L2 缓存上，以便提升执行速度。</p>
<p>但是，在多核 CPU 的场景下，一旦应用程序需要在一个新的 CPU 核上运行，那么，运行时信息就需要重新加载到新的 CPU 核上。而且，新的 CPU 核的 L1、L2 缓存也需要重新加载数据和指令，这会导致程序的运行时间增加。</p>
<p>说到这儿，我想跟你分享一个我曾经在多核 CPU 环境下对 Redis 性能进行调优的案例。希望借助这个案例，帮你全方位地了解到多核 CPU 对 Redis 的性能的影响。</p>
<p>当时，我们的项目需求是要对 Redis 的 99% 尾延迟进行优化，要求 GET 尾延迟小于 300 微秒，PUT 尾延迟小于 500 微秒。</p>
<p>可能有同学不太清楚 99% 尾延迟是啥，我先解释一下。我们把所有请求的处理延迟从小到大排个序，99% 的请求延迟小于的值就是 99% 尾延迟。比如说，我们有 1000 个请求，假设按请求延迟从小到大排序后，第 991 个请求的延迟实测值是 1ms，而前 990 个请求的延迟都小于 1ms，所以，这里的 99% 尾延迟就是 1ms。</p>
<p>刚开始的时候，我们使用 GET/PUT 复杂度为 O(1) 的 String 类型进行数据存取，同时关闭了 RDB 和 AOF，而且，Redis 实例中没有保存集合类型的其他数据，也就没有bigkey<br>操作，避免了可能导致延迟增加的许多情况。</p>
<p>但是，即使这样，我们在一台有 24 个 CPU 核的服务器上运行 Redis 实例，GET 和 PUT 的 99% 尾延迟分别是 504 微秒和 1175 微秒，明显大于我们设定的目标。</p>
<p>后来，我们仔细检测了 Redis 实例运行时的服务器 CPU 的状态指标值，这才发现，CPU 的 context switch 次数比较多。</p>
<p>context switch 是指线程的上下文切换，这里的上下文就是线程的运行时信息。在 CPU 多核的环境中，一个线程先在一个 CPU 核上运行，之后又切换到另一个 CPU 核上运行，这时就会发生 context switch。</p>
<p>当 context switch 发生后，Redis 主线程的运行时信息需要被重新加载到另一个 CPU 核上，而且，此时，另一个 CPU 核上的 L1、L2 缓存中，并没有 Redis 实例之前运行时频繁<br>访问的指令和数据，所以，这些指令和数据都需要重新从 L3 缓存，甚至是内存中加载。这个重新加载的过程是需要花费一定时间的。而且，Redis 实例需要等待这个重新加载的过程完成后，才能开始处理请求，所以，这也会导致一些请求的处理时间增加。</p>
<p>如果在 CPU 多核场景下，Redis 实例被频繁调度到不同 CPU 核上运行的话，那么，对 Redis 实例的请求处理时间影响就更大了。每调度一次，一些请求就会受到运行时信息、指令和数据重新加载过程的影响，这就会导致某些请求的延迟明显高于其他请求。分析到这里，我们就知道了刚刚的例子中 99% 尾延迟的值始终降不下来的原因。</p>
<p>所以，我们要避免 Redis 总是在不同 CPU 核上来回调度执行。于是，我们尝试着把 Redis 实例和 CPU 核绑定了，让一个 Redis 实例固定运行在一个 CPU 核上。我们可以使用<br>taskset 命令把一个程序绑定在一个核上运行。比如说，我们执行下面的命令，就把 Redis 实例绑在了 0 号核上，其中，“-c”选项用于设置要绑定的核编号。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">taskset -c 0 ./redis-server</span><br></pre></td></tr></table></figure>

<p>绑定以后，我们进行了测试。我们发现，Redis 实例的 GET 和 PUT 的 99% 尾延迟一下子就分别降到了 260 微秒和 482 微秒，达到了我们期望的目标。</p>
<p>我们来看一下绑核前后的 Redis 的 99% 尾延迟。</p>
<p><img src="/images/redis-58.jpg" alt="redis-3"></p>
<p>可以看到，在 CPU 多核的环境下，通过绑定 Redis 实例和 CPU 核，可以有效降低 Redis 的尾延迟。当然，绑核不仅对降低尾延迟有好处，同样也能降低平均延迟、提升吞吐率，进而提升 Redis 性能。</p>
<p><strong>CPU 的 NUMA 架构对 Redis 性能的影响</strong></p>
<p>在实际应用 Redis 时，我经常看到一种做法，为了提升 Redis 的网络性能，把操作系统的网络中断处理程序和 CPU 核绑定。这个做法可以避免网络中断处理程序在不同核上来回调度执行，的确能有效提升 Redis 的网络处理性能。</p>
<p>但是，网络中断程序是要和 Redis 实例进行网络数据交互的，一旦把网络中断程序绑核后，我们就需要注意 Redis 实例是绑在哪个核上了，这会关系到 Redis 访问网络数据的效率高低。</p>
<p>我们先来看下 Redis 实例和网络中断程序的数据交互：网络中断处理程序从网卡硬件中读取数据，并把数据写入到操作系统内核维护的一块内存缓冲区。内核会通过 epoll 机制触发事件，通知 Redis 实例，Redis 实例再把数据从内核的内存缓冲区拷贝到自己的内存空间，如下图所示：</p>
<p><img src="/images/redis-59.jpg" alt="redis-3"></p>
<p>那么，在 CPU 的 NUMA 架构下，当网络中断处理程序、Redis 实例分别和 CPU 核绑定后，就会有一个潜在的风险：如果网络中断处理程序和 Redis 实例各自所绑的 CPU 核不在同一个 CPU Socket 上，那么，Redis 实例读取网络数据时，就需要跨 CPU Socket 访问内存，这个过程会花费较多时间。</p>
<p>这么说可能有点抽象，我再借助一张图来解释下。</p>
<p><img src="/images/redis-60.jpg" alt="redis-3"></p>
<p>可以看到，图中的网络中断处理程序被绑在了 CPU Socket 1 的某个核上，而 Redis 实例则被绑在了 CPU Socket  2 上。此时，网络中断处理程序读取到的网络数据，被保存在<br>CPU Socket  1 的本地内存中，当 Redis 实例要访问网络数据时，就需要 Socket 2 通过总线把内存访问命令发送到 Socket 1 上，进行远程访问，时间开销比较大。</p>
<p>我们曾经做过测试，和访问 CPU Socket 本地内存相比，跨 CPU Socket 的内存访问延迟增加了 18%，这自然会导致 Redis 处理请求的延迟增加。</p>
<p>所以，为了避免 Redis 跨 CPU Socket 访问网络数据，我们最好把网络中断程序和 Redis 实例绑在同一个 CPU Socket 上，这样一来，Redis 实例就可以直接从本地内存读取网络数据了，如下图所示取：</p>
<p><img src="/images/redis-61.jpg" alt="redis-3"></p>
<p>不过，需要注意的是，在 CPU 的 NUMA 架构下，对 CPU 核的编号规则，并不是先把一个 CPU Socket 中的所有逻辑核编完，再对下一个 CPU Socket 中的逻辑核编码，而是先给每个 CPU Socket 中每个物理核的第一个逻辑核依次编号，再给每个 CPU Socket 中的物理核的第二个逻辑核依次编号。</p>
<p>我给你举个例子。假设有 2 个 CPU Socket，每个 Socket 上有 6 个物理核，每个物理核又有 2 个逻辑核，总共 24 个逻辑核。我们可以执行 lscpu 命令，查看到这些核的编号：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">lscpu</span><br><span class="line">Architecture: x86_64</span><br><span class="line">...</span><br><span class="line">NUMA node0 CPU(s): 0-5,12-17</span><br><span class="line">NUMA node1 CPU(s): 6-11,18-23</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>可以看到，NUMA node0 的 CPU 核编号是 0 到 5、12 到 17。其中，0 到 5 是 node0 上的 6 个物理核中的第一个逻辑核的编号，12 到 17 是相应物理核中的第二个逻辑核编号。NUMA node1 的 CPU 核编号规则和 node0 一样。</p>
<p>所以，在绑核时，我们一定要注意，不能想当然地认为第一个 Socket 上的 12 个逻辑核的编号就是 0 到 11。否则，网络中断程序和 Redis 实例就可能绑在了不同的 CPU Socket<br>上。</p>
<p>比如说，如果我们把网络中断程序和 Redis 实例分别绑到编号为 1 和 7 的 CPU 核上，此时，它们仍然是在 2 个 CPU Socket 上，Redis 实例仍然需要跨 Socket 读取网络数据。</p>
<p>所以，你一定要注意 NUMA 架构下 CPU 核的编号方法，这样才不会绑错核。</p>
<p>我们先简单地总结下刚刚学习的内容。在 CPU 多核的场景下，用 taskset 命令把 Redis 实例和一个核绑定，可以减少 Redis 实例在不同核上被来回调度执行的开销，避免较高的尾<br>延迟；在多 CPU 的 NUMA 架构下，如果你对网络中断程序做了绑核操作，建议你同时把 Redis 实例和网络中断程序绑在同一个 CPU Socket 的不同核上，这样可以避免 Redis 跨<br>Socket 访问内存中的网络数据的时间开销。</p>
<p>不过，“硬币都是有两面的”，绑核也存在一定的风险。接下来，我们就来了解下它的潜在风险点和解决方案。</p>
<p>绑核的风险和解决方案：</p>
<p>Redis 除了主线程以外，还有用于 RDB 生成和 AOF 重写的子进程。此外，我们还在之前学习了 Redis 的后台线程。</p>
<p>当我们把 Redis 实例绑到一个 CPU 逻辑核上时，就会导致子进程、后台线程和 Redis 主线程竞争 CPU 资源，一旦子进程或后台线程占用 CPU 时，主线程就会被阻塞，导致 Redis 请求延迟增加。</p>
<p>针对这种情况，我来给你介绍两种解决方案，分别是一个 Redis 实例对应绑一个物理核和优化 Redis 源码。</p>
<p>方案一：一个 Redis 实例对应绑一个物理核</p>
<p>在给 Redis 实例绑核时，我们不要把一个实例和一个逻辑核绑定，而要和一个物理核绑定，也就是说，把一个物理核的 2 个逻辑核都用上。</p>
<p>我们还是以刚才的 NUMA 架构为例，NUMA node0 的 CPU 核编号是 0 到 5、12 到 17。其中，编号 0 和 12、1 和 13、2 和 14 等都是表示一个物理核的 2 个逻辑核。所以，在绑核时，我们使用属于同一个物理核的 2 个逻辑核进行绑核操作。例如，我们执行下面的命令，就把 Redis 实例绑定到了逻辑核 0 和 12 上，而这两个核正好都属于物理核 1。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">taskset -c 0,12 ./redis-server</span><br></pre></td></tr></table></figure>

<p>和只绑一个逻辑核相比，把 Redis 实例和物理核绑定，可以让主线程、子进程、后台线程共享使用 2 个逻辑核，可以在一定程度上缓解 CPU 资源竞争。但是，因为只用了 2 个逻辑核，它们相互之间的 CPU 竞争仍然还会存在。如果你还想进一步减少 CPU 竞争，优化redis代码就先不写了。</p>
<h3 id="波动的响应延迟：如何应对变慢的Redis？"><a href="#波动的响应延迟：如何应对变慢的Redis？" class="headerlink" title="波动的响应延迟：如何应对变慢的Redis？"></a>波动的响应延迟：如何应对变慢的Redis？</h3><p>你可以重点关注下我在图上新增的红色模块，也就是 Redis 自身的操作特性、文件系统和操作系统，它们是影响 Redis 性能的三大要素。</p>
<p><img src="/images/redis-62.jpg" alt="redis-3"></p>
<p><strong>Redis 自身操作特性的影响</strong></p>
<p><strong>1.慢查询命令</strong></p>
<p>慢查询命令，就是指在 Redis 中执行速度慢的命令，这会导致 Redis 延迟增加。Redis 提供的命令操作很多，并不是所有命令都慢，这和命令操作的复杂度有关。所以，我们必须要知道 Redis 的不同命令的复杂度。</p>
<p>比如说，Value 类型为 String 时，GET/SET 操作主要就是操作 Redis 的哈希表索引。这个操作复杂度基本是固定的，即 O(1)。但是，当 Value 类型为 Set 时，SORT、SUNION/SMEMBERS 操作复杂度分别为 O(N+M*log(M)) 和 O(N)。其中，N 为 Set 中的元素个数，M 为 SORT 操作返回的元素个数。这个复杂度就增加了很多。 </p>
<p>那该怎么应对这个问题呢？在这儿，我就要给你排查建议和解决方法了，这也是今天的第一个方法。<br>当你发现 Redis 性能变慢时，可以通过 Redis 日志，或者是 latency monitor 工具，查询变慢的请求，根据请求对应的具体命令以及官方文档，确认下是否采用了复杂度高的慢查询命令。</p>
<p>如果的确有大量的慢查询命令，有两种处理方式：</p>
<blockquote>
<p>1.用其他高效命令代替。比如说，如果你需要返回一个 SET 中的所有成员时，不要使用 SMEMBERS 命令，而是要使用 SSCAN 多次迭代返回，避免一次返回大量数据，造成线程阻塞。</p>
<p>2.当你需要执行排序、交集、并集操作时，可以在客户端完成，而不要用 SORT、SUNION、SINTER 这些命令，以免拖慢Redis 实例。</p>
</blockquote>
<p>当然，如果业务逻辑就是要求使用慢查询命令，那你得考虑采用性能更好的 CPU，更快地完成查询命令，避免慢查询的影响。</p>
<p>还有一个比较容易忽略的慢查询命令，就是 KEYS。它用于返回和输入模式匹配的所有 key，例如，以下命令返回所有包含“name”字符串的 keys。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">redis&gt;</span> KEYS *name*</span><br><span class="line">1) "lastname"</span><br><span class="line">2) "firstname"</span><br></pre></td></tr></table></figure>

<p>因为 KEYS 命令需要遍历存储的键值对，所以操作延时高。如果你不了解它的实现而使用了它，就会导致 Redis 性能变慢。所以，KEYS 命令一般不被建议用于生产环境中。</p>
<p><strong>2.过期 key 操作</strong></p>
<p>接下来，我们来看过期 key 的自动删除机制。它是 Redis 用来回收内存空间的常用机制，应用广泛，本身就会引起 Redis 操作阻塞，导致性能变慢，所以，你必须要知道该机制对性能的影响。</p>
<p>Redis 键值对的 key 可以设置过期时间。默认情况下，Redis 每 100 毫秒会删除一些过期 key，具体的算法如下：</p>
<blockquote>
<p>1.采样 ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP 个数的 key，并将其中过期的 key 全部删除；</p>
<p>2.如果超过 25% 的 key 过期了，则重复删除的过程，直到过期 key 的比例降至 25% 以下。</p>
</blockquote>
<p>ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP 是 Redis 的一个参数，默认是 20，那么，一秒内基本有 200 个过期 key 会被删除。这一策略对清除过期 key、释放内存空间很有帮助。如果每秒钟删除 200 个过期 key，并不会对 Redis 造成太大影响。</p>
<p>但是，如果触发了上面这个算法的第二条，Redis 就会一直删除以释放内存空间。注意，删除操作是阻塞的（Redis 4.0 后可以用异步线程机制来减少阻塞影响）。所以，一旦该条件触发，Redis 的线程就会一直执行删除，这样一来，就没办法正常服务其他的键值操作了，就会进一步引起其他键值操作的延迟增加，Redis 就会变慢。</p>
<p>那么，算法的第二条是怎么被触发的呢？其中一个重要来源，就是频繁使用带有相同时间参数的 EXPIREAT 命令设置过期 key，这就会导致，在同一秒内有大量的 key 同时过期。</p>
<p>现在，我就要给出第二条排查建议和解决方法了。</p>
<p>你要检查业务代码在使用 EXPIREAT 命令设置 key 过期时间时，是否使用了相同的 UNIX 时间戳，有没有使用 EXPIRE 命令给批量的 key 设置相同的过期秒数。因为，这都会造成大量 key 在同一时间过期，导致性能变慢。</p>
<p>遇到这种情况时，千万不要嫌麻烦，你首先要根据实际业务的使用需求，决定 EXPIREAT 和 EXPIRE 的过期时间参数。其次，如果一批 key 的确是同时过期，你还可以在 EXPIREAT 和 EXPIRE 的过期时间参数上，加上一个一定大小范围内的随机数，这样，既保证了 key 在一个邻近时间范围内被删除，又避免了同时过期造成的压力。</p>
<p><strong>3.文件系统：AOF 模式</strong></p>
<p>为了保证数据可靠性，Redis 会采用 AOF 日志或 RDB 快照。其中，AOF 日志提供了三种日志写回策略：no、everysec、always。这三种写回策略依赖文件系统的两个系统调用完成，也就是 write 和 fsync。</p>
<p>write 只要把日志记录写到内核缓冲区，就可以返回了，并不需要等待日志实际写回到磁盘；而 fsync 需要把日志记录写回到磁盘后才能返回，时间较长。下面这张表展示了三种写回策略所执行的系统调用。</p>
<p><img src="/images/redis-63.jpg" alt="redis-3"></p>
<p>当写回策略配置为 everysec 和 always 时，Redis 需要调用 fsync 把日志写回磁盘。但是，这两种写回策略的具体执行情况还不太一样。</p>
<p>在使用 everysec 时，Redis 允许丢失一秒的操作记录，所以，Redis 主线程并不需要确保每个操作记录日志都写回磁盘。而且，fsync 的执行时间很长，如果是在 Redis 主线程中<br>执行 fsync，就容易阻塞主线程。所以，<strong>当写回策略配置为 everysec 时，Redis 会使用后台的子线程异步完成 fsync 的操作</strong>。</p>
<p>而对于 always 策略来说，Redis 需要确保每个操作记录日志都写回磁盘，如果用后台子线程异步完成，主线程就无法及时地知道每个操作是否已经完成了，这就不符合 always 策略的要求了。所以，<strong>always 策略并不使用后台子线程来执行</strong>。</p>
<p>另外，在使用 AOF 日志时，为了避免日志文件不断增大，Redis 会执行 AOF 重写，生成体量缩小的新的 AOF 日志文件。AOF 重写本身需要的时间很长，也容易阻塞 Redis 主线<br>程，所以，<strong>Redis 使用子进程来进行 AOF 重写</strong>。</p>
<p>但是，这里有一个潜在的风险点：AOF 重写会对磁盘进行大量 IO 操作，同时，fsync 又需要等到数据写到磁盘后才能返回，所以，当 AOF 重写的压力比较大时，就会导致 fsync 被<br>阻塞。<strong>虽然 fsync 是由后台子线程负责执行的，但是，主线程会监控 fsync 的执行进度</strong>。</p>
<p>当主线程使用后台子线程执行了一次 fsync，需要再次把新接收的操作记录写回磁盘时，如果主线程发现上一次的 fsync 还没有执行完，那么它就会阻塞。所以，如果后台子线程执<br>行的 fsync 频繁阻塞的话（比如 AOF 重写占用了大量的磁盘 IO 带宽），主线程也会阻塞，导致 Redis 性能变慢。</p>
<p><img src="/images/redis-64.jpg" alt="redis-3"></p>
<p>好了，说到这里，你已经了解了，由于 fsync 后台子线程和 AOF 重写子进程的存在，主 IO 线程一般不会被阻塞。但是，如果在重写日志时，AOF 重写子进程的写入量比较大，fsync 线程也会被阻塞，进而阻塞主线程，导致延迟增加。现在，我来给出排查和解决建议。</p>
<p>首先，你可以检查下 Redis 配置文件中的 appendfsync 配置项，该配置项的取值表明了 Redis 实例使用的是哪种 AOF 日志写回策略，如下所示：</p>
<p><img src="/images/redis-65.jpg" alt="redis-3"></p>
<p>如果 AOF 写回策略使用了 everysec 或 always 配置，请先确认下业务方对数据可靠性的要求，明确是否需要每一秒或每一个操作都记日志。有的业务方不了解 Redis AOF 机制，很可能就直接使用数据可靠性最高等级的 always 配置了。其实，在有些场景中（例如 Redis 用于缓存），数据丢了还可以从后端数据库中获取，并不需要很高的数据可靠性。</p>
<p>如果业务应用对延迟非常敏感，但同时允许一定量的数据丢失，那么，可以把配置项 no-appendfsync-on-rewrite 设置为 yes，如下所示：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">no-appendfsync-on-rewrite yes</span><br></pre></td></tr></table></figure>

<p>这个配置项设置为 yes 时，表示在 AOF 重写时，不进行 fsync 操作。也就是说，Redis 实例把写命令写到内存后，不调用后台线程进行 fsync 操作，就可以直接返回了。当然，如<br>果此时实例发生宕机，就会导致数据丢失。反之，如果这个配置项设置为 no（也是默认配置），在 AOF 重写时，Redis 实例仍然会调用后台线程进行 fsync 操作，这就会给实例带来阻塞。</p>
<p>如果的确需要高性能，同时也需要高可靠数据保证，我建议你考虑采用高速的固态硬盘作为 AOF 日志的写入设备。高速固态盘的带宽和并发度比传统的机械硬盘的要高出 10 倍及以上。在 AOF 重写和 fsync 后台线程同时执行时，固态硬盘可以提供较为充足的磁盘 IO 资源，让 AOF 重写和 fsync 后台线程的磁盘 IO 资源竞争减少，从而降低对 Redis 的性能影响。</p>
<p><strong>4.操作系统内存swap和内存大页</strong></p>
<p>内存 swap 是操作系统里将内存数据在内存和磁盘间来回换入和换出的机制，涉及到磁盘的读写，所以，一旦触发 swap，无论是被换入数据的进程，还是被换出数据的进程，其性能都会受到慢速磁盘读写的影响。</p>
<p>Redis 是内存数据库，内存使用量大，如果没有控制好内存的使用量，或者和其他内存需求大的应用一起运行了，就可能受到 swap 的影响，而导致性能变慢。</p>
<p>这一点对于 Redis 内存数据库而言，显得更为重要：正常情况下，Redis 的操作是直接通过访问内存就能完成，一旦 swap 被触发了，Redis 的请求操作需要等到磁盘数据读写完成才行。而且，和我刚才说的 AOF 日志文件读写使用 fsync 线程不同，swap 触发后影响的是 Redis 主 IO 线程，这会极大地增加 Redis 的响应时间。</p>
<p>说到这儿，我想给你分享一个我曾经遇到过的因为 swap 而导致性能降低的例子。</p>
<p>在正常情况下，我们运行的一个实例完成 5000 万个 GET 请求时需要 300s，但是，有一次，这个实例完成 5000 万 GET 请求，花了将近 4 个小时的时间。经过问题复现，我们发现，当时 Redis 处理请求用了近 4 小时的情况下，该实例所在的机器已经发生了 swap。从 300s 到 4 个小时，延迟增加了将近 48 倍，可以看到 swap 对性能造成的严重影响。</p>
<p>那么，什么时候会触发 swap 呢？</p>
<p>通常，<strong>触发 swap 的原因主要是物理机器内存不足</strong>，对于 Redis 而言，有两种常见的情况：</p>
<blockquote>
<p>Redis 实例自身使用了大量的内存，导致物理机器的可用内存不足；</p>
<p>和 Redis 实例在同一台机器上运行的其他进程，在进行大量的文件读写操作。文件读写本身会占用系统内存，这会导致分配给 Redis 实例的内存量变少，进而触发 Redis 发生 swap。</p>
</blockquote>
<p>针对这个问题，我也给你提供一个解决思路：<strong>增加机器的内存或者使用 Redis 集群</strong>。</p>
<p>操作系统本身会在后台记录每个进程的 swap 使用情况，即有多少数据量发生了 swap。你可以先通过下面的命令查看 Redis 的进程号，这里是 5332。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> redis-cli info | grep process_id</span><br><span class="line">process_id: 5332</span><br></pre></td></tr></table></figure>

<p>然后，进入 Redis 所在机器的 /proc 目录下的该进程目录中：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /proc/5332</span><br></pre></td></tr></table></figure>

<p>最后，运行下面的命令，查看该 Redis 进程的使用情况。在这儿，我只截取了部分结果：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span>cat smaps | egrep '^(Swap|Size)'</span><br><span class="line">Size: 584 kB</span><br><span class="line">Swap: 0 kB</span><br><span class="line">Size: 4 kB</span><br><span class="line">Swap: 4 kB</span><br><span class="line">Size: 4 kB</span><br><span class="line">Swap: 0 kB</span><br><span class="line">Size: 462044 kB</span><br><span class="line">Swap: 462008 kB</span><br><span class="line">Size: 21392 kB</span><br><span class="line">Swap: 0 kB</span><br></pre></td></tr></table></figure>

<p>每一行 Size 表示的是 Redis 实例所用的一块内存大小，而 Size 下方的 Swap 和它相对应，表示这块 Size 大小的内存区域有多少已经被换出到磁盘上了。如果这两个值相等，就<br>表示这块内存区域已经完全被换出到磁盘了。</p>
<p>作为内存数据库，Redis 本身会使用很多大小不一的内存块，所以，你可以看到有很多 Size 行，有的很小，就是 4KB，而有的很大，例如 462044KB。不同内存块被换出到磁盘上的大小也不一样，例如刚刚的结果中的第一个 4KB 内存块，它下方的 Swap 也是 4KB，这表示这个内存块已经被换出了；另外，462044KB 这个内存块也被换出了 462008KB，差不多有 462MB。</p>
<p>这里有个重要的地方，我得提醒你一下，当出现百 MB，甚至 GB 级别的 swap 大小时，就表明，此时，Redis 实例的内存压力很大，很有可能会变慢。所以，swap 的大小是排查 Redis 性能变慢是否由 swap 引起的重要指标。</p>
<p>一旦发生内存 swap，最直接的解决方法就是增加机器内存。如果该实例在一个 Redis 切片集群中，可以增加 Redis 集群的实例个数，来分摊每个实例服务的数据量，进而减少每个实例所需的内存量。</p>
<p>当然，如果 Redis 实例和其他操作大量文件的程序（例如数据分析程序）共享机器，你可以将 Redis 实例迁移到单独的机器上运行，以满足它的内存需求量。如果该实例正好是Redis 主从集群中的主库，而从库的内存很大，也可以考虑进行主从切换，把大内存的从库变成主库，由它来处理客户端请求。</p>
<p><strong>操作系统：内存大页</strong></p>
<p>除了内存 swap，还有一个和内存相关的因素，即内存大页机制（Transparent Huge Page, THP），也会影响 Redis 性能。</p>
<p>Linux 内核从 2.6.38 开始支持内存大页机制，该机制支持 2MB 大小的内存页分配，而常规的内存页分配是按 4KB 的粒度来执行的。</p>
<p>很多人都觉得：“Redis 是内存数据库，内存大页不正好可以满足 Redis 的需求吗？而且在分配相同的内存量时，内存大页还能减少分配次数，不也是对 Redis 友好吗?”</p>
<p>其实，系统的设计通常是一个取舍过程，我们称之为 trade-off。很多机制通常都是优势和劣势并存的。Redis 使用内存大页就是一个典型的例子。</p>
<p>虽然内存大页可以给 Redis 带来内存分配方面的收益，但是，不要忘了，Redis 为了提供数据可靠性保证，需要将数据做持久化保存。这个写入过程由额外的线程执行，所以，此时，Redis 主线程仍然可以接收客户端写请求。客户端的写请求可能会修改正在进行持久化的数据。在这一过程中，Redis 就会采用写时复制机制，也就是说，一旦有数据要被修改，Redis 并不会直接修改内存中的数据，而是将这些数据拷贝一份，然后再进行修改。</p>
<p>如果采用了内存大页，那么，即使客户端请求只修改 100B 的数据，Redis 也需要拷贝 2MB 的大页。相反，如果是常规内存页机制，只用拷贝 4KB。两者相比，你可以看到，当客户端请求修改或新写入数据较多时，内存大页机制将导致大量的拷贝，这就会影响 Redis 正常的访存操作，最终导致性能变慢。</p>
<p>那该怎么办呢？很简单，关闭内存大页，就行了。</p>
<p>首先，我们要先排查下内存大页。方法是：在 Redis 实例运行的机器上执行如下命令:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /sys/kernel/mm/transparent_hugepage/enabled</span><br></pre></td></tr></table></figure>

<p>如果执行结果是 always，就表明内存大页机制被启动了；如果是 never，就表示，内存大页机制被禁止。在实际生产环境中部署时，我建议你不要使用内存大页机制，操作也很简单，只需要执行下面的命令就可以了：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo never /sys/kernel/mm/transparent_hugepage/enabled</span><br></pre></td></tr></table></figure>

<p>为了方便你应用，我给你梳理了一个包含 9 个检查点的 Checklist，希望你在遇到 Redis 性能变慢时，按照这些步骤逐一检查，高效地解决问题。</p>
<blockquote>
<p>1.获取 Redis 实例在当前环境下的基线性能。</p>
<ol start="2">
<li><p>是否用了慢查询命令？如果是的话，就使用其他命令替代慢查询命令，或者把聚合计算命令放在客户端做。</p>
</li>
<li><p>是否对过期 key 设置了相同的过期时间？对于批量删除的 key，可以在每个 key 的过期时间上加一个随机数，避免同时删除。</p>
</li>
<li><p>是否存在 bigkey？ 对于 bigkey 的删除操作，如果你的 Redis 是 4.0 及以上的版本，可以直接利用异步线程机制减少主线程阻塞；如果是 Redis 4.0 以前的版本，可以使用 SCAN 命令迭代删除；对于 bigkey 的集合查询和聚合操作，可以使用 SCAN 命令在客户端完成。</p>
</li>
<li><p>Redis AOF 配置级别是什么？业务层面是否的确需要这一可靠性级别？如果我们需要高性能，同时也允许数据丢失，可以将配置项 no-appendfsync-on-rewrite 设置为yes，避免 AOF 重写和 fsync 竞争磁盘 IO 资源，导致 Redis 延迟增加。当然， 如果既需要高性能又需要高可靠性，最好使用高速固态盘作为 AOF 日志的写入盘。</p>
</li>
<li><p>Redis 实例的内存使用是否过大？发生 swap 了吗？如果是的话，就增加机器内存，或者是使用 Redis 集群，分摊单机 Redis 的键值对数量和内存压力。同时，要避免出现 Redis 和其他内存需求大的应用共享机器的情况。</p>
</li>
<li><p>在 Redis 实例的运行环境中，是否启用了透明大页机制？如果是的话，直接关闭内存大页机制就行了。</p>
</li>
<li><p>是否运行了 Redis 主从集群？如果是的话，把主库实例的数据量大小控制在 2~4GB，以免主从复制时，从库因加载大的 RDB 文件而阻塞。</p>
</li>
<li><p>是否使用了多核 CPU 或 NUMA 架构的机器运行 Redis 实例？使用多核 CPU 时，可以给 Redis 实例绑定物理核；使用 NUMA 架构时，注意把 Redis 实例和网络中断处理程序运行在同一个 CPU Socket 上</p>
</li>
</ol>
</blockquote>
<h3 id="删除数据后，为什么内存占用率还是很高？"><a href="#删除数据后，为什么内存占用率还是很高？" class="headerlink" title="删除数据后，为什么内存占用率还是很高？"></a>删除数据后，为什么内存占用率还是很高？</h3><p>在使用 Redis 时，我们经常会遇到这样一个问题：明明做了数据删除，数据量已经不大了，为什么使用 top 命令查看时，还会发现 Redis 占用了很多内存呢？</p>
<p>实际上，这是因为，当数据删除后，Redis 释放的内存空间会由内存分配器管理，并不会立即返回给操作系统。所以，操作系统仍然会记录着给 Redis 分配了大量内存。</p>
<p>但是，这往往会伴随一个潜在的风险点：Redis 释放的内存空间可能并不是连续的，那么，这些不连续的内存空间很有可能处于一种闲置的状态。这就会导致一个问题：虽然有空闲空间，Redis 却无法用来保存数据，不仅会减少 Redis 能够实际保存的数据量，还会降低 Redis 运行机器的成本回报率。</p>
<p><strong>内存碎片是如何形成的？</strong></p>
<p><strong>内因：内存分配器的分配策略</strong></p>
<p>内存分配器的分配策略就决定了操作系统无法做到“按需分配”。这是因为，内存分配器一般是按固定大小来分配内存，而不是完全按照应用程序申请的内存空间大小给程序分配。</p>
<p>Redis 可以使用 libc、jemalloc、tcmalloc 多种内存分配器来分配内存，默认使用 jemalloc。接下来，我就以 jemalloc 为例，来具体解释一下。其他分配器也存在类似的问<br>题。</p>
<p>jemalloc 的分配策略之一，是按照一系列固定的大小划分内存空间，例如 8 字节、16 字节、32 字节、48 字节，…, 2KB、4KB、8KB 等。当程序申请的内存最接近某个固定值<br>时，jemalloc 会给它分配相应大小的空间。</p>
<p>这样的分配方式本身是为了减少分配次数。例如，Redis 申请一个 20 字节的空间保存数据，jemalloc 就会分配 32 字节，此时，如果应用还要写入 10 字节的数据，Redis 就不用再向操作系统申请空间了，因为刚才分配的 32 字节已经够用了，这就避免了一次分配操作。</p>
<p>但是，如果 Redis 每次向分配器申请的内存空间大小不一样，这种分配方式就会有形成碎片的风险，而这正好来源于 Redis 的外因了。</p>
<p><strong>外因：键值对大小不一样和删改操作</strong></p>
<p>Redis 通常作为共用的缓存系统或键值数据库对外提供服务，所以，不同业务应用的数据都可能保存在 Redis 中，这就会带来不同大小的键值对。这样一来，Redis 申请内存空间分配时，本身就会有大小不一的空间需求。这是第一个外因。</p>
<p>但是咱们刚刚讲过，内存分配器只能按固定大小分配内存，所以，分配的内存空间一般都会比申请的空间大一些，不会完全一致，这本身就会造成一定的碎片，降低内存空间存储效率。</p>
<p>比如说，应用 A 保存 6 字节数据，jemalloc 按分配策略分配 8 字节。如果应用 A 不再保存新数据，那么，这里多出来的 2 字节空间就是内存碎片了，如下图所示：</p>
<p><img src="/images/redis-66.jpg" alt="redis-3"></p>
<p>第二个外因是，这些键值对会被修改和删除，这会导致空间的扩容和释放。具体来说，一方面，如果修改后的键值对变大或变小了，就需要占用额外的空间或者释放不用的空间。</p>
<p>另一方面，删除的键值对就不再需要内存空间了，此时，就会把空间释放出来，形成空闲空间。我画了下面这张图来帮助你理解。</p>
<p><img src="/images/redis-67.jpg" alt="redis-3"></p>
<p>一开始，应用 A、B、C、D 分别保存了 3、1、2、4 字节的数据，并占据了相应的内存空间。然后，应用 D 删除了 1 个字节，这个 1 字节的内存空间就空出来了。紧接着，应用 A 修改了数据，从 3 字节变成了 4 字节。为了保持 A 数据的空间连续性，操作系统就需要把 B 的数据拷贝到别的空间，比如拷贝到 D 刚刚释放的空间中。此时，应用 C 和 D 也分别删除了 2 字节和 1 字节的数据，整个内存空间上就分别出现了 2 字节和1 字节的空闲碎片。如果应用 E 想要一个 3 字节的连续空间，显然是不能得到满足的。因为，虽然空间总量够，但却是碎片空间，并不是连续的。</p>
<p>好了，到这里，我们就知道了造成内存碎片的内外因素，其中，内存分配器策略是内因，而 Redis 的负载属于外因，包括了大小不一的键值对和键值对修改删除带来的内存空间变化。</p>
<p>大量内存碎片的存在，会造成 Redis 的内存实际利用率变低，接下来，我们就要来解决这个问题了。不过，在解决问题前，我们要先判断 Redis 运行过程中是否存在内存碎片。</p>
<p><strong>如何判断是否有内存碎片？</strong></p>
<p>Redis 是内存数据库，内存利用率的高低直接关系到 Redis 运行效率的高低。为了让用户能监控到实时的内存使用情况，Redis 自身提供了 INFO 命令，可以用来查询内存使用的<br>详细信息，命令如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">INFO memory</span><br><span class="line"><span class="meta">#</span> Memory</span><br><span class="line">used_memory:1073741736</span><br><span class="line">used_memory_human:1024.00M</span><br><span class="line">used_memory_rss:1997159792</span><br><span class="line">used_memory_rss_human:1.86G</span><br><span class="line">...</span><br><span class="line">mem_fragmentation_ratio:1.86</span><br></pre></td></tr></table></figure>

<p>这里有一个 mem_fragmentation_ratio 的指标，它表示的就是 Redis 当前的内存碎片率。那么，这个碎片率是怎么计算的呢？其实，就是上面的命令中的两个指标 used_memory_rss 和 used_memory 相除的结果。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mem_fragmentation_ratio = used_memory_rss/ used_memory</span><br></pre></td></tr></table></figure>

<p>used_memory_rss 是操作系统实际分配给 Redis 的物理内存空间，里面就包含了碎片；而 used_memory 是 Redis 为了保存数据实际申请使用的空间。</p>
<p>我简单举个例子。例如，Redis 申请使用了 100 字节（used_memory），操作系统实际分配了 128 字节（used_memory_rss），此时mem_fragmentation_ratio 就是 1.28。</p>
<p>那么，知道了这个指标，我们该如何使用呢？在这儿，我提供一些经验阈值：</p>
<blockquote>
<p>mem_fragmentation_ratio 大于 1 但小于 1.5。这种情况是合理的。这是因为，刚才我介绍的那些因素是难以避免的。毕竟，内因的内存分配器是一定要使用的，分配策略都是通用的，不会轻易修改；而外因由 Redis 负载决定，也无法限制。所以，存在内存碎片也是正常的。</p>
<p>mem_fragmentation_ratio 大于 1.5 。这表明内存碎片率已经超过了 50%。一般情况下，这个时候，我们就需要采取一些措施来降低内存碎片率了。</p>
</blockquote>
<p><strong>如何清理内存碎片？</strong></p>
<p>当 Redis 发生内存碎片后，一个“简单粗暴”的方法就是重启 Redis 实例。当然，这并不是一个“优雅”的方法，毕竟，重启 Redis 会带来两个后果：</p>
<blockquote>
<p>如果 Redis 中的数据没有持久化，那么，数据就会丢失；</p>
<p>即使 Redis 数据持久化了，我们还需要通过 AOF 或 RDB 进行恢复，恢复时长取决于<br>AOF 或 RDB 的大小，如果只有一个 Redis 实例，恢复阶段无法提供服务。</p>
</blockquote>
<p>所以，还有什么其他好办法吗?</p>
<p>幸运的是，从 4.0-RC3 版本以后，Redis 自身提供了一种内存碎片自动清理的方法，我们先来看这个方法的基本机制。内存碎片清理，简单来说，就是“搬家让位，合并空间”。</p>
<p>这么一说，碎片清理的机制就很容易理解了。当有数据把一块连续的内存空间分割成好几块不连续的空间时，操作系统就会把数据拷贝到别处。此时，数据拷贝需要能把这些数据原来占用的空间都空出来，把原本不连续的内存空间变成连续的空间。否则，如果数据拷贝后，并没有形成连续的内存空间，这就不能算是清理了。</p>
<p>我画一张图来解释一下。</p>
<p><img src="/images/redis-68.jpg" alt="redis-3"></p>
<p>在进行碎片清理前，这段 10 字节的空间中分别有 1 个 2 字节和 1 个 1 字节的空闲空间，只是这两个空间并不连续。操作系统在清理碎片时，会先把应用 D 的数据拷贝到 2 字节的空闲空间中，并释放 D 原先所占的空间。然后，再把 B 的数据拷贝到 D 原来的空间中。这样一来，这段 10 字节空间的最后三个字节就是一块连续空间了。到这里，碎片清理结束。</p>
<p>不过，需要注意的是：<strong>碎片清理是有代价的</strong>，操作系统需要把多份数据拷贝到新位置，把原有空间释放出来，这会带来时间开销。因为 Redis 是单线程，在数据拷贝时，Redis 只能等着，这就导致 Redis 无法及时处理请求，性能就会降低。而且，有的时候，数据拷贝还需要注意顺序，就像刚刚说的清理内存碎片的例子，操作系统需要先拷贝 D，并释放 D 的空间后，才能拷贝 B。这种对顺序性的要求，会进一步增加 Redis 的等待时间，导致性能降低。</p>
<p>那么，有什么办法可以尽量缓解这个问题吗？这就要提到，Redis 专门为自动内存碎片清理功机制设置的参数了。我们可以通过设置参数，来控制碎片清理的开始和结束时机，以及占用的 CPU 比例，从而减少碎片清理对 Redis 本身请求处理的性能影响。</p>
<p>首先，Redis 需要启用自动内存碎片清理，可以把activedefrag 配置项设置为 yes，命令如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">config set activedefrag yes</span><br></pre></td></tr></table></figure>

<p>这个命令只是启用了自动清理功能，但是，具体什么时候清理，会受到下面这两个参数的控制。这两个参数分别设置了触发内存清理的一个条件，如果同时满足这两个条件，就开始清理。在清理的过程中，只要有一个条件不满足了，就停止自动清理。</p>
<blockquote>
<p>active-defrag-ignore-bytes 100mb：表示内存碎片的字节数达到 100MB 时，开始清理；</p>
<p>active-defrag-threshold-lower 10：表示内存碎片空间占操作系统分配给 Redis 的总空间比例达到 10% 时，开始清理。</p>
</blockquote>
<p>为了尽可能减少碎片清理对 Redis 正常请求处理的影响，自动内存碎片清理功能在执行时，还会监控清理操作占用的 CPU 时间，而且还设置了两个参数，分别用于控制清理操作占用的 CPU 时间比例的上、下限，既保证清理工作能正常进行，又避免了降低 Redis 性能。这两个参数具体如下：</p>
<blockquote>
<p>active-defrag-cycle-min 25： 表示自动清理过程所用 CPU 时间的比例不低于 25%，保证清理能正常开展；</p>
<p>active-defrag-cycle-max 75：表示自动清理过程所用 CPU 时间的比例不高于 75%，一旦超过，就停止清理，从而避免在清理时，大量的内存拷贝阻塞 Redis，导致响应延迟升高。</p>
</blockquote>
<p>自动内存碎片清理机制在控制碎片清理启停的时机上，既考虑了碎片的空间占比、对 Redis 内存使用效率的影响，还考虑了清理机制本身的 CPU 时间占比、对 Redis 性能的影响。而且，清理机制还提供了 4 个参数，让我们可以根据实际应用中的数据量需求和性能要求灵活使用，建议你在实践中好好地把这个机制用起来。</p>
<h3 id="缓冲区：一个可能引发“惨案”的地方"><a href="#缓冲区：一个可能引发“惨案”的地方" class="headerlink" title="缓冲区：一个可能引发“惨案”的地方"></a>缓冲区：一个可能引发“惨案”的地方</h3><p>缓冲区的功能其实很简单，主要就是用一块内存空间来暂时存放命令数据，以免出现因为数据和命令的处理速度慢于发送速度而导致的数据丢失和性能问题。但因为缓冲区的内存空间有限，如果往里面写入数据的速度持续地大于从里面读取数据的速度，就会导致缓冲区需要越来越多的内存来暂存数据。当缓冲区占用的内存超出了设定的上限阈值时，就会出现缓冲区溢出。</p>
<p>如果发生了溢出，就会丢数据了。那是不是不给缓冲区的大小设置上限，就可以了呢？显然不是，随着累积的数据越来越多，缓冲区占用内存空间越来越大，一旦耗尽了 Redis 实例所在机器的可用内存，就会导致 Redis 实例崩溃。</p>
<p>我们知道，Redis 是典型的 client-server 架构，所有的操作命令都需要通过客户端发送给服务器端。所以，缓冲区在 Redis 中的一个主要应用场景，就是在客户端和服务器端之间<br>进行通信时，用来暂存客户端发送的命令数据，或者是服务器端返回给客户端的数据结果。此外，缓冲区的另一个主要应用场景，是在主从节点间进行数据同步时，用来暂存主节点接收的写命令和数据。</p>
<p><strong>客户端输入和输出缓冲区</strong></p>
<p>为了避免客户端和服务器端的请求发送和处理速度不匹配，服务器端给每个连接的客户端都设置了一个输入缓冲区和输出缓冲区，我们称之为客户端输入缓冲区和输出缓冲区。<br>输入缓冲区会先把客户端发送过来的命令暂存起来，Redis 主线程再从输入缓冲区中读取命令，进行处理。当 Redis 主线程处理完数据后，会把结果写入到输出缓冲区，再通过输出缓冲区返回给客户端，如下图所示：</p>
<p><img src="/images/redis-69.jpg" alt="redis-3"></p>
<p>如何应对输入缓冲区溢出？</p>
<p>我们前面已经分析过了，输入缓冲区就是用来暂存客户端发送的请求命令的，所以可能导致溢出的情况主要是下面两种：</p>
<blockquote>
<p>写入了 bigkey，比如一下子写入了多个百万级别的集合类型数据；</p>
<p>服务器端处理请求的速度过慢，例如，Redis 主线程出现了间歇性阻塞，无法及时处理正常发送的请求，导致客户端发送的请求在缓冲区越积越多。</p>
</blockquote>
<p>要查看和服务器端相连的每个客户端对输入缓冲区的使用情况，我们可以使用 CLIENT LIST 命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CLIENT LIST</span><br><span class="line">id=5 addr=127.0.0.1:50487 fd=9 name= age=4 idle=0 flags=N db=0 sub=0 psub=0 mu</span><br></pre></td></tr></table></figure>

<p>CLIENT 命令返回的信息虽然很多，但我们只需要重点关注两类信息就可以了。</p>
<p>一类是与服务器端连接的客户端的信息。这个案例展示的是一个客户端的输入缓冲区情况，如果有多个客户端，输出结果中的 addr 会显示不同客户端的 IP 和端口号。</p>
<p>另一类是与输入缓冲区相关的三个参数：</p>
<blockquote>
<p>cmd，表示客户端最新执行的命令。这个例子中执行的是 CLIENT 命令。</p>
<p>qbuf，表示输入缓冲区已经使用的大小。这个例子中的 CLIENT 命令已使用了 26 字节大小的缓冲区。</p>
<p>qbuf-free，表示输入缓冲区尚未使用的大小。这个例子中的 CLIENT 命令还可以使用 32742 字节的缓冲区。qbuf 和 qbuf-free 的总和就是，Redis 服务器端当前为已连接的这个客户端分配的缓冲区总大小。这个例子中总共分配了 26 + 32742 = 32768 字节，也就是 32KB 的缓冲区。</p>
</blockquote>
<p>有了 CLIENT LIST 命令，我们就可以通过输出结果来判断客户端输入缓冲区的内存占用情况了。如果 qbuf 很大，而同时 qbuf-free 很小，就要引起注意了，因为这时候输入缓冲区已经占用了很多内存，而且没有什么空闲空间了。此时，客户端再写入大量命令的话，就会引起客户端输入缓冲区溢出，Redis 的处理办法就是把客户端连接关闭，结果就是业务程序无法进行数据存取了。</p>
<p>通常情况下，Redis 服务器端不止服务一个客户端，当多个客户端连接占用的内存总量，超过了 Redis 的 maxmemory 配置项时（例如 4GB），就会触发 Redis 进行数据淘汰。</p>
<p>一旦数据被淘汰出 Redis，再要访问这部分数据，就需要去后端数据库读取，这就降低了业务应用的访问性能。此外，更糟糕的是，如果使用多个客户端，导致 Redis 内存占用过大，也会导致内存溢出（out-of-memory）问题，进而会引起 Redis 崩溃，给业务应用造成严重影响。</p>
<p>所以，我们必须得想办法避免输入缓冲区溢出。我们可以从两个角度去考虑如何避免，一是把缓冲区调大，二是从数据命令的发送和处理速度入手。</p>
<p>我们先看看，到底有没有办法通过参数调整输入缓冲区的大小呢？答案是没有。</p>
<p>Redis 的客户端输入缓冲区大小的上限阈值，在代码中就设定为了 1GB。也就是说，Redis 服务器端允许为每个客户端最多暂存 1GB 的命令和数据。1GB 的大小，对于一般的生产环境已经是比较合适的了。一方面，这个大小对于处理绝大部分客户端的请求已经够用了；</p>
<p>另一方面，如果再大的话，Redis 就有可能因为客户端占用了过多的内存资源而崩溃。</p>
<p>所以，Redis 并没有提供参数让我们调节客户端输入缓冲区的大小。如果要避免输入缓冲区溢出，那我们就只能从数据命令的发送和处理速度入手，也就是前面提到的避免客户端写入 bigkey，以及避免 Redis 主线程阻塞。接下来，我们再来看看输出缓冲区的溢出问题。</p>
<p><strong>如何应对输出缓冲区溢出？</strong></p>
<p>Redis 的输出缓冲区暂存的是 Redis 主线程要返回给客户端的数据。一般来说，主线程返回给客户端的数据，既有简单且大小固定的 OK 响应（例如，执行 SET 命令）或报错信息，也有大小不固定的、包含具体数据的执行结果（例如，执行 HGET 命令）。</p>
<p>因此，Redis 为每个客户端设置的输出缓冲区也包括两部分：一部分，是一个大小为 16KB 的固定缓冲空间，用来暂存 OK 响应和出错信息；另一部分，是一个可以动态增加的缓冲空间，用来暂存大小可变的响应结果。</p>
<p>那什么情况下会发生输出缓冲区溢出呢？ 我为你总结了三种：</p>
<blockquote>
<p>服务器端返回 bigkey 的大量结果；</p>
<p>执行了 MONITOR 命令；</p>
<p>缓冲区大小设置得不合理。</p>
</blockquote>
<p>其中，bigkey 原本就会占用大量的内存空间，所以服务器端返回的结果包含 bigkey，必然会影响输出缓冲区。接下来，我们就重点看下，执行 MONITOR 命令和设置缓冲区大小这两种情况吧。</p>
<p>MONITOR 命令是用来监测 Redis 执行的。执行这个命令之后，就会持续输出监测到的各个命令操作，如下所示：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">MONITOR</span><br><span class="line">OK</span><br><span class="line">1600617456.437129 [0 127.0.0.1:50487] "COMMAND"</span><br><span class="line">1600617477.289667 [0 127.0.0.1:50487] "info" "memory"</span><br></pre></td></tr></table></figure>

<p>到这里，你有没有看出什么问题呢？MONITOR 的输出结果会持续占用输出缓冲区，并越占越多，最后的结果就是发生溢出。所以，我要给你一个小建议：MONITOR 命令主要用在调试环境中，不要在线上生产环境中持续使用 MONITOR。当然，如果在线上环境中偶尔使用 MONITOR 检查 Redis 的命令执行情况，是没问题的。</p>
<p>接下来，我们看下输出缓冲区大小设置的问题。和输入缓冲区不同，我们可以通过 client-output-buffer-limit 配置项，来设置缓冲区的大小。具体设置的内容包括两方面：</p>
<blockquote>
<p>设置缓冲区大小的上限阈值；</p>
<p>设置输出缓冲区持续写入数据的数量上限阈值，和持续写入数据的时间的上限阈值。</p>
</blockquote>
<p>在具体使用 client-output-buffer-limit 来设置缓冲区大小的时候，我们需要先区分下客户端的类型。</p>
<p>对于和 Redis 实例进行交互的应用程序来说，主要使用两类客户端和 Redis 服务器端交互，分别是常规和 Redis 服务器端进行读写命令交互的普通客户端，以及订阅了 Redis 频道的订阅客户端。此外，在 Redis 主从集群中，主节点上也有一类客户端（从节点客户端）用来和从节点进行数据同步，我会在介绍主从集群中的缓冲区时，向你具体介绍。</p>
<p>当我们给普通客户端设置缓冲区大小时，通常可以在 Redis 配置文件中进行这样的设置：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">client-output-buffer-limit normal 0 0 0</span><br></pre></td></tr></table></figure>

<p>其中，normal 表示当前设置的是普通客户端，第 1 个 0 设置的是缓冲区大小限制，第 2 个 0 和第 3 个 0 分别表示缓冲区持续写入量限制和持续写入时间限制。</p>
<p>对于普通客户端来说，它每发送完一个请求，会等到请求结果返回后，再发送下一个请求，这种发送方式称为阻塞式发送。在这种情况下，如果不是读取体量特别大的 bigkey，服务器端的输出缓冲区一般不会被阻塞的。</p>
<p>所以，我们通常把普通客户端的缓冲区大小限制，以及持续写入量限制、持续写入时间限制都设置为 0，也就是不做限制。</p>
<p>对于订阅客户端来说，一旦订阅的 Redis 频道有消息了，服务器端都会通过输出缓冲区把消息发给客户端。所以，订阅客户端和服务器间的消息发送方式，不属于阻塞式发送。不过，如果频道消息较多的话，也会占用较多的输出缓冲区空间。</p>
<p>因此，我们会给订阅客户端设置缓冲区大小限制、缓冲区持续写入量限制，以及持续写入时间限制，可以在 Redis 配置文件中这样设置：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">client-output-buffer-limit pubsub 8mb 2mb 60</span><br></pre></td></tr></table></figure>

<p>其中，pubsub 参数表示当前是对订阅客户端进行设置；8mb 表示输出缓冲区的大小上限为 8MB，一旦实际占用的缓冲区大小要超过 8MB，服务器端就会直接关闭客户端的连接；2mb 和 60 表示，如果连续 60 秒内对输出缓冲区的写入量超过 2MB 的话，服务器端也会关闭客户端连接。</p>
<p>好了，我们来总结下如何应对输出缓冲区溢出：</p>
<blockquote>
<p>避免 bigkey 操作返回大量数据结果；</p>
<p>避免在线上环境中持续使用 MONITOR 命令。</p>
<p>使用 client-output-buffer-limit 设置合理的缓冲区大小上限，或是缓冲区连续写入时间和写入量上限。</p>
</blockquote>
<p>以上就是关于客户端缓冲区，我们要重点掌握的内容了。我们继续看看在主从集群间使用缓冲区，需要注意什么问题。</p>
<p><strong>主从集群中的缓冲区</strong></p>
<p>主从集群间的数据复制包括全量复制和增量复制两种。全量复制是同步所有数据，而增量复制只会把主从库网络断连期间主库收到的命令，同步给从库。无论在哪种形式的复制中，为了保证主从节点的数据一致，都会用到缓冲区。但是，这两种复制场景下的缓冲区，在溢出影响和大小设置方面并不一样。所以，我们分别来学习下吧。</p>
<p><strong>复制缓冲区的溢出问题</strong></p>
<p>在全量复制过程中，主节点在向从节点传输 RDB 文件的同时，会继续接收客户端发送的写命令请求。这些写命令就会先保存在复制缓冲区中，等 RDB 文件传输完成后，再发送给从节点去执行。主节点上会为每个从节点都维护一个复制缓冲区，来保证主从节点间的数据同步。</p>
<p><img src="/images/redis-70.jpg" alt="redis-3"></p>
<p>所以，如果在全量复制时，从节点接收和加载 RDB 较慢，同时主节点接收到了大量的写命令，写命令在复制缓冲区中就会越积越多，最终导致溢出。</p>
<p>其实，主节点上的复制缓冲区，本质上也是一个用于和从节点连接的客户端（我们称之为从节点客户端），使用的输出缓冲区。复制缓冲区一旦发生溢出，主节点也会直接关闭和从节点进行复制操作的连接，导致全量复制失败。那如何避免复制缓冲区发生溢出呢？</p>
<p>一方面，我们可以控制主节点保存的数据量大小。按通常的使用经验，我们会把主节点的数据量控制在 2~4GB，这样可以让全量同步执行得更快些，避免复制缓冲区累积过多命令。</p>
<p>另一方面，我们可以使用 client-output-buffer-limit 配置项，来设置合理的复制缓冲区大小。设置的依据，就是主节点的数据量大小、主节点的写负载压力和主节点本身的内存大小。</p>
<p>我们通过一个具体的例子，来学习下具体怎么设置。在主节点执行如下命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">config set client-output-buffer-limit slave 512mb 128mb 60</span><br></pre></td></tr></table></figure>

<p>其中，slave 参数表明该配置项是针对复制缓冲区的。512mb 代表将缓冲区大小的上限设置为 512MB；128mb 和 60 代表的设置是，如果连续 60 秒内的写入量超过 128MB 的话，也会触发缓冲区溢出。</p>
<p>我们再继续看看这个设置对我们有啥用。假设一条写命令数据是 1KB，那么，复制缓冲区可以累积 512K 条（512MB/1KB = 512K）写命令。同时，主节点在全量复制期间，可以承受的写命令速率上限是 2000 条 /s（128MB/1KB/60 约等于 2000）。</p>
<p>这样一来，我们就得到了一种方法：在实际应用中设置复制缓冲区的大小时，可以根据写命令数据的大小和应用的实际负载情况（也就是写命令速率），来粗略估计缓冲区中会累积的写命令数据量；然后，再和所设置的复制缓冲区大小进行比较，判断设置的缓冲区大小是否足够支撑累积的写命令数据量。</p>
<p>关于复制缓冲区，我们还会遇到一个问题。主节点上复制缓冲区的内存开销，会是每个从节点客户端输出缓冲区占用内存的总和。如果集群中的从节点数非常多的话，主节点的内存开销就会非常大。所以，我们还必须得控制和主节点连接的从节点个数，不要使用大规模的主从集群。</p>
<p>好了，我们先总结一下这部分的内容。为了避免复制缓冲区累积过多命令造成溢出，引发全量复制失败，我们可以控制主节点保存的数据量大小，并设置合理的复制缓冲区大小。同时，我们需要控制从节点的数量，来避免主节点中复制缓冲区占用过多内存的问题。</p>
<p><strong>复制积压缓冲区的溢出问题</strong></p>
<p>接下来，我们再来看下增量复制时使用的缓冲区，这个缓冲区称为复制积压缓冲区。</p>
<p>主节点在把接收到的写命令同步给从节点时，同时会把这些写命令写入复制积压缓冲区。一旦从节点发生网络闪断，再次和主节点恢复连接后，从节点就会从复制积压缓冲区中，读取断连期间主节点接收到的写命令，进而进行增量同步，如下图所示：</p>
<p><img src="/images/redis-71.jpg" alt="redis-3"></p>
<p>我们从缓冲区溢出的角度再来回顾下两个重点：复制积压缓冲区溢出的影响，以及如何应对复制积压缓冲区的溢出问题。</p>
<p>首先，复制积压缓冲区是一个大小有限的环形缓冲区。当主节点把复制积压缓冲区写满后，会覆盖缓冲区中的旧命令数据。如果从节点还没有同步这些旧命令数据，就会造成主从节点间重新开始执行全量复制。</p>
<p>其次，为了应对复制积压缓冲区的溢出问题，我们可以调整复制积压缓冲区的大小，也就是设置 repl_backlog_size 这个参数的值。</p>
<blockquote>
<p>缓冲区溢出导致网络连接关闭：普通客户端、订阅客户端，以及从节点客户端，它们使用的缓冲区，本质上都是 Redis 客户端和服务器端之间，或是主从节点之间为了传输命令数据而维护的。这些缓冲区一旦发生溢出，处理机制都是直接把客户端和服务器端的连接，或是主从节点间的连接关闭。网络连接关闭造成的直接影响，就是业务程序无法读写 Redis，或者是主从节点全量同步失败，需要重新执行。</p>
<p>缓冲区溢出导致命令数据丢失：主节点上的复制积压缓冲区属于环形缓冲区，一旦发生溢出，新写入的命令数据就会覆盖旧的命令数据，导致旧命令数据的丢失，进而导致主从节点重新进行全量复制。</p>
</blockquote>
<blockquote>
<p>针对命令数据发送过快过大的问题，对于普通客户端来说可以避免 bigkey，而对于复制缓冲区来说，就是避免过大的 RDB 文件。</p>
<p>针对命令数据处理较慢的问题，解决方案就是减少 Redis 主线程上的阻塞操作，例如使用异步的删除操作。</p>
<p>针对缓冲区空间过小的问题，解决方案就是使用 client-output-buffer-limit 配置项设置合理的输出缓冲区、复制缓冲区和复制积压缓冲区大小。当然，我们不要忘了，输入缓冲区的大小默认是固定的，我们无法通过配置来修改它，除非直接去修改 Redis 源码。</p>
</blockquote>
<h2 id="Redis缓存问题汇总"><a href="#Redis缓存问题汇总" class="headerlink" title="Redis缓存问题汇总"></a>Redis缓存问题汇总</h2><h2 id="旁路缓存：Redis是如何工作的？"><a href="#旁路缓存：Redis是如何工作的？" class="headerlink" title="旁路缓存：Redis是如何工作的？"></a>旁路缓存：Redis是如何工作的？</h2><p><img src="/images/redis-72.jpg" alt="redis-3"></p>
<p>从图上可以看到，CPU、内存和磁盘这三层的访问速度从几十 ns 到 100ns，再到几 ms，性能的差异很大。</p>
<p>想象一下，如果每次 CPU 处理数据时，都要从 ms 级别的慢速磁盘中读取数据，然后再进行处理，那么，CPU 只能等磁盘的数据传输完成。这样一来，高速的 CPU 就被慢速的磁盘拖累了，整个计算机系统的运行速度会变得非常慢。</p>
<p>所以，计算机系统中，默认有两种缓存：</p>
<blockquote>
<p>CPU 里面的末级缓存，即 LLC，用来缓存内存中的数据，避免每次从内存中存取数据；</p>
<p>内存中的高速页缓存，即 page cache，用来缓存磁盘中的数据，避免每次从磁盘中存取数据。</p>
</blockquote>
<p><img src="assets/16328983917246.jpg" alt></p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><p><a href="http://www.redis.cn/" target="_blank" rel="noopener">Redis中文网</a></p>
</li>
<li><p><a href="https://github.com/doocs/technical-books#database" target="_blank" rel="noopener">Redis设计与实现</a>——黄健宏</p>
</li>
<li><p>Redis 核心技术与实战</p>
</li>
</ul>

      
    </div>
    
    
    

    <div>
      
        <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div>
    
</div>

      
    </div>

    <div>
          
            
<div class="my_post_copyright">
  <script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script>

  <!-- JS库 sweetalert 可修改路径 -->
  <script src="https://cdn.bootcss.com/jquery/2.0.0/jquery.min.js"></script>
  <script src="https://unpkg.com/sweetalert/dist/sweetalert.min.js"></script>
  <p><span>本文标题:</span><a href="/2020/03/28/redis/">redis知识汇总</a></p>
  <p><span>文章作者:</span><a href="/" title="访问 Wxning 的个人博客">Wxning</a></p>
  <p><span>发布时间:</span>2020年03月28日 - 23:03</p>
  <p><span>最后更新:</span>2021年09月29日 - 14:09</p>
  <p><span>原始链接:</span><a href="/2020/03/28/redis/" title="redis知识汇总">http://yoursite.com/2020/03/28/redis/</a>
    <span class="copy-path" title="点击复制文章链接"><i class="fa fa-clipboard" data-clipboard-text="http://yoursite.com/2020/03/28/redis/" aria-label="复制成功！"></i></span>
  </p>
  <p><span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)">署名-非商业性使用-禁止演绎 4.0 国际</a> 转载请保留原文链接及作者。</p>
</div>
<script>
    var clipboard = new Clipboard('.fa-clipboard');
    $(".fa-clipboard").click(function(){
      clipboard.on('success', function(){
        swal({
          title: "",
          text: '复制成功',
          icon: "success",
          showConfirmButton: true
          });
    });
    });
</script>


          
    </div>

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/redis/" rel="tag"># redis</a>
          
            <a href="/tags/数据库/" rel="tag"># 数据库</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/03/22/context/" rel="next" title="go语言context">
                <i class="fa fa-chevron-left"></i> go语言context
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2020/04/02/pipeline/" rel="prev" title="go语言搭建pipeline">
                go语言搭建pipeline <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="lv-container" data-id="city" data-uid="MTAyMC80NTE2Ny8yMTY4NA=="></div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/avatar.gif" alt="Wxning">
            
              <p class="site-author-name" itemprop="name">Wxning</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">40</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">42</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">35</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/wxning1107" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Redis单线程优势"><span class="nav-number">1.</span> <span class="nav-text">Redis单线程优势</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#为什么不用多线程？"><span class="nav-number">1.1.</span> <span class="nav-text">为什么不用多线程？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#单线程-Redis-为什么那么快？"><span class="nav-number">1.2.</span> <span class="nav-text">单线程 Redis 为什么那么快？</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#redis数据类型"><span class="nav-number">2.</span> <span class="nav-text">redis数据类型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#String-应用场景"><span class="nav-number">3.</span> <span class="nav-text">String 应用场景</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Hash-应用场景"><span class="nav-number">4.</span> <span class="nav-text">Hash 应用场景</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#List-应用场景"><span class="nav-number">5.</span> <span class="nav-text">List 应用场景</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Set应用场景"><span class="nav-number">6.</span> <span class="nav-text">Set应用场景</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Sorted-Set-应用场景"><span class="nav-number">7.</span> <span class="nav-text">Sorted Set 应用场景</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Redis使用场景"><span class="nav-number">8.</span> <span class="nav-text">Redis使用场景</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#高级用法"><span class="nav-number">9.</span> <span class="nav-text">高级用法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Redis持久化"><span class="nav-number">10.</span> <span class="nav-text">Redis持久化</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#RDB-–-内存快照（宕机快速恢复）"><span class="nav-number">11.</span> <span class="nav-text">RDB – 内存快照（宕机快速恢复）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#原理"><span class="nav-number">11.1.</span> <span class="nav-text">原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#快照时数据能修改吗"><span class="nav-number">11.2.</span> <span class="nav-text">快照时数据能修改吗?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#增加快照"><span class="nav-number">11.3.</span> <span class="nav-text">增加快照</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#什么时候fork子进程（触发RDB持久化机制）"><span class="nav-number">11.4.</span> <span class="nav-text">什么时候fork子进程（触发RDB持久化机制）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#优缺点"><span class="nav-number">11.5.</span> <span class="nav-text">优缺点</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#AOF-—-避免数据丢失"><span class="nav-number">12.</span> <span class="nav-text">AOF — 避免数据丢失</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#AOF三种写回策略"><span class="nav-number">12.1.</span> <span class="nav-text">AOF三种写回策略</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#AOF重写机制"><span class="nav-number">12.2.</span> <span class="nav-text">AOF重写机制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#AOF-重写过程中有没有其他潜在的阻塞风险？"><span class="nav-number">12.3.</span> <span class="nav-text">AOF 重写过程中有没有其他潜在的阻塞风险？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#AOF追加阻塞"><span class="nav-number">12.4.</span> <span class="nav-text">AOF追加阻塞</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#优缺点-1"><span class="nav-number">12.5.</span> <span class="nav-text">优缺点</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#总结"><span class="nav-number">13.</span> <span class="nav-text">总结</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#两者如何选择"><span class="nav-number">13.1.</span> <span class="nav-text">两者如何选择</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#使用缓存一般思路"><span class="nav-number">14.</span> <span class="nav-text">使用缓存一般思路</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#内存淘汰机制"><span class="nav-number">15.</span> <span class="nav-text">内存淘汰机制</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#缓存穿透"><span class="nav-number">16.</span> <span class="nav-text">缓存穿透</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#缓存击穿"><span class="nav-number">17.</span> <span class="nav-text">缓存击穿</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#缓存雪崩"><span class="nav-number">18.</span> <span class="nav-text">缓存雪崩</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#布隆过滤器"><span class="nav-number">19.</span> <span class="nav-text">布隆过滤器</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#缓存与数据库数据一致性"><span class="nav-number">20.</span> <span class="nav-text">缓存与数据库数据一致性</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#单线程的redis为什么这么快"><span class="nav-number">21.</span> <span class="nav-text">单线程的redis为什么这么快</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Redis变慢的场景"><span class="nav-number">22.</span> <span class="nav-text">Redis变慢的场景</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Redis架构模式"><span class="nav-number">23.</span> <span class="nav-text">Redis架构模式</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#主从复制"><span class="nav-number">23.1.</span> <span class="nav-text">主从复制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#哨兵模式"><span class="nav-number">23.2.</span> <span class="nav-text">哨兵模式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Redis-Cluster高可用集群"><span class="nav-number">23.3.</span> <span class="nav-text">Redis Cluster高可用集群</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#数据结构实践-–-字符串"><span class="nav-number">24.</span> <span class="nav-text">数据结构实践 – 字符串</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#集合类型统计模式"><span class="nav-number">25.</span> <span class="nav-text">集合类型统计模式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#如何在Redis中保存时间序列数据？"><span class="nav-number">26.</span> <span class="nav-text">如何在Redis中保存时间序列数据？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#影响-Redis-性能的-5-大方面的潜在因素"><span class="nav-number">27.</span> <span class="nav-text">影响 Redis 性能的 5 大方面的潜在因素</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#内部的阻塞式操作"><span class="nav-number">27.1.</span> <span class="nav-text">内部的阻塞式操作</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#为什么CPU结构也会影响Redis的性能？"><span class="nav-number">27.2.</span> <span class="nav-text">为什么CPU结构也会影响Redis的性能？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#波动的响应延迟：如何应对变慢的Redis？"><span class="nav-number">27.3.</span> <span class="nav-text">波动的响应延迟：如何应对变慢的Redis？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#删除数据后，为什么内存占用率还是很高？"><span class="nav-number">27.4.</span> <span class="nav-text">删除数据后，为什么内存占用率还是很高？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#缓冲区：一个可能引发“惨案”的地方"><span class="nav-number">27.5.</span> <span class="nav-text">缓冲区：一个可能引发“惨案”的地方</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Redis缓存问题汇总"><span class="nav-number">28.</span> <span class="nav-text">Redis缓存问题汇总</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#旁路缓存：Redis是如何工作的？"><span class="nav-number">29.</span> <span class="nav-text">旁路缓存：Redis是如何工作的？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#参考资料"><span class="nav-number">30.</span> <span class="nav-text">参考资料</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Wxning</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>




        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i> 访问人数
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      人
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i> 总访问量
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  
    <script type="text/javascript">
      (function(d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') { return; }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;
        e.parentNode.insertBefore(j, e);
      })(document, 'script');
    </script>
  












  





  

  

  

  
  

  

  

  

</body>
</html>
